TID: [2014-09-17 17:11:01,286]  INFO {org.wso2.carbon.server.extensions.PatchInstaller} -  Patch changes detected  {org.wso2.carbon.server.extensions.PatchInstaller}
TID: [2014-09-17 17:11:01,509]  INFO {org.wso2.carbon.server.util.PatchUtils.console} -  Backed up plugins to patch0000 {org.wso2.carbon.server.util.PatchUtils.console}
TID: [2014-09-17 17:11:01,665]  INFO {org.wso2.carbon.server.util.PatchUtils.console} -  Patch verification started {org.wso2.carbon.server.util.PatchUtils.console}
TID: [2014-09-17 17:11:01,820]  INFO {org.wso2.carbon.server.util.PatchUtils.console} -  Patch verification successfully completed. {org.wso2.carbon.server.util.PatchUtils.console}
TID: [0] [BAM] [2014-09-17 17:11:04,284]  INFO {org.wso2.carbon.core.internal.CarbonCoreActivator} -  Starting WSO2 Carbon... {org.wso2.carbon.core.internal.CarbonCoreActivator}
TID: [0] [BAM] [2014-09-17 17:11:04,286]  INFO {org.wso2.carbon.core.internal.CarbonCoreActivator} -  Operating System : Linux 3.13.0-24-generic, amd64 {org.wso2.carbon.core.internal.CarbonCoreActivator}
TID: [0] [BAM] [2014-09-17 17:11:04,286]  INFO {org.wso2.carbon.core.internal.CarbonCoreActivator} -  Java Home        : /usr/lib/jvm/java-6-oracle/jre {org.wso2.carbon.core.internal.CarbonCoreActivator}
TID: [0] [BAM] [2014-09-17 17:11:04,286]  INFO {org.wso2.carbon.core.internal.CarbonCoreActivator} -  Java Version     : 1.6.0_45 {org.wso2.carbon.core.internal.CarbonCoreActivator}
TID: [0] [BAM] [2014-09-17 17:11:04,286]  INFO {org.wso2.carbon.core.internal.CarbonCoreActivator} -  Java VM          : Java HotSpot(TM) 64-Bit Server VM 20.45-b01,Sun Microsystems Inc. {org.wso2.carbon.core.internal.CarbonCoreActivator}
TID: [0] [BAM] [2014-09-17 17:11:04,286]  INFO {org.wso2.carbon.core.internal.CarbonCoreActivator} -  Carbon Home      : /home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0 {org.wso2.carbon.core.internal.CarbonCoreActivator}
TID: [0] [BAM] [2014-09-17 17:11:04,286]  INFO {org.wso2.carbon.core.internal.CarbonCoreActivator} -  Java Temp Dir    : /home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/tmp {org.wso2.carbon.core.internal.CarbonCoreActivator}
TID: [0] [BAM] [2014-09-17 17:11:04,286]  INFO {org.wso2.carbon.core.internal.CarbonCoreActivator} -  User             : denuwanthi, en-US, Asia/Colombo {org.wso2.carbon.core.internal.CarbonCoreActivator}
TID: [0] [BAM] [2014-09-17 17:11:04,352]  WARN {org.wso2.carbon.core.bootup.validator.util.ValidationResultPrinter} -  The default keystore (wso2carbon.jks) is currently being used. To maximize security when deploying to a production environment, configure a new keystore with a unique password in the production server profile. {org.wso2.carbon.core.bootup.validator.util.ValidationResultPrinter}
TID: [0] [BAM] [2014-09-17 17:11:04,376]  INFO {org.wso2.carbon.databridge.agent.thrift.AgentHolder} -  Agent created ! {org.wso2.carbon.databridge.agent.thrift.AgentHolder}
TID: [0] [BAM] [2014-09-17 17:11:04,435]  INFO {org.wso2.carbon.databridge.agent.thrift.internal.AgentDS} -  Successfully deployed Agent Client {org.wso2.carbon.databridge.agent.thrift.internal.AgentDS}
TID: [0] [BAM] [2014-09-17 17:11:05,682]  INFO {org.wso2.carbon.bam.toolbox.deployer.internal.DataBridgeRecieverServiceComponent} -  Successfully setted data bridge reciever service {org.wso2.carbon.bam.toolbox.deployer.internal.DataBridgeRecieverServiceComponent}
TID: [0] [BAM] [2014-09-17 17:11:05,688]  INFO {org.wso2.carbon.databridge.core.internal.DataBridgeDS} -  Successfully deployed Agent Server  {org.wso2.carbon.databridge.core.internal.DataBridgeDS}
TID: [0] [BAM] [2014-09-17 17:11:05,857]  INFO {org.wso2.carbon.registry.core.jdbc.EmbeddedRegistryService} -  Configured Registry in 106ms {org.wso2.carbon.registry.core.jdbc.EmbeddedRegistryService}
TID: [0] [BAM] [2014-09-17 17:11:06,192]  INFO {org.wso2.carbon.registry.core.internal.RegistryCoreServiceComponent} -  Registry Mode    : READ-WRITE {org.wso2.carbon.registry.core.internal.RegistryCoreServiceComponent}
TID: [0] [BAM] [2014-09-17 17:11:06,255]  INFO {org.wso2.carbon.dashboard.dashboardpopulator.GadgetPopulator} -  Couldn't find a Dashboard at '/home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/repository/resources/dashboard/dashboard.xml'. Giving up. {org.wso2.carbon.dashboard.dashboardpopulator.GadgetPopulator}
TID: [0] [BAM] [2014-09-17 17:11:06,255]  INFO {org.wso2.carbon.dashboard.dashboardpopulator.GadgetPopulator} -  Couldn't find contents at '/home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/repository/resources/dashboard/gadgets'. Giving up. {org.wso2.carbon.dashboard.dashboardpopulator.GadgetPopulator}
TID: [0] [BAM] [2014-09-17 17:11:06,308]  INFO {org.apache.cassandra.net.MessagingService} -  Starting Messaging Service on port 7000 {org.apache.cassandra.net.MessagingService}
TID: [0] [BAM] [2014-09-17 17:11:06,347]  INFO {org.apache.cassandra.thrift.CassandraDaemon} -  Binding thrift service to localhost/127.0.0.1:9160 {org.apache.cassandra.thrift.CassandraDaemon}
TID: [0] [BAM] [2014-09-17 17:11:06,348]  INFO {org.apache.cassandra.thrift.CassandraDaemon} -  Using TFastFramedTransport with a max frame size of 15728640 bytes. {org.apache.cassandra.thrift.CassandraDaemon}
TID: [0] [BAM] [2014-09-17 17:11:06,350]  INFO {org.apache.cassandra.thrift.CassandraDaemon} -  Using synchronous/threadpool thrift server on localhost/127.0.0.1 : 9160 {org.apache.cassandra.thrift.CassandraDaemon}
TID: [0] [BAM] [2014-09-17 17:11:06,350]  INFO {org.wso2.carbon.cassandra.server.CassandraServerController} -  Cassandra Server Controller Thread was destroyed successfully {org.wso2.carbon.cassandra.server.CassandraServerController}
TID: [0] [BAM] [2014-09-17 17:11:06,350]  INFO {org.apache.cassandra.thrift.CassandraDaemon} -  Listening for thrift clients... {org.apache.cassandra.thrift.CassandraDaemon}
TID: [0] [BAM] [2014-09-17 17:11:06,908]  INFO {org.wso2.carbon.user.core.internal.UserStoreMgtDSComponent} -  Carbon UserStoreMgtDSComponent activated successfully. {org.wso2.carbon.user.core.internal.UserStoreMgtDSComponent}
TID: [0] [BAM] [2014-09-17 17:11:10,748]  INFO {org.apache.axis2.deployment.ClusterBuilder} -  Clustering has been disabled {org.apache.axis2.deployment.ClusterBuilder}
TID: [0] [BAM] [2014-09-17 17:11:10,985]  INFO {org.wso2.carbon.identity.user.store.configuration.deployer.UserStoreConfigurationDeployer} -  User Store Configuration Deployer initiated. {org.wso2.carbon.identity.user.store.configuration.deployer.UserStoreConfigurationDeployer}
TID: [0] [BAM] [2014-09-17 17:11:11,020]  INFO {org.wso2.carbon.stratos.landing.page.deployer.LandingPageWebappDeployer} -  Deployed product landing page webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/home] {org.wso2.carbon.stratos.landing.page.deployer.LandingPageWebappDeployer}
TID: [0] [BAM] [2014-09-17 17:11:11,024]  INFO {org.apache.axis2.transport.tcp.TCPTransportSender} -  TCP Sender started {org.apache.axis2.transport.tcp.TCPTransportSender}
TID: [0] [BAM] [2014-09-17 17:11:11,053]  INFO {org.wso2.carbon.webapp.mgt.TomcatGenericWebappsDeployer} -  Deployed webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/STRATOS_ROOT].File[/home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/repository/deployment/server/webapps/STRATOS_ROOT] {org.wso2.carbon.webapp.mgt.TomcatGenericWebappsDeployer}
TID: [0] [BAM] [2014-09-17 17:11:11,736]  INFO {org.springframework.web.context.support.XmlWebApplicationContext} -  Refreshing Root WebApplicationContext: startup date [Wed Sep 17 17:11:11 IST 2014]; root of context hierarchy {org.springframework.web.context.support.XmlWebApplicationContext}
TID: [0] [BAM] [2014-09-17 17:11:11,781]  INFO {org.springframework.beans.factory.xml.XmlBeanDefinitionReader} -  Loading XML bean definitions from class path resource [META-INF/cxf/cxf.xml] {org.springframework.beans.factory.xml.XmlBeanDefinitionReader}
TID: [0] [BAM] [2014-09-17 17:11:11,857]  INFO {org.springframework.beans.factory.xml.XmlBeanDefinitionReader} -  Loading XML bean definitions from URL [jndi:/localhost/datareceiver/WEB-INF/cxf-servlet.xml] {org.springframework.beans.factory.xml.XmlBeanDefinitionReader}
TID: [0] [BAM] [2014-09-17 17:11:12,111]  INFO {org.springframework.beans.factory.support.DefaultListableBeanFactory} -  Pre-instantiating singletons in org.springframework.beans.factory.support.DefaultListableBeanFactory@332b24bc: defining beans [cxf,org.apache.cxf.bus.spring.BusWiringBeanFactoryPostProcessor,org.apache.cxf.bus.spring.Jsr250BeanPostProcessor,org.apache.cxf.bus.spring.BusExtensionPostProcessor,dataReceiverStreamsService,dataReceiverStreamService,streamsBean,streamBean]; root of factory hierarchy {org.springframework.beans.factory.support.DefaultListableBeanFactory}
TID: [0] [BAM] [2014-09-17 17:11:12,391]  INFO {org.apache.cxf.endpoint.ServerImpl} -  Setting the server's publish address to be /streams {org.apache.cxf.endpoint.ServerImpl}
TID: [0] [BAM] [2014-09-17 17:11:12,443]  INFO {org.apache.cxf.endpoint.ServerImpl} -  Setting the server's publish address to be /stream {org.apache.cxf.endpoint.ServerImpl}
TID: [0] [BAM] [2014-09-17 17:11:12,450]  INFO {org.wso2.carbon.webapp.mgt.TomcatGenericWebappsDeployer} -  Deployed webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/datareceiver].File[/home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/repository/deployment/server/webapps/datareceiver.war] {org.wso2.carbon.webapp.mgt.TomcatGenericWebappsDeployer}
TID: [0] [BAM] [2014-09-17 17:11:13,051]  INFO {org.jaggeryjs.jaggery.app.mgt.TomcatJaggeryWebappsDeployer} -  Deployed webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/bamdashboards].File[/home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/repository/deployment/server/jaggeryapps/bamdashboards] {org.jaggeryjs.jaggery.app.mgt.TomcatJaggeryWebappsDeployer}
TID: [0] [BAM] [2014-09-17 17:11:13,097]  INFO {org.jaggeryjs.jaggery.app.mgt.TomcatJaggeryWebappsDeployer} -  Deployed webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/activitymonitoring].File[/home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/repository/deployment/server/jaggeryapps/activitymonitoring] {org.jaggeryjs.jaggery.app.mgt.TomcatJaggeryWebappsDeployer}
TID: [0] [BAM] [2014-09-17 17:11:13,156]  INFO {org.apache.axis2.deployment.ModuleDeployer} -  Deploying module: rampart-1.6.1-wso2v10 - file:/home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/repository/deployment/client/modules/rampart-1.6.1-wso2v10.mar {org.apache.axis2.deployment.ModuleDeployer}
TID: [0] [BAM] [2014-09-17 17:11:13,159]  INFO {org.apache.axis2.deployment.ModuleDeployer} -  Deploying module: addressing-1.6.1-wso2v10 - file:/home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/repository/deployment/client/modules/addressing-1.6.1-wso2v10.mar {org.apache.axis2.deployment.ModuleDeployer}
TID: [0] [BAM] [2014-09-17 17:11:13,162]  INFO {org.apache.axis2.transport.tcp.TCPTransportSender} -  TCP Sender started {org.apache.axis2.transport.tcp.TCPTransportSender}
TID: [0] [BAM] [2014-09-17 17:11:13,388]  INFO {org.wso2.carbon.core.deployment.DeploymentInterceptor} -  Deploying Axis2 service: BAMMessageStoreService {super-tenant} {org.wso2.carbon.core.deployment.DeploymentInterceptor}
TID: [0] [BAM] [2014-09-17 17:11:13,421]  INFO {org.apache.axis2.deployment.DeploymentEngine} -  Deploying Web service: org.wso2.carbon.bam.messagestore -  {org.apache.axis2.deployment.DeploymentEngine}
TID: [0] [BAM] [2014-09-17 17:11:13,595]  INFO {org.wso2.carbon.core.deployment.DeploymentInterceptor} -  Deploying Axis2 service: CassandraSearchAdmin {super-tenant} {org.wso2.carbon.core.deployment.DeploymentInterceptor}
TID: [0] [BAM] [2014-09-17 17:11:13,710]  INFO {org.apache.axis2.deployment.DeploymentEngine} -  Deploying Web service: org.wso2.carbon.cassandra.search.mgt -  {org.apache.axis2.deployment.DeploymentEngine}
TID: [0] [BAM] [2014-09-17 17:11:14,579]  INFO {org.wso2.carbon.core.init.CarbonServerManager} -  Repository       : /home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/repository/deployment/server/ {org.wso2.carbon.core.init.CarbonServerManager}
TID: [0] [BAM] [2014-09-17 17:11:14,611]  INFO {org.wso2.carbon.bam.toolbox.deployer.internal.BAMToolBoxDeployerComponent} -  Successfully Started BAM Toolbox Deployer {org.wso2.carbon.bam.toolbox.deployer.internal.BAMToolBoxDeployerComponent}
TID: [0] [BAM] [2014-09-17 17:11:14,644]  INFO {org.wso2.carbon.core.internal.permission.update.PermissionUpdater} -  Permission cache updated for tenant -1234 {org.wso2.carbon.core.internal.permission.update.PermissionUpdater}
TID: [0] [BAM] [2014-09-17 17:11:14,656]  INFO {org.wso2.carbon.bam.toolbox.deployer.internal.DashboardServiceComponent} -  Successfully setted dashboard services {org.wso2.carbon.bam.toolbox.deployer.internal.DashboardServiceComponent}
TID: [0] [BAM] [2014-09-17 17:11:14,784]  INFO {org.wso2.carbon.databridge.receiver.thrift.internal.ThriftDataReceiver} -  Thrift Server started at 10.100.5.90 {org.wso2.carbon.databridge.receiver.thrift.internal.ThriftDataReceiver}
TID: [0] [BAM] [2014-09-17 17:11:14,791]  INFO {org.wso2.carbon.databridge.receiver.thrift.internal.ThriftDataReceiver} -  Thrift SSL port : 7711 {org.wso2.carbon.databridge.receiver.thrift.internal.ThriftDataReceiver}
TID: [0] [BAM] [2014-09-17 17:11:14,793]  INFO {org.wso2.carbon.databridge.receiver.thrift.internal.ThriftDataReceiver} -  Thrift port : 7611 {org.wso2.carbon.databridge.receiver.thrift.internal.ThriftDataReceiver}
TID: [0] [BAM] [2014-09-17 17:11:15,015]  INFO {org.wso2.carbon.core.transports.http.HttpsTransportListener} -  HTTPS port       : 9443 {org.wso2.carbon.core.transports.http.HttpsTransportListener}
TID: [0] [BAM] [2014-09-17 17:11:15,015]  INFO {org.wso2.carbon.core.transports.http.HttpTransportListener} -  HTTP port        : 9763 {org.wso2.carbon.core.transports.http.HttpTransportListener}
TID: [0] [BAM] [2014-09-17 17:11:15,018] ERROR {org.wso2.carbon.tomcat.internal.CarbonTomcat} -  LifeCycleException while starting tomcat connector {org.wso2.carbon.tomcat.internal.CarbonTomcat}
org.apache.catalina.LifecycleException: Failed to start component [Connector[org.apache.coyote.http11.Http11NioProtocol-9763]]
	at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:154)
	at org.wso2.carbon.tomcat.internal.CarbonTomcat.startConnectors(CarbonTomcat.java:379)
	at org.wso2.carbon.tomcat.ext.transport.ServletTransportManager.startTransports(ServletTransportManager.java:79)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.wso2.carbon.core.internal.StartupFinalizerServiceComponent.completeInitialization(StartupFinalizerServiceComponent.java:185)
	at org.wso2.carbon.core.internal.StartupFinalizerServiceComponent.serviceChanged(StartupFinalizerServiceComponent.java:280)
	at org.eclipse.osgi.internal.serviceregistry.FilteredServiceListener.serviceChanged(FilteredServiceListener.java:107)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.dispatchEvent(BundleContextImpl.java:861)
	at org.eclipse.osgi.framework.eventmgr.EventManager.dispatchEvent(EventManager.java:230)
	at org.eclipse.osgi.framework.eventmgr.ListenerQueue.dispatchEventSynchronous(ListenerQueue.java:148)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistry.publishServiceEventPrivileged(ServiceRegistry.java:819)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistry.publishServiceEvent(ServiceRegistry.java:771)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistrationImpl.register(ServiceRegistrationImpl.java:130)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistry.registerService(ServiceRegistry.java:214)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.registerService(BundleContextImpl.java:433)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.registerService(BundleContextImpl.java:451)
	at org.wso2.carbon.server.admin.internal.ServerAdminServiceComponent.activate(ServerAdminServiceComponent.java:106)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.eclipse.equinox.internal.ds.model.ServiceComponent.activate(ServiceComponent.java:260)
	at org.eclipse.equinox.internal.ds.model.ServiceComponentProp.activate(ServiceComponentProp.java:146)
	at org.eclipse.equinox.internal.ds.model.ServiceComponentProp.build(ServiceComponentProp.java:347)
	at org.eclipse.equinox.internal.ds.InstanceProcess.buildComponent(InstanceProcess.java:620)
	at org.eclipse.equinox.internal.ds.InstanceProcess.buildComponents(InstanceProcess.java:197)
	at org.eclipse.equinox.internal.ds.Resolver.getEligible(Resolver.java:343)
	at org.eclipse.equinox.internal.ds.SCRManager.serviceChanged(SCRManager.java:222)
	at org.eclipse.osgi.internal.serviceregistry.FilteredServiceListener.serviceChanged(FilteredServiceListener.java:107)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.dispatchEvent(BundleContextImpl.java:861)
	at org.eclipse.osgi.framework.eventmgr.EventManager.dispatchEvent(EventManager.java:230)
	at org.eclipse.osgi.framework.eventmgr.ListenerQueue.dispatchEventSynchronous(ListenerQueue.java:148)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistry.publishServiceEventPrivileged(ServiceRegistry.java:819)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistry.publishServiceEvent(ServiceRegistry.java:771)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistrationImpl.register(ServiceRegistrationImpl.java:130)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistry.registerService(ServiceRegistry.java:214)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.registerService(BundleContextImpl.java:433)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.registerService(BundleContextImpl.java:451)
	at org.wso2.carbon.core.init.CarbonServerManager.initializeCarbon(CarbonServerManager.java:517)
	at org.wso2.carbon.core.init.CarbonServerManager.start(CarbonServerManager.java:219)
	at org.wso2.carbon.core.internal.CarbonCoreServiceComponent.activate(CarbonCoreServiceComponent.java:77)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.eclipse.equinox.internal.ds.model.ServiceComponent.activate(ServiceComponent.java:260)
	at org.eclipse.equinox.internal.ds.model.ServiceComponentProp.activate(ServiceComponentProp.java:146)
	at org.eclipse.equinox.internal.ds.model.ServiceComponentProp.build(ServiceComponentProp.java:347)
	at org.eclipse.equinox.internal.ds.InstanceProcess.buildComponent(InstanceProcess.java:620)
	at org.eclipse.equinox.internal.ds.InstanceProcess.buildComponents(InstanceProcess.java:197)
	at org.eclipse.equinox.internal.ds.Resolver.getEligible(Resolver.java:343)
	at org.eclipse.equinox.internal.ds.SCRManager.serviceChanged(SCRManager.java:222)
	at org.eclipse.osgi.internal.serviceregistry.FilteredServiceListener.serviceChanged(FilteredServiceListener.java:107)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.dispatchEvent(BundleContextImpl.java:861)
	at org.eclipse.osgi.framework.eventmgr.EventManager.dispatchEvent(EventManager.java:230)
	at org.eclipse.osgi.framework.eventmgr.ListenerQueue.dispatchEventSynchronous(ListenerQueue.java:148)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistry.publishServiceEventPrivileged(ServiceRegistry.java:819)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistry.publishServiceEvent(ServiceRegistry.java:771)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistrationImpl.register(ServiceRegistrationImpl.java:130)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistry.registerService(ServiceRegistry.java:214)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.registerService(BundleContextImpl.java:433)
	at org.eclipse.equinox.http.servlet.internal.Activator.registerHttpService(Activator.java:81)
	at org.eclipse.equinox.http.servlet.internal.Activator.addProxyServlet(Activator.java:60)
	at org.eclipse.equinox.http.servlet.internal.ProxyServlet.init(ProxyServlet.java:40)
	at org.wso2.carbon.tomcat.ext.servlet.DelegationServlet.init(DelegationServlet.java:38)
	at org.apache.catalina.core.StandardWrapper.initServlet(StandardWrapper.java:1267)
	at org.apache.catalina.core.StandardWrapper.loadServlet(StandardWrapper.java:1186)
	at org.apache.catalina.core.StandardWrapper.load(StandardWrapper.java:1081)
	at org.apache.catalina.core.StandardContext.loadOnStartup(StandardContext.java:5027)
	at org.apache.catalina.core.StandardContext.startInternal(StandardContext.java:5314)
	at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150)
	at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1559)
	at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1549)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.catalina.LifecycleException: service.getName(): "Catalina";  Protocol handler start failed
	at org.apache.catalina.connector.Connector.startInternal(Connector.java:1017)
	at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150)
	... 80 more
Caused by: java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind(Native Method)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:124)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:59)
	at org.apache.tomcat.util.net.NioEndpoint.bind(NioEndpoint.java:470)
	at org.apache.tomcat.util.net.AbstractEndpoint.start(AbstractEndpoint.java:617)
	at org.apache.coyote.AbstractProtocol.start(AbstractProtocol.java:444)
	at org.apache.catalina.connector.Connector.startInternal(Connector.java:1010)
	... 81 more
TID: [0] [BAM] [2014-09-17 17:11:15,022] ERROR {org.wso2.carbon.tomcat.internal.CarbonTomcat} -  LifeCycleException while starting tomcat connector {org.wso2.carbon.tomcat.internal.CarbonTomcat}
org.apache.catalina.LifecycleException: Failed to start component [Connector[org.apache.coyote.http11.Http11NioProtocol-9443]]
	at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:154)
	at org.wso2.carbon.tomcat.internal.CarbonTomcat.startConnectors(CarbonTomcat.java:379)
	at org.wso2.carbon.tomcat.ext.transport.ServletTransportManager.startTransports(ServletTransportManager.java:79)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.wso2.carbon.core.internal.StartupFinalizerServiceComponent.completeInitialization(StartupFinalizerServiceComponent.java:185)
	at org.wso2.carbon.core.internal.StartupFinalizerServiceComponent.serviceChanged(StartupFinalizerServiceComponent.java:280)
	at org.eclipse.osgi.internal.serviceregistry.FilteredServiceListener.serviceChanged(FilteredServiceListener.java:107)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.dispatchEvent(BundleContextImpl.java:861)
	at org.eclipse.osgi.framework.eventmgr.EventManager.dispatchEvent(EventManager.java:230)
	at org.eclipse.osgi.framework.eventmgr.ListenerQueue.dispatchEventSynchronous(ListenerQueue.java:148)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistry.publishServiceEventPrivileged(ServiceRegistry.java:819)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistry.publishServiceEvent(ServiceRegistry.java:771)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistrationImpl.register(ServiceRegistrationImpl.java:130)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistry.registerService(ServiceRegistry.java:214)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.registerService(BundleContextImpl.java:433)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.registerService(BundleContextImpl.java:451)
	at org.wso2.carbon.server.admin.internal.ServerAdminServiceComponent.activate(ServerAdminServiceComponent.java:106)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.eclipse.equinox.internal.ds.model.ServiceComponent.activate(ServiceComponent.java:260)
	at org.eclipse.equinox.internal.ds.model.ServiceComponentProp.activate(ServiceComponentProp.java:146)
	at org.eclipse.equinox.internal.ds.model.ServiceComponentProp.build(ServiceComponentProp.java:347)
	at org.eclipse.equinox.internal.ds.InstanceProcess.buildComponent(InstanceProcess.java:620)
	at org.eclipse.equinox.internal.ds.InstanceProcess.buildComponents(InstanceProcess.java:197)
	at org.eclipse.equinox.internal.ds.Resolver.getEligible(Resolver.java:343)
	at org.eclipse.equinox.internal.ds.SCRManager.serviceChanged(SCRManager.java:222)
	at org.eclipse.osgi.internal.serviceregistry.FilteredServiceListener.serviceChanged(FilteredServiceListener.java:107)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.dispatchEvent(BundleContextImpl.java:861)
	at org.eclipse.osgi.framework.eventmgr.EventManager.dispatchEvent(EventManager.java:230)
	at org.eclipse.osgi.framework.eventmgr.ListenerQueue.dispatchEventSynchronous(ListenerQueue.java:148)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistry.publishServiceEventPrivileged(ServiceRegistry.java:819)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistry.publishServiceEvent(ServiceRegistry.java:771)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistrationImpl.register(ServiceRegistrationImpl.java:130)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistry.registerService(ServiceRegistry.java:214)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.registerService(BundleContextImpl.java:433)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.registerService(BundleContextImpl.java:451)
	at org.wso2.carbon.core.init.CarbonServerManager.initializeCarbon(CarbonServerManager.java:517)
	at org.wso2.carbon.core.init.CarbonServerManager.start(CarbonServerManager.java:219)
	at org.wso2.carbon.core.internal.CarbonCoreServiceComponent.activate(CarbonCoreServiceComponent.java:77)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.eclipse.equinox.internal.ds.model.ServiceComponent.activate(ServiceComponent.java:260)
	at org.eclipse.equinox.internal.ds.model.ServiceComponentProp.activate(ServiceComponentProp.java:146)
	at org.eclipse.equinox.internal.ds.model.ServiceComponentProp.build(ServiceComponentProp.java:347)
	at org.eclipse.equinox.internal.ds.InstanceProcess.buildComponent(InstanceProcess.java:620)
	at org.eclipse.equinox.internal.ds.InstanceProcess.buildComponents(InstanceProcess.java:197)
	at org.eclipse.equinox.internal.ds.Resolver.getEligible(Resolver.java:343)
	at org.eclipse.equinox.internal.ds.SCRManager.serviceChanged(SCRManager.java:222)
	at org.eclipse.osgi.internal.serviceregistry.FilteredServiceListener.serviceChanged(FilteredServiceListener.java:107)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.dispatchEvent(BundleContextImpl.java:861)
	at org.eclipse.osgi.framework.eventmgr.EventManager.dispatchEvent(EventManager.java:230)
	at org.eclipse.osgi.framework.eventmgr.ListenerQueue.dispatchEventSynchronous(ListenerQueue.java:148)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistry.publishServiceEventPrivileged(ServiceRegistry.java:819)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistry.publishServiceEvent(ServiceRegistry.java:771)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistrationImpl.register(ServiceRegistrationImpl.java:130)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistry.registerService(ServiceRegistry.java:214)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.registerService(BundleContextImpl.java:433)
	at org.eclipse.equinox.http.servlet.internal.Activator.registerHttpService(Activator.java:81)
	at org.eclipse.equinox.http.servlet.internal.Activator.addProxyServlet(Activator.java:60)
	at org.eclipse.equinox.http.servlet.internal.ProxyServlet.init(ProxyServlet.java:40)
	at org.wso2.carbon.tomcat.ext.servlet.DelegationServlet.init(DelegationServlet.java:38)
	at org.apache.catalina.core.StandardWrapper.initServlet(StandardWrapper.java:1267)
	at org.apache.catalina.core.StandardWrapper.loadServlet(StandardWrapper.java:1186)
	at org.apache.catalina.core.StandardWrapper.load(StandardWrapper.java:1081)
	at org.apache.catalina.core.StandardContext.loadOnStartup(StandardContext.java:5027)
	at org.apache.catalina.core.StandardContext.startInternal(StandardContext.java:5314)
	at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150)
	at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1559)
	at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1549)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.catalina.LifecycleException: service.getName(): "Catalina";  Protocol handler start failed
	at org.apache.catalina.connector.Connector.startInternal(Connector.java:1017)
	at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150)
	... 80 more
Caused by: java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind(Native Method)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:124)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:59)
	at org.apache.tomcat.util.net.NioEndpoint.bind(NioEndpoint.java:470)
	at org.apache.tomcat.util.net.AbstractEndpoint.start(AbstractEndpoint.java:617)
	at org.apache.coyote.AbstractProtocol.start(AbstractProtocol.java:444)
	at org.apache.catalina.connector.Connector.startInternal(Connector.java:1010)
	... 81 more
TID: [0] [BAM] [2014-09-17 17:11:15,081]  INFO {org.wso2.carbon.ntask.core.service.impl.TaskServiceImpl} -  Task service starting in STANDALONE mode... {org.wso2.carbon.ntask.core.service.impl.TaskServiceImpl}
TID: [0] [BAM] [2014-09-17 17:11:15,481]  INFO {org.wso2.carbon.ntask.core.impl.AbstractQuartzTaskManager} -  Task scheduled: [-1234][BAM_NOTIFICATION_DISPATCHER_TASK][NOTIFIER] {org.wso2.carbon.ntask.core.impl.AbstractQuartzTaskManager}
TID: [0] [BAM] [2014-09-17 17:11:15,489] ERROR {org.wso2.carbon.core.init.JMXServerManager} -  Could not create the RMI local registry {org.wso2.carbon.core.init.JMXServerManager}
java.rmi.server.ExportException: Port already in use: 9999; nested exception is: 
	java.net.BindException: Address already in use
	at sun.rmi.transport.tcp.TCPTransport.listen(TCPTransport.java:310)
	at sun.rmi.transport.tcp.TCPTransport.exportObject(TCPTransport.java:218)
	at sun.rmi.transport.tcp.TCPEndpoint.exportObject(TCPEndpoint.java:393)
	at sun.rmi.transport.LiveRef.exportObject(LiveRef.java:129)
	at sun.rmi.server.UnicastServerRef.exportObject(UnicastServerRef.java:188)
	at sun.rmi.registry.RegistryImpl.setup(RegistryImpl.java:100)
	at sun.rmi.registry.RegistryImpl.<init>(RegistryImpl.java:86)
	at java.rmi.registry.LocateRegistry.createRegistry(LocateRegistry.java:186)
	at org.wso2.carbon.core.init.JMXServerManager.startJMXService(JMXServerManager.java:89)
	at org.wso2.carbon.core.internal.StartupFinalizerServiceComponent.completeInitialization(StartupFinalizerServiceComponent.java:195)
	at org.wso2.carbon.core.internal.StartupFinalizerServiceComponent.serviceChanged(StartupFinalizerServiceComponent.java:280)
	at org.eclipse.osgi.internal.serviceregistry.FilteredServiceListener.serviceChanged(FilteredServiceListener.java:107)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.dispatchEvent(BundleContextImpl.java:861)
	at org.eclipse.osgi.framework.eventmgr.EventManager.dispatchEvent(EventManager.java:230)
	at org.eclipse.osgi.framework.eventmgr.ListenerQueue.dispatchEventSynchronous(ListenerQueue.java:148)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistry.publishServiceEventPrivileged(ServiceRegistry.java:819)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistry.publishServiceEvent(ServiceRegistry.java:771)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistrationImpl.register(ServiceRegistrationImpl.java:130)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistry.registerService(ServiceRegistry.java:214)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.registerService(BundleContextImpl.java:433)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.registerService(BundleContextImpl.java:451)
	at org.wso2.carbon.server.admin.internal.ServerAdminServiceComponent.activate(ServerAdminServiceComponent.java:106)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.eclipse.equinox.internal.ds.model.ServiceComponent.activate(ServiceComponent.java:260)
	at org.eclipse.equinox.internal.ds.model.ServiceComponentProp.activate(ServiceComponentProp.java:146)
	at org.eclipse.equinox.internal.ds.model.ServiceComponentProp.build(ServiceComponentProp.java:347)
	at org.eclipse.equinox.internal.ds.InstanceProcess.buildComponent(InstanceProcess.java:620)
	at org.eclipse.equinox.internal.ds.InstanceProcess.buildComponents(InstanceProcess.java:197)
	at org.eclipse.equinox.internal.ds.Resolver.getEligible(Resolver.java:343)
	at org.eclipse.equinox.internal.ds.SCRManager.serviceChanged(SCRManager.java:222)
	at org.eclipse.osgi.internal.serviceregistry.FilteredServiceListener.serviceChanged(FilteredServiceListener.java:107)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.dispatchEvent(BundleContextImpl.java:861)
	at org.eclipse.osgi.framework.eventmgr.EventManager.dispatchEvent(EventManager.java:230)
	at org.eclipse.osgi.framework.eventmgr.ListenerQueue.dispatchEventSynchronous(ListenerQueue.java:148)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistry.publishServiceEventPrivileged(ServiceRegistry.java:819)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistry.publishServiceEvent(ServiceRegistry.java:771)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistrationImpl.register(ServiceRegistrationImpl.java:130)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistry.registerService(ServiceRegistry.java:214)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.registerService(BundleContextImpl.java:433)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.registerService(BundleContextImpl.java:451)
	at org.wso2.carbon.core.init.CarbonServerManager.initializeCarbon(CarbonServerManager.java:517)
	at org.wso2.carbon.core.init.CarbonServerManager.start(CarbonServerManager.java:219)
	at org.wso2.carbon.core.internal.CarbonCoreServiceComponent.activate(CarbonCoreServiceComponent.java:77)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.eclipse.equinox.internal.ds.model.ServiceComponent.activate(ServiceComponent.java:260)
	at org.eclipse.equinox.internal.ds.model.ServiceComponentProp.activate(ServiceComponentProp.java:146)
	at org.eclipse.equinox.internal.ds.model.ServiceComponentProp.build(ServiceComponentProp.java:347)
	at org.eclipse.equinox.internal.ds.InstanceProcess.buildComponent(InstanceProcess.java:620)
	at org.eclipse.equinox.internal.ds.InstanceProcess.buildComponents(InstanceProcess.java:197)
	at org.eclipse.equinox.internal.ds.Resolver.getEligible(Resolver.java:343)
	at org.eclipse.equinox.internal.ds.SCRManager.serviceChanged(SCRManager.java:222)
	at org.eclipse.osgi.internal.serviceregistry.FilteredServiceListener.serviceChanged(FilteredServiceListener.java:107)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.dispatchEvent(BundleContextImpl.java:861)
	at org.eclipse.osgi.framework.eventmgr.EventManager.dispatchEvent(EventManager.java:230)
	at org.eclipse.osgi.framework.eventmgr.ListenerQueue.dispatchEventSynchronous(ListenerQueue.java:148)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistry.publishServiceEventPrivileged(ServiceRegistry.java:819)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistry.publishServiceEvent(ServiceRegistry.java:771)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistrationImpl.register(ServiceRegistrationImpl.java:130)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistry.registerService(ServiceRegistry.java:214)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.registerService(BundleContextImpl.java:433)
	at org.eclipse.equinox.http.servlet.internal.Activator.registerHttpService(Activator.java:81)
	at org.eclipse.equinox.http.servlet.internal.Activator.addProxyServlet(Activator.java:60)
	at org.eclipse.equinox.http.servlet.internal.ProxyServlet.init(ProxyServlet.java:40)
	at org.wso2.carbon.tomcat.ext.servlet.DelegationServlet.init(DelegationServlet.java:38)
	at org.apache.catalina.core.StandardWrapper.initServlet(StandardWrapper.java:1267)
	at org.apache.catalina.core.StandardWrapper.loadServlet(StandardWrapper.java:1186)
	at org.apache.catalina.core.StandardWrapper.load(StandardWrapper.java:1081)
	at org.apache.catalina.core.StandardContext.loadOnStartup(StandardContext.java:5027)
	at org.apache.catalina.core.StandardContext.startInternal(StandardContext.java:5314)
	at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150)
	at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1559)
	at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1549)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.net.BindException: Address already in use
	at java.net.PlainSocketImpl.socketBind(Native Method)
	at java.net.PlainSocketImpl.bind(PlainSocketImpl.java:383)
	at java.net.ServerSocket.bind(ServerSocket.java:328)
	at java.net.ServerSocket.<init>(ServerSocket.java:194)
	at java.net.ServerSocket.<init>(ServerSocket.java:106)
	at sun.rmi.transport.proxy.RMIDirectSocketFactory.createServerSocket(RMIDirectSocketFactory.java:27)
	at sun.rmi.transport.proxy.RMIMasterSocketFactory.createServerSocket(RMIMasterSocketFactory.java:333)
	at sun.rmi.transport.tcp.TCPEndpoint.newServerSocket(TCPEndpoint.java:649)
	at sun.rmi.transport.tcp.TCPTransport.listen(TCPTransport.java:299)
	... 82 more
TID: [0] [BAM] [2014-09-17 17:11:15,494] ERROR {org.wso2.carbon.core.init.JMXServerManager} -  Could not initialize RMI server {org.wso2.carbon.core.init.JMXServerManager}
java.rmi.server.ExportException: Port already in use: 11111; nested exception is: 
	java.net.BindException: Address already in use
	at sun.rmi.transport.tcp.TCPTransport.listen(TCPTransport.java:310)
	at sun.rmi.transport.tcp.TCPTransport.exportObject(TCPTransport.java:218)
	at sun.rmi.transport.tcp.TCPEndpoint.exportObject(TCPEndpoint.java:393)
	at sun.rmi.transport.LiveRef.exportObject(LiveRef.java:129)
	at sun.rmi.server.UnicastServerRef.exportObject(UnicastServerRef.java:188)
	at java.rmi.server.UnicastRemoteObject.exportObject(UnicastRemoteObject.java:293)
	at java.rmi.server.UnicastRemoteObject.exportObject(UnicastRemoteObject.java:256)
	at javax.management.remote.rmi.RMIJRMPServerImpl.export(RMIJRMPServerImpl.java:82)
	at javax.management.remote.rmi.RMIJRMPServerImpl.export(RMIJRMPServerImpl.java:75)
	at javax.management.remote.rmi.RMIConnectorServer.start(RMIConnectorServer.java:388)
	at org.wso2.carbon.core.init.JMXServerManager.startJMXService(JMXServerManager.java:121)
	at org.wso2.carbon.core.internal.StartupFinalizerServiceComponent.completeInitialization(StartupFinalizerServiceComponent.java:195)
	at org.wso2.carbon.core.internal.StartupFinalizerServiceComponent.serviceChanged(StartupFinalizerServiceComponent.java:280)
	at org.eclipse.osgi.internal.serviceregistry.FilteredServiceListener.serviceChanged(FilteredServiceListener.java:107)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.dispatchEvent(BundleContextImpl.java:861)
	at org.eclipse.osgi.framework.eventmgr.EventManager.dispatchEvent(EventManager.java:230)
	at org.eclipse.osgi.framework.eventmgr.ListenerQueue.dispatchEventSynchronous(ListenerQueue.java:148)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistry.publishServiceEventPrivileged(ServiceRegistry.java:819)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistry.publishServiceEvent(ServiceRegistry.java:771)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistrationImpl.register(ServiceRegistrationImpl.java:130)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistry.registerService(ServiceRegistry.java:214)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.registerService(BundleContextImpl.java:433)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.registerService(BundleContextImpl.java:451)
	at org.wso2.carbon.server.admin.internal.ServerAdminServiceComponent.activate(ServerAdminServiceComponent.java:106)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.eclipse.equinox.internal.ds.model.ServiceComponent.activate(ServiceComponent.java:260)
	at org.eclipse.equinox.internal.ds.model.ServiceComponentProp.activate(ServiceComponentProp.java:146)
	at org.eclipse.equinox.internal.ds.model.ServiceComponentProp.build(ServiceComponentProp.java:347)
	at org.eclipse.equinox.internal.ds.InstanceProcess.buildComponent(InstanceProcess.java:620)
	at org.eclipse.equinox.internal.ds.InstanceProcess.buildComponents(InstanceProcess.java:197)
	at org.eclipse.equinox.internal.ds.Resolver.getEligible(Resolver.java:343)
	at org.eclipse.equinox.internal.ds.SCRManager.serviceChanged(SCRManager.java:222)
	at org.eclipse.osgi.internal.serviceregistry.FilteredServiceListener.serviceChanged(FilteredServiceListener.java:107)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.dispatchEvent(BundleContextImpl.java:861)
	at org.eclipse.osgi.framework.eventmgr.EventManager.dispatchEvent(EventManager.java:230)
	at org.eclipse.osgi.framework.eventmgr.ListenerQueue.dispatchEventSynchronous(ListenerQueue.java:148)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistry.publishServiceEventPrivileged(ServiceRegistry.java:819)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistry.publishServiceEvent(ServiceRegistry.java:771)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistrationImpl.register(ServiceRegistrationImpl.java:130)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistry.registerService(ServiceRegistry.java:214)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.registerService(BundleContextImpl.java:433)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.registerService(BundleContextImpl.java:451)
	at org.wso2.carbon.core.init.CarbonServerManager.initializeCarbon(CarbonServerManager.java:517)
	at org.wso2.carbon.core.init.CarbonServerManager.start(CarbonServerManager.java:219)
	at org.wso2.carbon.core.internal.CarbonCoreServiceComponent.activate(CarbonCoreServiceComponent.java:77)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.eclipse.equinox.internal.ds.model.ServiceComponent.activate(ServiceComponent.java:260)
	at org.eclipse.equinox.internal.ds.model.ServiceComponentProp.activate(ServiceComponentProp.java:146)
	at org.eclipse.equinox.internal.ds.model.ServiceComponentProp.build(ServiceComponentProp.java:347)
	at org.eclipse.equinox.internal.ds.InstanceProcess.buildComponent(InstanceProcess.java:620)
	at org.eclipse.equinox.internal.ds.InstanceProcess.buildComponents(InstanceProcess.java:197)
	at org.eclipse.equinox.internal.ds.Resolver.getEligible(Resolver.java:343)
	at org.eclipse.equinox.internal.ds.SCRManager.serviceChanged(SCRManager.java:222)
	at org.eclipse.osgi.internal.serviceregistry.FilteredServiceListener.serviceChanged(FilteredServiceListener.java:107)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.dispatchEvent(BundleContextImpl.java:861)
	at org.eclipse.osgi.framework.eventmgr.EventManager.dispatchEvent(EventManager.java:230)
	at org.eclipse.osgi.framework.eventmgr.ListenerQueue.dispatchEventSynchronous(ListenerQueue.java:148)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistry.publishServiceEventPrivileged(ServiceRegistry.java:819)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistry.publishServiceEvent(ServiceRegistry.java:771)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistrationImpl.register(ServiceRegistrationImpl.java:130)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistry.registerService(ServiceRegistry.java:214)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.registerService(BundleContextImpl.java:433)
	at org.eclipse.equinox.http.servlet.internal.Activator.registerHttpService(Activator.java:81)
	at org.eclipse.equinox.http.servlet.internal.Activator.addProxyServlet(Activator.java:60)
	at org.eclipse.equinox.http.servlet.internal.ProxyServlet.init(ProxyServlet.java:40)
	at org.wso2.carbon.tomcat.ext.servlet.DelegationServlet.init(DelegationServlet.java:38)
	at org.apache.catalina.core.StandardWrapper.initServlet(StandardWrapper.java:1267)
	at org.apache.catalina.core.StandardWrapper.loadServlet(StandardWrapper.java:1186)
	at org.apache.catalina.core.StandardWrapper.load(StandardWrapper.java:1081)
	at org.apache.catalina.core.StandardContext.loadOnStartup(StandardContext.java:5027)
	at org.apache.catalina.core.StandardContext.startInternal(StandardContext.java:5314)
	at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150)
	at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1559)
	at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1549)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.net.BindException: Address already in use
	at java.net.PlainSocketImpl.socketBind(Native Method)
	at java.net.PlainSocketImpl.bind(PlainSocketImpl.java:383)
	at java.net.ServerSocket.bind(ServerSocket.java:328)
	at java.net.ServerSocket.<init>(ServerSocket.java:194)
	at java.net.ServerSocket.<init>(ServerSocket.java:106)
	at sun.rmi.transport.proxy.RMIDirectSocketFactory.createServerSocket(RMIDirectSocketFactory.java:27)
	at sun.rmi.transport.proxy.RMIMasterSocketFactory.createServerSocket(RMIMasterSocketFactory.java:333)
	at sun.rmi.transport.tcp.TCPEndpoint.newServerSocket(TCPEndpoint.java:649)
	at sun.rmi.transport.tcp.TCPTransport.listen(TCPTransport.java:299)
	... 84 more
TID: [0] [BAM] [2014-09-17 17:11:15,498]  INFO {org.wso2.carbon.bam.toolbox.deployer.internal.ServerStartUpInspector} -  BAM Toolbox is ready to do deployments {org.wso2.carbon.bam.toolbox.deployer.internal.ServerStartUpInspector}
TID: [0] [BAM] [2014-09-17 17:11:15,500]  INFO {org.wso2.carbon.bam.toolbox.deployer.core.BAMToolBoxDeployer} -  /home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/repository/deployment/server/bam-toolbox {org.wso2.carbon.bam.toolbox.deployer.core.BAMToolBoxDeployer}
TID: [0] [BAM] [2014-09-17 17:11:15,501]  INFO {org.wso2.carbon.bam.toolbox.deployer.core.BAMToolBoxDeployer} -  Deploying file:/home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/repository/deployment/server/bam-toolbox/Message_Tracing.tbox {org.wso2.carbon.bam.toolbox.deployer.core.BAMToolBoxDeployer}
TID: [0] [BAM] [2014-09-17 17:11:15,509]  INFO {org.wso2.carbon.bam.toolbox.deployer.core.BAMArtifactProcessor} -  No Analytics found for toolbox :Message_Tracing {org.wso2.carbon.bam.toolbox.deployer.core.BAMArtifactProcessor}
TID: [0] [BAM] [2014-09-17 17:11:15,510]  INFO {org.wso2.carbon.bam.toolbox.deployer.core.BAMArtifactProcessor} -  No jaggery artifacts found {org.wso2.carbon.bam.toolbox.deployer.core.BAMArtifactProcessor}
TID: [0] [BAM] [2014-09-17 17:11:15,512]  INFO {org.wso2.carbon.databridge.core.DataBridge} -  admin connected {org.wso2.carbon.databridge.core.DataBridge}
TID: [0] [BAM] [2014-09-17 17:11:15,543]  INFO {org.wso2.carbon.databridge.persistence.cassandra.datastore.ClusterFactory} -  Initializing cluster {org.wso2.carbon.databridge.persistence.cassandra.datastore.ClusterFactory}
TID: [0] [BAM] [2014-09-17 17:11:16,471]  INFO {org.wso2.carbon.databridge.persistence.cassandra.datastore.CassandraConnector} -  Saving Stream Definition : BAM_MESSAGE_TRACE_FILTER:1.0.0 {org.wso2.carbon.databridge.persistence.cassandra.datastore.CassandraConnector}
TID: [0] [BAM] [2014-09-17 17:11:17,487]  INFO {org.wso2.carbon.databridge.core.DataBridge} -  admin connected {org.wso2.carbon.databridge.core.DataBridge}
TID: [0] [BAM] [2014-09-17 17:11:17,702]  INFO {org.wso2.carbon.databridge.persistence.cassandra.datastore.CassandraConnector} -  Saving Stream Definition : BAM_MESSAGE_TRACE:1.0.0 {org.wso2.carbon.databridge.persistence.cassandra.datastore.CassandraConnector}
TID: [0] [BAM] [2014-09-17 17:11:18,857]  INFO {org.wso2.carbon.bam.toolbox.deployer.core.BAMToolBoxDeployer} -  Deployed successfully file: /home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/repository/deployment/server/bam-toolbox/Message_Tracing.tbox {org.wso2.carbon.bam.toolbox.deployer.core.BAMToolBoxDeployer}
TID: [0] [BAM] [2014-09-17 17:11:18,862]  INFO {org.wso2.carbon.core.internal.StartupFinalizerServiceComponent} -  Server           :  WSO2 Business Activity Monitor-2.4.0 {org.wso2.carbon.core.internal.StartupFinalizerServiceComponent}
TID: [0] [BAM] [2014-09-17 17:11:18,863]  INFO {org.wso2.carbon.core.internal.StartupFinalizerServiceComponent} -  WSO2 Carbon started in 17 sec {org.wso2.carbon.core.internal.StartupFinalizerServiceComponent}
TID: [0] [BAM] [2014-09-17 17:11:19,991]  INFO {org.wso2.carbon.dashboard.common.oauth.GSOAuthModule} -  Using random key for OAuth client-side state encryption {org.wso2.carbon.dashboard.common.oauth.GSOAuthModule}
TID: [0] [BAM] [2014-09-17 17:11:20,298]  INFO {org.wso2.carbon.ui.internal.CarbonUIServiceComponent} -  Mgt Console URL  : https://10.100.5.90:9443/carbon/ {org.wso2.carbon.ui.internal.CarbonUIServiceComponent}
TID: [0] [BAM] [2014-09-17 17:11:20,299]  INFO {org.wso2.carbon.ui.internal.CarbonUIServiceComponent} -  Gadget Server Default Context : http://10.100.5.90:9763/portal {org.wso2.carbon.ui.internal.CarbonUIServiceComponent}
TID: [0] [BAM] [2014-09-17 17:11:20,557]  INFO {org.wso2.carbon.databridge.core.DataBridge} -  admin connected {org.wso2.carbon.databridge.core.DataBridge}
TID: [0] [BAM] [2014-09-17 17:11:54,159]  INFO {org.apache.cassandra.thrift.CassandraDaemon} -  Stop listening to thrift clients {org.apache.cassandra.thrift.CassandraDaemon}
TID: [0] [BAM] [2014-09-17 17:11:54,159]  INFO {org.wso2.carbon.core.init.CarbonServerManager} -  Shutdown hook triggered.... {org.wso2.carbon.core.init.CarbonServerManager}
TID: [0] [BAM] [2014-09-17 17:11:54,161]  INFO {org.wso2.carbon.core.init.CarbonServerManager} -  Gracefully shutting down WSO2 Business Activity Monitor... {org.wso2.carbon.core.init.CarbonServerManager}
TID: [0] [BAM] [2014-09-17 17:11:54,162]  INFO {org.apache.cassandra.gms.Gossiper} -  Announcing shutdown {org.apache.cassandra.gms.Gossiper}
TID: [0] [BAM] [2014-09-17 17:11:54,165]  INFO {org.wso2.carbon.core.ServerManagement} -  Starting to switch to maintenance mode... {org.wso2.carbon.core.ServerManagement}
TID: [0] [BAM] [2014-09-17 17:11:54,166]  INFO {org.wso2.carbon.core.ServerManagement} -  Stopped all transport listeners {org.wso2.carbon.core.ServerManagement}
TID: [0] [BAM] [2014-09-17 17:11:54,166]  INFO {org.wso2.carbon.core.ServerManagement} -  Waiting for request service completion... {org.wso2.carbon.core.ServerManagement}
TID: [0] [BAM] [2014-09-17 17:11:54,169]  INFO {org.wso2.carbon.core.ServerManagement} -  All requests have been served. {org.wso2.carbon.core.ServerManagement}
TID: [0] [BAM] [2014-09-17 17:11:54,169]  INFO {org.wso2.carbon.core.ServerManagement} -  Waiting for deployment completion... {org.wso2.carbon.core.ServerManagement}
TID: [0] [BAM] [2014-09-17 17:11:54,197]  INFO {org.wso2.carbon.webapp.mgt.WebApplication} -  Unloaded webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/STRATOS_ROOT] {org.wso2.carbon.webapp.mgt.WebApplication}
TID: [0] [BAM] [2014-09-17 17:11:54,198]  INFO {org.springframework.web.context.support.XmlWebApplicationContext} -  Closing Root WebApplicationContext: startup date [Wed Sep 17 17:11:11 IST 2014]; root of context hierarchy {org.springframework.web.context.support.XmlWebApplicationContext}
TID: [0] [BAM] [2014-09-17 17:11:54,202]  INFO {org.springframework.beans.factory.support.DefaultListableBeanFactory} -  Destroying singletons in org.springframework.beans.factory.support.DefaultListableBeanFactory@332b24bc: defining beans [cxf,org.apache.cxf.bus.spring.BusWiringBeanFactoryPostProcessor,org.apache.cxf.bus.spring.Jsr250BeanPostProcessor,org.apache.cxf.bus.spring.BusExtensionPostProcessor,dataReceiverStreamsService,dataReceiverStreamService,streamsBean,streamBean]; root of factory hierarchy {org.springframework.beans.factory.support.DefaultListableBeanFactory}
TID: [0] [BAM] [2014-09-17 17:11:54,218]  INFO {org.wso2.carbon.webapp.mgt.WebApplication} -  Unloaded webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/datareceiver] {org.wso2.carbon.webapp.mgt.WebApplication}
TID: [0] [BAM] [2014-09-17 17:11:54,236]  INFO {org.wso2.carbon.webapp.mgt.WebApplication} -  Unloaded webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/bamdashboards] {org.wso2.carbon.webapp.mgt.WebApplication}
TID: [0] [BAM] [2014-09-17 17:11:54,250]  INFO {org.wso2.carbon.webapp.mgt.WebApplication} -  Unloaded webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/activitymonitoring] {org.wso2.carbon.webapp.mgt.WebApplication}
TID: [0] [BAM] [2014-09-17 17:11:54,251]  INFO {org.wso2.carbon.core.ServerManagement} -  All deployment tasks have been completed. {org.wso2.carbon.core.ServerManagement}
TID: [0] [BAM] [2014-09-17 17:11:54,251]  INFO {org.wso2.carbon.core.ServerManagement} -  Waiting for server task completion... {org.wso2.carbon.core.ServerManagement}
TID: [0] [BAM] [2014-09-17 17:11:54,253]  INFO {org.wso2.carbon.core.ServerManagement} -  All server tasks have been completed. {org.wso2.carbon.core.ServerManagement}
TID: [0] [BAM] [2014-09-17 17:11:54,253]  INFO {org.wso2.carbon.core.init.CarbonServerManager} -  Shutting down WSO2 Business Activity Monitor... {org.wso2.carbon.core.init.CarbonServerManager}
TID: [0] [BAM] [2014-09-17 17:11:54,253]  INFO {org.wso2.carbon.core.init.CarbonServerManager} -  Shutting down OSGi framework... {org.wso2.carbon.core.init.CarbonServerManager}
TID: [0] [BAM] [2014-09-17 17:11:54,274]  INFO {org.wso2.carbon.databridge.receiver.thrift.internal.ThriftDataReceiverDS} -  Thrift server shutting down... {org.wso2.carbon.databridge.receiver.thrift.internal.ThriftDataReceiverDS}
TID: [0] [BAM] [2014-09-17 17:11:54,443]  INFO {org.wso2.carbon.core.init.CarbonServerManager} -  Stopping CarbonServerManager... {org.wso2.carbon.core.init.CarbonServerManager}
TID: [0] [BAM] [2014-09-17 17:11:54,445]  INFO {org.apache.axis2.transport.tcp.TCPTransportSender} -  TCP Sender Shutdown {org.apache.axis2.transport.tcp.TCPTransportSender}
TID: [0] [BAM] [2014-09-17 17:11:54,458]  INFO {org.wso2.carbon.tomcat.ext.internal.CarbonTomcatServiceComponent} -  Stopping the carbon web-app registered under : / {org.wso2.carbon.tomcat.ext.internal.CarbonTomcatServiceComponent}
TID: [0] [BAM] [2014-09-17 17:11:54,916]  INFO {org.wso2.carbon.core.init.CarbonServerManager} -  Shutdown complete {org.wso2.carbon.core.init.CarbonServerManager}
TID: [0] [BAM] [2014-09-17 17:11:54,917]  INFO {org.wso2.carbon.core.init.CarbonServerManager} -  Halting JVM {org.wso2.carbon.core.init.CarbonServerManager}
TID: [0] [BAM] [2014-09-17 17:11:55,164]  INFO {org.apache.cassandra.net.MessagingService} -  Waiting for messaging service to quiesce {org.apache.cassandra.net.MessagingService}
TID: [0] [BAM] [2014-09-17 17:11:55,165]  INFO {org.apache.cassandra.net.MessagingService} -  MessagingService shutting down server thread. {org.apache.cassandra.net.MessagingService}
TID: [0] [BAM] [2014-09-17 17:12:22,018]  INFO {org.wso2.carbon.core.internal.CarbonCoreActivator} -  Starting WSO2 Carbon... {org.wso2.carbon.core.internal.CarbonCoreActivator}
TID: [0] [BAM] [2014-09-17 17:12:22,019]  INFO {org.wso2.carbon.core.internal.CarbonCoreActivator} -  Operating System : Linux 3.13.0-24-generic, amd64 {org.wso2.carbon.core.internal.CarbonCoreActivator}
TID: [0] [BAM] [2014-09-17 17:12:22,019]  INFO {org.wso2.carbon.core.internal.CarbonCoreActivator} -  Java Home        : /usr/lib/jvm/java-6-oracle/jre {org.wso2.carbon.core.internal.CarbonCoreActivator}
TID: [0] [BAM] [2014-09-17 17:12:22,019]  INFO {org.wso2.carbon.core.internal.CarbonCoreActivator} -  Java Version     : 1.6.0_45 {org.wso2.carbon.core.internal.CarbonCoreActivator}
TID: [0] [BAM] [2014-09-17 17:12:22,019]  INFO {org.wso2.carbon.core.internal.CarbonCoreActivator} -  Java VM          : Java HotSpot(TM) 64-Bit Server VM 20.45-b01,Sun Microsystems Inc. {org.wso2.carbon.core.internal.CarbonCoreActivator}
TID: [0] [BAM] [2014-09-17 17:12:22,019]  INFO {org.wso2.carbon.core.internal.CarbonCoreActivator} -  Carbon Home      : /home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0 {org.wso2.carbon.core.internal.CarbonCoreActivator}
TID: [0] [BAM] [2014-09-17 17:12:22,019]  INFO {org.wso2.carbon.core.internal.CarbonCoreActivator} -  Java Temp Dir    : /home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/tmp {org.wso2.carbon.core.internal.CarbonCoreActivator}
TID: [0] [BAM] [2014-09-17 17:12:22,019]  INFO {org.wso2.carbon.core.internal.CarbonCoreActivator} -  User             : denuwanthi, en-US, Asia/Colombo {org.wso2.carbon.core.internal.CarbonCoreActivator}
TID: [0] [BAM] [2014-09-17 17:12:22,071]  WARN {org.wso2.carbon.core.bootup.validator.util.ValidationResultPrinter} -  The default keystore (wso2carbon.jks) is currently being used. To maximize security when deploying to a production environment, configure a new keystore with a unique password in the production server profile. {org.wso2.carbon.core.bootup.validator.util.ValidationResultPrinter}
TID: [0] [BAM] [2014-09-17 17:12:22,096]  INFO {org.wso2.carbon.databridge.agent.thrift.AgentHolder} -  Agent created ! {org.wso2.carbon.databridge.agent.thrift.AgentHolder}
TID: [0] [BAM] [2014-09-17 17:12:22,154]  INFO {org.wso2.carbon.databridge.agent.thrift.internal.AgentDS} -  Successfully deployed Agent Client {org.wso2.carbon.databridge.agent.thrift.internal.AgentDS}
TID: [0] [BAM] [2014-09-17 17:12:23,282]  INFO {org.wso2.carbon.bam.toolbox.deployer.internal.DataBridgeRecieverServiceComponent} -  Successfully setted data bridge reciever service {org.wso2.carbon.bam.toolbox.deployer.internal.DataBridgeRecieverServiceComponent}
TID: [0] [BAM] [2014-09-17 17:12:23,289]  INFO {org.wso2.carbon.databridge.core.internal.DataBridgeDS} -  Successfully deployed Agent Server  {org.wso2.carbon.databridge.core.internal.DataBridgeDS}
TID: [0] [BAM] [2014-09-17 17:12:23,397]  INFO {org.wso2.carbon.registry.core.jdbc.EmbeddedRegistryService} -  Configured Registry in 45ms {org.wso2.carbon.registry.core.jdbc.EmbeddedRegistryService}
TID: [0] [BAM] [2014-09-17 17:12:23,487]  INFO {org.wso2.carbon.registry.core.internal.RegistryCoreServiceComponent} -  Registry Mode    : READ-WRITE {org.wso2.carbon.registry.core.internal.RegistryCoreServiceComponent}
TID: [0] [BAM] [2014-09-17 17:12:24,064]  INFO {org.wso2.carbon.user.core.internal.UserStoreMgtDSComponent} -  Carbon UserStoreMgtDSComponent activated successfully. {org.wso2.carbon.user.core.internal.UserStoreMgtDSComponent}
TID: [0] [BAM] [2014-09-17 17:12:24,518]  INFO {org.apache.cassandra.net.MessagingService} -  Starting Messaging Service on port 7001 {org.apache.cassandra.net.MessagingService}
TID: [0] [BAM] [2014-09-17 17:12:24,580]  INFO {org.apache.cassandra.thrift.CassandraDaemon} -  Binding thrift service to localhost/127.0.0.1:9161 {org.apache.cassandra.thrift.CassandraDaemon}
TID: [0] [BAM] [2014-09-17 17:12:24,582]  INFO {org.apache.cassandra.thrift.CassandraDaemon} -  Using TFastFramedTransport with a max frame size of 15728640 bytes. {org.apache.cassandra.thrift.CassandraDaemon}
TID: [0] [BAM] [2014-09-17 17:12:24,584]  INFO {org.apache.cassandra.thrift.CassandraDaemon} -  Using synchronous/threadpool thrift server on localhost/127.0.0.1 : 9161 {org.apache.cassandra.thrift.CassandraDaemon}
TID: [0] [BAM] [2014-09-17 17:12:24,584]  INFO {org.wso2.carbon.cassandra.server.CassandraServerController} -  Cassandra Server Controller Thread was destroyed successfully {org.wso2.carbon.cassandra.server.CassandraServerController}
TID: [0] [BAM] [2014-09-17 17:12:24,584]  INFO {org.apache.cassandra.thrift.CassandraDaemon} -  Listening for thrift clients... {org.apache.cassandra.thrift.CassandraDaemon}
TID: [0] [BAM] [2014-09-17 17:12:28,509]  INFO {org.apache.axis2.deployment.ClusterBuilder} -  Clustering has been disabled {org.apache.axis2.deployment.ClusterBuilder}
TID: [0] [BAM] [2014-09-17 17:12:28,662]  INFO {org.wso2.carbon.identity.user.store.configuration.deployer.UserStoreConfigurationDeployer} -  User Store Configuration Deployer initiated. {org.wso2.carbon.identity.user.store.configuration.deployer.UserStoreConfigurationDeployer}
TID: [0] [BAM] [2014-09-17 17:12:28,696]  INFO {org.wso2.carbon.stratos.landing.page.deployer.LandingPageWebappDeployer} -  Deployed product landing page webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/home] {org.wso2.carbon.stratos.landing.page.deployer.LandingPageWebappDeployer}
TID: [0] [BAM] [2014-09-17 17:12:28,700]  INFO {org.apache.axis2.transport.tcp.TCPTransportSender} -  TCP Sender started {org.apache.axis2.transport.tcp.TCPTransportSender}
TID: [0] [BAM] [2014-09-17 17:12:28,730]  INFO {org.wso2.carbon.webapp.mgt.TomcatGenericWebappsDeployer} -  Deployed webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/STRATOS_ROOT].File[/home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/repository/deployment/server/webapps/STRATOS_ROOT] {org.wso2.carbon.webapp.mgt.TomcatGenericWebappsDeployer}
TID: [0] [BAM] [2014-09-17 17:12:29,325]  INFO {org.springframework.web.context.support.XmlWebApplicationContext} -  Refreshing Root WebApplicationContext: startup date [Wed Sep 17 17:12:29 IST 2014]; root of context hierarchy {org.springframework.web.context.support.XmlWebApplicationContext}
TID: [0] [BAM] [2014-09-17 17:12:29,363]  INFO {org.springframework.beans.factory.xml.XmlBeanDefinitionReader} -  Loading XML bean definitions from class path resource [META-INF/cxf/cxf.xml] {org.springframework.beans.factory.xml.XmlBeanDefinitionReader}
TID: [0] [BAM] [2014-09-17 17:12:29,426]  INFO {org.springframework.beans.factory.xml.XmlBeanDefinitionReader} -  Loading XML bean definitions from URL [jndi:/localhost/datareceiver/WEB-INF/cxf-servlet.xml] {org.springframework.beans.factory.xml.XmlBeanDefinitionReader}
TID: [0] [BAM] [2014-09-17 17:12:29,659]  INFO {org.springframework.beans.factory.support.DefaultListableBeanFactory} -  Pre-instantiating singletons in org.springframework.beans.factory.support.DefaultListableBeanFactory@59311a3e: defining beans [cxf,org.apache.cxf.bus.spring.BusWiringBeanFactoryPostProcessor,org.apache.cxf.bus.spring.Jsr250BeanPostProcessor,org.apache.cxf.bus.spring.BusExtensionPostProcessor,dataReceiverStreamsService,dataReceiverStreamService,streamsBean,streamBean]; root of factory hierarchy {org.springframework.beans.factory.support.DefaultListableBeanFactory}
TID: [0] [BAM] [2014-09-17 17:12:29,928]  INFO {org.apache.cxf.endpoint.ServerImpl} -  Setting the server's publish address to be /streams {org.apache.cxf.endpoint.ServerImpl}
TID: [0] [BAM] [2014-09-17 17:12:29,977]  INFO {org.apache.cxf.endpoint.ServerImpl} -  Setting the server's publish address to be /stream {org.apache.cxf.endpoint.ServerImpl}
TID: [0] [BAM] [2014-09-17 17:12:29,982]  INFO {org.wso2.carbon.webapp.mgt.TomcatGenericWebappsDeployer} -  Deployed webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/datareceiver].File[/home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/repository/deployment/server/webapps/datareceiver.war] {org.wso2.carbon.webapp.mgt.TomcatGenericWebappsDeployer}
TID: [0] [BAM] [2014-09-17 17:12:30,579]  INFO {org.jaggeryjs.jaggery.app.mgt.TomcatJaggeryWebappsDeployer} -  Deployed webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/bamdashboards].File[/home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/repository/deployment/server/jaggeryapps/bamdashboards] {org.jaggeryjs.jaggery.app.mgt.TomcatJaggeryWebappsDeployer}
TID: [0] [BAM] [2014-09-17 17:12:30,623]  INFO {org.jaggeryjs.jaggery.app.mgt.TomcatJaggeryWebappsDeployer} -  Deployed webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/activitymonitoring].File[/home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/repository/deployment/server/jaggeryapps/activitymonitoring] {org.jaggeryjs.jaggery.app.mgt.TomcatJaggeryWebappsDeployer}
TID: [0] [BAM] [2014-09-17 17:12:30,707]  INFO {org.apache.axis2.deployment.ModuleDeployer} -  Deploying module: rampart-1.6.1-wso2v10 - file:/home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/repository/deployment/client/modules/rampart-1.6.1-wso2v10.mar {org.apache.axis2.deployment.ModuleDeployer}
TID: [0] [BAM] [2014-09-17 17:12:30,711]  INFO {org.apache.axis2.deployment.ModuleDeployer} -  Deploying module: addressing-1.6.1-wso2v10 - file:/home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/repository/deployment/client/modules/addressing-1.6.1-wso2v10.mar {org.apache.axis2.deployment.ModuleDeployer}
TID: [0] [BAM] [2014-09-17 17:12:30,713]  INFO {org.apache.axis2.transport.tcp.TCPTransportSender} -  TCP Sender started {org.apache.axis2.transport.tcp.TCPTransportSender}
TID: [0] [BAM] [2014-09-17 17:12:30,933]  INFO {org.wso2.carbon.core.deployment.DeploymentInterceptor} -  Deploying Axis2 service: BAMMessageStoreService {super-tenant} {org.wso2.carbon.core.deployment.DeploymentInterceptor}
TID: [0] [BAM] [2014-09-17 17:12:30,989]  INFO {org.apache.axis2.deployment.DeploymentEngine} -  Deploying Web service: org.wso2.carbon.bam.messagestore -  {org.apache.axis2.deployment.DeploymentEngine}
TID: [0] [BAM] [2014-09-17 17:12:31,190]  INFO {org.wso2.carbon.core.deployment.DeploymentInterceptor} -  Deploying Axis2 service: CassandraSearchAdmin {super-tenant} {org.wso2.carbon.core.deployment.DeploymentInterceptor}
TID: [0] [BAM] [2014-09-17 17:12:31,377]  INFO {org.apache.axis2.deployment.DeploymentEngine} -  Deploying Web service: org.wso2.carbon.cassandra.search.mgt -  {org.apache.axis2.deployment.DeploymentEngine}
TID: [0] [BAM] [2014-09-17 17:12:32,099]  INFO {org.wso2.carbon.core.init.CarbonServerManager} -  Repository       : /home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/repository/deployment/server/ {org.wso2.carbon.core.init.CarbonServerManager}
TID: [0] [BAM] [2014-09-17 17:12:32,122]  INFO {org.wso2.carbon.bam.toolbox.deployer.internal.BAMToolBoxDeployerComponent} -  Successfully Started BAM Toolbox Deployer {org.wso2.carbon.bam.toolbox.deployer.internal.BAMToolBoxDeployerComponent}
TID: [0] [BAM] [2014-09-17 17:12:32,156]  INFO {org.wso2.carbon.core.internal.permission.update.PermissionUpdater} -  Permission cache updated for tenant -1234 {org.wso2.carbon.core.internal.permission.update.PermissionUpdater}
TID: [0] [BAM] [2014-09-17 17:12:32,169]  INFO {org.wso2.carbon.bam.toolbox.deployer.internal.DashboardServiceComponent} -  Successfully setted dashboard services {org.wso2.carbon.bam.toolbox.deployer.internal.DashboardServiceComponent}
TID: [0] [BAM] [2014-09-17 17:12:32,264]  INFO {org.wso2.carbon.databridge.receiver.thrift.internal.ThriftDataReceiver} -  Thrift Server started at 10.100.5.90 {org.wso2.carbon.databridge.receiver.thrift.internal.ThriftDataReceiver}
TID: [0] [BAM] [2014-09-17 17:12:32,269]  INFO {org.wso2.carbon.databridge.receiver.thrift.internal.ThriftDataReceiver} -  Thrift SSL port : 7712 {org.wso2.carbon.databridge.receiver.thrift.internal.ThriftDataReceiver}
TID: [0] [BAM] [2014-09-17 17:12:32,326]  INFO {org.wso2.carbon.databridge.receiver.thrift.internal.ThriftDataReceiver} -  Thrift port : 7612 {org.wso2.carbon.databridge.receiver.thrift.internal.ThriftDataReceiver}
TID: [0] [BAM] [2014-09-17 17:12:32,513]  INFO {org.wso2.carbon.core.transports.http.HttpsTransportListener} -  HTTPS port       : 9444 {org.wso2.carbon.core.transports.http.HttpsTransportListener}
TID: [0] [BAM] [2014-09-17 17:12:32,514]  INFO {org.wso2.carbon.core.transports.http.HttpTransportListener} -  HTTP port        : 9764 {org.wso2.carbon.core.transports.http.HttpTransportListener}
TID: [0] [BAM] [2014-09-17 17:12:32,597]  INFO {org.wso2.carbon.ntask.core.service.impl.TaskServiceImpl} -  Task service starting in STANDALONE mode... {org.wso2.carbon.ntask.core.service.impl.TaskServiceImpl}
TID: [0] [BAM] [2014-09-17 17:12:32,747] ERROR {me.prettyprint.cassandra.connection.HConnectionManager} -  Could not start connection pool for host localhost(127.0.0.1):9160 {me.prettyprint.cassandra.connection.HConnectionManager}
TID: [0] [BAM] [2014-09-17 17:12:32,748]  WARN {me.prettyprint.cassandra.connection.CassandraHostRetryService} -  Downed localhost(127.0.0.1):9160 host still appears to be down: Unable to open transport to localhost(127.0.0.1):9160 , java.net.ConnectException: Connection refused {me.prettyprint.cassandra.connection.CassandraHostRetryService}
TID: [0] [BAM] [2014-09-17 17:12:32,753] ERROR {org.wso2.carbon.bam.notification.task.internal.NotificationDispatchComponent} -  All host pools marked down. Retry burden pushed out to client. {org.wso2.carbon.bam.notification.task.internal.NotificationDispatchComponent}
me.prettyprint.hector.api.exceptions.HectorException: All host pools marked down. Retry burden pushed out to client.
	at me.prettyprint.cassandra.connection.HConnectionManager.getClientFromLBPolicy(HConnectionManager.java:393)
	at me.prettyprint.cassandra.connection.HConnectionManager.operateWithFailover(HConnectionManager.java:249)
	at me.prettyprint.cassandra.service.ThriftCluster.addKeyspace(ThriftCluster.java:168)
	at org.wso2.carbon.bam.datasource.utils.DataSourceUtils.createKeyspaceIfNotExist(DataSourceUtils.java:80)
	at org.wso2.carbon.bam.datasource.utils.DataSourceUtils.getClusterKeyspaceFromRDBMSConfig(DataSourceUtils.java:92)
	at org.wso2.carbon.bam.datasource.utils.DataSourceUtils.getClusterKeyspaceFromRDBMSDataSource(DataSourceUtils.java:96)
	at org.wso2.carbon.bam.notification.task.internal.NotificationDispatchComponent.initRecordStore(NotificationDispatchComponent.java:72)
	at org.wso2.carbon.bam.notification.task.internal.NotificationDispatchComponent.activate(NotificationDispatchComponent.java:64)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.eclipse.equinox.internal.ds.model.ServiceComponent.activate(ServiceComponent.java:260)
	at org.eclipse.equinox.internal.ds.model.ServiceComponentProp.activate(ServiceComponentProp.java:146)
	at org.eclipse.equinox.internal.ds.model.ServiceComponentProp.build(ServiceComponentProp.java:347)
	at org.eclipse.equinox.internal.ds.InstanceProcess.buildComponent(InstanceProcess.java:620)
	at org.eclipse.equinox.internal.ds.InstanceProcess.buildComponents(InstanceProcess.java:197)
	at org.eclipse.equinox.internal.ds.Resolver.getEligible(Resolver.java:343)
	at org.eclipse.equinox.internal.ds.SCRManager.serviceChanged(SCRManager.java:222)
	at org.eclipse.osgi.internal.serviceregistry.FilteredServiceListener.serviceChanged(FilteredServiceListener.java:107)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.dispatchEvent(BundleContextImpl.java:861)
	at org.eclipse.osgi.framework.eventmgr.EventManager.dispatchEvent(EventManager.java:230)
	at org.eclipse.osgi.framework.eventmgr.ListenerQueue.dispatchEventSynchronous(ListenerQueue.java:148)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistry.publishServiceEventPrivileged(ServiceRegistry.java:819)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistry.publishServiceEvent(ServiceRegistry.java:771)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistrationImpl.register(ServiceRegistrationImpl.java:130)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistry.registerService(ServiceRegistry.java:214)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.registerService(BundleContextImpl.java:433)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.registerService(BundleContextImpl.java:451)
	at org.wso2.carbon.ntask.core.internal.TasksDSComponent.activate(TasksDSComponent.java:105)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.eclipse.equinox.internal.ds.model.ServiceComponent.activate(ServiceComponent.java:260)
	at org.eclipse.equinox.internal.ds.model.ServiceComponentProp.activate(ServiceComponentProp.java:146)
	at org.eclipse.equinox.internal.ds.model.ServiceComponentProp.build(ServiceComponentProp.java:347)
	at org.eclipse.equinox.internal.ds.InstanceProcess.buildComponent(InstanceProcess.java:620)
	at org.eclipse.equinox.internal.ds.InstanceProcess.buildComponents(InstanceProcess.java:197)
	at org.eclipse.equinox.internal.ds.Resolver.getEligible(Resolver.java:343)
	at org.eclipse.equinox.internal.ds.SCRManager.serviceChanged(SCRManager.java:222)
	at org.eclipse.osgi.internal.serviceregistry.FilteredServiceListener.serviceChanged(FilteredServiceListener.java:107)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.dispatchEvent(BundleContextImpl.java:861)
	at org.eclipse.osgi.framework.eventmgr.EventManager.dispatchEvent(EventManager.java:230)
	at org.eclipse.osgi.framework.eventmgr.ListenerQueue.dispatchEventSynchronous(ListenerQueue.java:148)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistry.publishServiceEventPrivileged(ServiceRegistry.java:819)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistry.publishServiceEvent(ServiceRegistry.java:771)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistrationImpl.register(ServiceRegistrationImpl.java:130)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistry.registerService(ServiceRegistry.java:214)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.registerService(BundleContextImpl.java:433)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.registerService(BundleContextImpl.java:451)
	at org.wso2.carbon.core.internal.StartupFinalizerServiceComponent.completeInitialization(StartupFinalizerServiceComponent.java:192)
	at org.wso2.carbon.core.internal.StartupFinalizerServiceComponent.serviceChanged(StartupFinalizerServiceComponent.java:280)
	at org.eclipse.osgi.internal.serviceregistry.FilteredServiceListener.serviceChanged(FilteredServiceListener.java:107)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.dispatchEvent(BundleContextImpl.java:861)
	at org.eclipse.osgi.framework.eventmgr.EventManager.dispatchEvent(EventManager.java:230)
	at org.eclipse.osgi.framework.eventmgr.ListenerQueue.dispatchEventSynchronous(ListenerQueue.java:148)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistry.publishServiceEventPrivileged(ServiceRegistry.java:819)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistry.publishServiceEvent(ServiceRegistry.java:771)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistrationImpl.register(ServiceRegistrationImpl.java:130)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistry.registerService(ServiceRegistry.java:214)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.registerService(BundleContextImpl.java:433)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.registerService(BundleContextImpl.java:451)
	at org.wso2.carbon.server.admin.internal.ServerAdminServiceComponent.activate(ServerAdminServiceComponent.java:106)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.eclipse.equinox.internal.ds.model.ServiceComponent.activate(ServiceComponent.java:260)
	at org.eclipse.equinox.internal.ds.model.ServiceComponentProp.activate(ServiceComponentProp.java:146)
	at org.eclipse.equinox.internal.ds.model.ServiceComponentProp.build(ServiceComponentProp.java:347)
	at org.eclipse.equinox.internal.ds.InstanceProcess.buildComponent(InstanceProcess.java:620)
	at org.eclipse.equinox.internal.ds.InstanceProcess.buildComponents(InstanceProcess.java:197)
	at org.eclipse.equinox.internal.ds.Resolver.getEligible(Resolver.java:343)
	at org.eclipse.equinox.internal.ds.SCRManager.serviceChanged(SCRManager.java:222)
	at org.eclipse.osgi.internal.serviceregistry.FilteredServiceListener.serviceChanged(FilteredServiceListener.java:107)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.dispatchEvent(BundleContextImpl.java:861)
	at org.eclipse.osgi.framework.eventmgr.EventManager.dispatchEvent(EventManager.java:230)
	at org.eclipse.osgi.framework.eventmgr.ListenerQueue.dispatchEventSynchronous(ListenerQueue.java:148)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistry.publishServiceEventPrivileged(ServiceRegistry.java:819)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistry.publishServiceEvent(ServiceRegistry.java:771)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistrationImpl.register(ServiceRegistrationImpl.java:130)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistry.registerService(ServiceRegistry.java:214)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.registerService(BundleContextImpl.java:433)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.registerService(BundleContextImpl.java:451)
	at org.wso2.carbon.core.init.CarbonServerManager.initializeCarbon(CarbonServerManager.java:517)
	at org.wso2.carbon.core.init.CarbonServerManager.start(CarbonServerManager.java:219)
	at org.wso2.carbon.core.internal.CarbonCoreServiceComponent.activate(CarbonCoreServiceComponent.java:77)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.eclipse.equinox.internal.ds.model.ServiceComponent.activate(ServiceComponent.java:260)
	at org.eclipse.equinox.internal.ds.model.ServiceComponentProp.activate(ServiceComponentProp.java:146)
	at org.eclipse.equinox.internal.ds.model.ServiceComponentProp.build(ServiceComponentProp.java:347)
	at org.eclipse.equinox.internal.ds.InstanceProcess.buildComponent(InstanceProcess.java:620)
	at org.eclipse.equinox.internal.ds.InstanceProcess.buildComponents(InstanceProcess.java:197)
	at org.eclipse.equinox.internal.ds.Resolver.getEligible(Resolver.java:343)
	at org.eclipse.equinox.internal.ds.SCRManager.serviceChanged(SCRManager.java:222)
	at org.eclipse.osgi.internal.serviceregistry.FilteredServiceListener.serviceChanged(FilteredServiceListener.java:107)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.dispatchEvent(BundleContextImpl.java:861)
	at org.eclipse.osgi.framework.eventmgr.EventManager.dispatchEvent(EventManager.java:230)
	at org.eclipse.osgi.framework.eventmgr.ListenerQueue.dispatchEventSynchronous(ListenerQueue.java:148)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistry.publishServiceEventPrivileged(ServiceRegistry.java:819)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistry.publishServiceEvent(ServiceRegistry.java:771)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistrationImpl.register(ServiceRegistrationImpl.java:130)
	at org.eclipse.osgi.internal.serviceregistry.ServiceRegistry.registerService(ServiceRegistry.java:214)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.registerService(BundleContextImpl.java:433)
	at org.eclipse.equinox.http.servlet.internal.Activator.registerHttpService(Activator.java:81)
	at org.eclipse.equinox.http.servlet.internal.Activator.addProxyServlet(Activator.java:60)
	at org.eclipse.equinox.http.servlet.internal.ProxyServlet.init(ProxyServlet.java:40)
	at org.wso2.carbon.tomcat.ext.servlet.DelegationServlet.init(DelegationServlet.java:38)
	at org.apache.catalina.core.StandardWrapper.initServlet(StandardWrapper.java:1267)
	at org.apache.catalina.core.StandardWrapper.loadServlet(StandardWrapper.java:1186)
	at org.apache.catalina.core.StandardWrapper.load(StandardWrapper.java:1081)
	at org.apache.catalina.core.StandardContext.loadOnStartup(StandardContext.java:5027)
	at org.apache.catalina.core.StandardContext.startInternal(StandardContext.java:5314)
	at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150)
	at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1559)
	at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1549)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:12:32,784]  INFO {org.wso2.carbon.core.init.JMXServerManager} -  JMX Service URL  : service:jmx:rmi://localhost:11112/jndi/rmi://localhost:10000/jmxrmi {org.wso2.carbon.core.init.JMXServerManager}
TID: [0] [BAM] [2014-09-17 17:12:32,784]  INFO {org.wso2.carbon.bam.toolbox.deployer.internal.ServerStartUpInspector} -  BAM Toolbox is ready to do deployments {org.wso2.carbon.bam.toolbox.deployer.internal.ServerStartUpInspector}
TID: [0] [BAM] [2014-09-17 17:12:32,789]  INFO {org.wso2.carbon.bam.toolbox.deployer.core.BAMToolBoxDeployer} -  /home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/repository/deployment/server/bam-toolbox {org.wso2.carbon.bam.toolbox.deployer.core.BAMToolBoxDeployer}
TID: [0] [BAM] [2014-09-17 17:12:32,828]  INFO {org.wso2.carbon.ntask.core.impl.AbstractQuartzTaskManager} -  Task scheduled: [-1234][BAM_NOTIFICATION_DISPATCHER_TASK][NOTIFIER] {org.wso2.carbon.ntask.core.impl.AbstractQuartzTaskManager}
TID: [0] [BAM] [2014-09-17 17:12:32,830]  INFO {org.wso2.carbon.core.internal.StartupFinalizerServiceComponent} -  Server           :  WSO2 Business Activity Monitor-2.4.0 {org.wso2.carbon.core.internal.StartupFinalizerServiceComponent}
TID: [0] [BAM] [2014-09-17 17:12:32,830]  INFO {org.wso2.carbon.core.internal.StartupFinalizerServiceComponent} -  WSO2 Carbon started in 13 sec {org.wso2.carbon.core.internal.StartupFinalizerServiceComponent}
TID: [0] [BAM] [2014-09-17 17:12:32,949]  INFO {org.wso2.carbon.databridge.core.DataBridge} -  admin connected {org.wso2.carbon.databridge.core.DataBridge}
TID: [0] [BAM] [2014-09-17 17:12:33,013] ERROR {me.prettyprint.cassandra.connection.HConnectionManager} -  Could not start connection pool for host localhost(127.0.0.1):9160 {me.prettyprint.cassandra.connection.HConnectionManager}
TID: [0] [BAM] [2014-09-17 17:12:33,014]  WARN {me.prettyprint.cassandra.connection.CassandraHostRetryService} -  Downed localhost(127.0.0.1):9160 host still appears to be down: Unable to open transport to localhost(127.0.0.1):9160 , java.net.ConnectException: Connection refused {me.prettyprint.cassandra.connection.CassandraHostRetryService}
TID: [0] [BAM] [2014-09-17 17:12:33,017] ERROR {org.wso2.carbon.bam.notification.task.NotificationDispatchTask} -  Error executing notification dispatch task: All host pools marked down. Retry burden pushed out to client. {org.wso2.carbon.bam.notification.task.NotificationDispatchTask}
me.prettyprint.hector.api.exceptions.HectorException: All host pools marked down. Retry burden pushed out to client.
	at me.prettyprint.cassandra.connection.HConnectionManager.getClientFromLBPolicy(HConnectionManager.java:393)
	at me.prettyprint.cassandra.connection.HConnectionManager.operateWithFailover(HConnectionManager.java:249)
	at me.prettyprint.cassandra.service.ThriftCluster.addKeyspace(ThriftCluster.java:168)
	at org.wso2.carbon.bam.datasource.utils.DataSourceUtils.createKeyspaceIfNotExist(DataSourceUtils.java:80)
	at org.wso2.carbon.bam.datasource.utils.DataSourceUtils.getClusterKeyspaceFromRDBMSConfig(DataSourceUtils.java:92)
	at org.wso2.carbon.bam.datasource.utils.DataSourceUtils.getClusterKeyspaceFromRDBMSDataSource(DataSourceUtils.java:96)
	at org.wso2.carbon.bam.notification.task.NotificationDispatchTask.initPublisherKS(NotificationDispatchTask.java:105)
	at org.wso2.carbon.bam.notification.task.NotificationDispatchTask.execute(NotificationDispatchTask.java:188)
	at org.wso2.carbon.ntask.core.impl.TaskQuartzJobAdapter.execute(TaskQuartzJobAdapter.java:67)
	at org.quartz.core.JobRunShell.run(JobRunShell.java:213)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:12:33,670]  INFO {org.wso2.carbon.dashboard.common.oauth.GSOAuthModule} -  Using random key for OAuth client-side state encryption {org.wso2.carbon.dashboard.common.oauth.GSOAuthModule}
TID: [0] [BAM] [2014-09-17 17:12:34,144]  INFO {org.wso2.carbon.ui.internal.CarbonUIServiceComponent} -  Mgt Console URL  : https://10.100.5.90:9444/carbon/ {org.wso2.carbon.ui.internal.CarbonUIServiceComponent}
TID: [0] [BAM] [2014-09-17 17:12:34,144]  INFO {org.wso2.carbon.ui.internal.CarbonUIServiceComponent} -  Gadget Server Default Context : http://10.100.5.90:9764/portal {org.wso2.carbon.ui.internal.CarbonUIServiceComponent}
TID: [0] [BAM] [2014-09-17 17:12:37,857] ERROR {me.prettyprint.cassandra.connection.HConnectionManager} -  Could not start connection pool for host localhost(127.0.0.1):9160 {me.prettyprint.cassandra.connection.HConnectionManager}
TID: [0] [BAM] [2014-09-17 17:12:37,858]  WARN {me.prettyprint.cassandra.connection.CassandraHostRetryService} -  Downed localhost(127.0.0.1):9160 host still appears to be down: Unable to open transport to localhost(127.0.0.1):9160 , java.net.ConnectException: Connection refused {me.prettyprint.cassandra.connection.CassandraHostRetryService}
TID: [0] [BAM] [2014-09-17 17:12:37,858] ERROR {org.wso2.carbon.bam.notification.task.NotificationDispatchTask} -  Error executing notification dispatch task: All host pools marked down. Retry burden pushed out to client. {org.wso2.carbon.bam.notification.task.NotificationDispatchTask}
me.prettyprint.hector.api.exceptions.HectorException: All host pools marked down. Retry burden pushed out to client.
	at me.prettyprint.cassandra.connection.HConnectionManager.getClientFromLBPolicy(HConnectionManager.java:393)
	at me.prettyprint.cassandra.connection.HConnectionManager.operateWithFailover(HConnectionManager.java:249)
	at me.prettyprint.cassandra.service.ThriftCluster.addKeyspace(ThriftCluster.java:168)
	at org.wso2.carbon.bam.datasource.utils.DataSourceUtils.createKeyspaceIfNotExist(DataSourceUtils.java:80)
	at org.wso2.carbon.bam.datasource.utils.DataSourceUtils.getClusterKeyspaceFromRDBMSConfig(DataSourceUtils.java:92)
	at org.wso2.carbon.bam.datasource.utils.DataSourceUtils.getClusterKeyspaceFromRDBMSDataSource(DataSourceUtils.java:96)
	at org.wso2.carbon.bam.notification.task.NotificationDispatchTask.initPublisherKS(NotificationDispatchTask.java:105)
	at org.wso2.carbon.bam.notification.task.NotificationDispatchTask.execute(NotificationDispatchTask.java:188)
	at org.wso2.carbon.ntask.core.impl.TaskQuartzJobAdapter.execute(TaskQuartzJobAdapter.java:67)
	at org.quartz.core.JobRunShell.run(JobRunShell.java:213)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:12:42,742]  WARN {me.prettyprint.cassandra.connection.CassandraHostRetryService} -  Downed localhost(127.0.0.1):9160 host still appears to be down: Unable to open transport to localhost(127.0.0.1):9160 , java.net.ConnectException: Connection refused {me.prettyprint.cassandra.connection.CassandraHostRetryService}
TID: [0] [BAM] [2014-09-17 17:12:42,861] ERROR {me.prettyprint.cassandra.connection.HConnectionManager} -  Could not start connection pool for host localhost(127.0.0.1):9160 {me.prettyprint.cassandra.connection.HConnectionManager}
TID: [0] [BAM] [2014-09-17 17:12:42,861] ERROR {org.wso2.carbon.bam.notification.task.NotificationDispatchTask} -  Error executing notification dispatch task: All host pools marked down. Retry burden pushed out to client. {org.wso2.carbon.bam.notification.task.NotificationDispatchTask}
me.prettyprint.hector.api.exceptions.HectorException: All host pools marked down. Retry burden pushed out to client.
	at me.prettyprint.cassandra.connection.HConnectionManager.getClientFromLBPolicy(HConnectionManager.java:393)
	at me.prettyprint.cassandra.connection.HConnectionManager.operateWithFailover(HConnectionManager.java:249)
	at me.prettyprint.cassandra.service.ThriftCluster.addKeyspace(ThriftCluster.java:168)
	at org.wso2.carbon.bam.datasource.utils.DataSourceUtils.createKeyspaceIfNotExist(DataSourceUtils.java:80)
	at org.wso2.carbon.bam.datasource.utils.DataSourceUtils.getClusterKeyspaceFromRDBMSConfig(DataSourceUtils.java:92)
	at org.wso2.carbon.bam.datasource.utils.DataSourceUtils.getClusterKeyspaceFromRDBMSDataSource(DataSourceUtils.java:96)
	at org.wso2.carbon.bam.notification.task.NotificationDispatchTask.initPublisherKS(NotificationDispatchTask.java:105)
	at org.wso2.carbon.bam.notification.task.NotificationDispatchTask.execute(NotificationDispatchTask.java:188)
	at org.wso2.carbon.ntask.core.impl.TaskQuartzJobAdapter.execute(TaskQuartzJobAdapter.java:67)
	at org.quartz.core.JobRunShell.run(JobRunShell.java:213)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:12:42,861]  WARN {me.prettyprint.cassandra.connection.CassandraHostRetryService} -  Downed localhost(127.0.0.1):9160 host still appears to be down: Unable to open transport to localhost(127.0.0.1):9160 , java.net.ConnectException: Connection refused {me.prettyprint.cassandra.connection.CassandraHostRetryService}
TID: [0] [BAM] [2014-09-17 17:12:43,013]  WARN {me.prettyprint.cassandra.connection.CassandraHostRetryService} -  Downed localhost(127.0.0.1):9160 host still appears to be down: Unable to open transport to localhost(127.0.0.1):9160 , java.net.ConnectException: Connection refused {me.prettyprint.cassandra.connection.CassandraHostRetryService}
TID: [0] [BAM] [2014-09-17 17:12:47,858]  WARN {me.prettyprint.cassandra.connection.CassandraHostRetryService} -  Downed localhost(127.0.0.1):9160 host still appears to be down: Unable to open transport to localhost(127.0.0.1):9160 , java.net.ConnectException: Connection refused {me.prettyprint.cassandra.connection.CassandraHostRetryService}
TID: [0] [BAM] [2014-09-17 17:12:47,863] ERROR {me.prettyprint.cassandra.connection.HConnectionManager} -  Could not start connection pool for host localhost(127.0.0.1):9160 {me.prettyprint.cassandra.connection.HConnectionManager}
TID: [0] [BAM] [2014-09-17 17:12:47,863] ERROR {org.wso2.carbon.bam.notification.task.NotificationDispatchTask} -  Error executing notification dispatch task: All host pools marked down. Retry burden pushed out to client. {org.wso2.carbon.bam.notification.task.NotificationDispatchTask}
me.prettyprint.hector.api.exceptions.HectorException: All host pools marked down. Retry burden pushed out to client.
	at me.prettyprint.cassandra.connection.HConnectionManager.getClientFromLBPolicy(HConnectionManager.java:393)
	at me.prettyprint.cassandra.connection.HConnectionManager.operateWithFailover(HConnectionManager.java:249)
	at me.prettyprint.cassandra.service.ThriftCluster.addKeyspace(ThriftCluster.java:168)
	at org.wso2.carbon.bam.datasource.utils.DataSourceUtils.createKeyspaceIfNotExist(DataSourceUtils.java:80)
	at org.wso2.carbon.bam.datasource.utils.DataSourceUtils.getClusterKeyspaceFromRDBMSConfig(DataSourceUtils.java:92)
	at org.wso2.carbon.bam.datasource.utils.DataSourceUtils.getClusterKeyspaceFromRDBMSDataSource(DataSourceUtils.java:96)
	at org.wso2.carbon.bam.notification.task.NotificationDispatchTask.initPublisherKS(NotificationDispatchTask.java:105)
	at org.wso2.carbon.bam.notification.task.NotificationDispatchTask.execute(NotificationDispatchTask.java:188)
	at org.wso2.carbon.ntask.core.impl.TaskQuartzJobAdapter.execute(TaskQuartzJobAdapter.java:67)
	at org.quartz.core.JobRunShell.run(JobRunShell.java:213)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:12:47,863]  WARN {me.prettyprint.cassandra.connection.CassandraHostRetryService} -  Downed localhost(127.0.0.1):9160 host still appears to be down: Unable to open transport to localhost(127.0.0.1):9160 , java.net.ConnectException: Connection refused {me.prettyprint.cassandra.connection.CassandraHostRetryService}
TID: [0] [BAM] [2014-09-17 17:12:51,752]  INFO {org.apache.cassandra.thrift.CassandraDaemon} -  Stop listening to thrift clients {org.apache.cassandra.thrift.CassandraDaemon}
TID: [0] [BAM] [2014-09-17 17:12:51,753]  INFO {org.wso2.carbon.core.init.CarbonServerManager} -  Shutdown hook triggered.... {org.wso2.carbon.core.init.CarbonServerManager}
TID: [0] [BAM] [2014-09-17 17:12:51,754]  INFO {org.wso2.carbon.core.init.CarbonServerManager} -  Gracefully shutting down WSO2 Business Activity Monitor... {org.wso2.carbon.core.init.CarbonServerManager}
TID: [0] [BAM] [2014-09-17 17:12:51,754]  INFO {org.apache.cassandra.gms.Gossiper} -  Announcing shutdown {org.apache.cassandra.gms.Gossiper}
TID: [0] [BAM] [2014-09-17 17:12:51,755]  INFO {org.wso2.carbon.core.ServerManagement} -  Starting to switch to maintenance mode... {org.wso2.carbon.core.ServerManagement}
TID: [0] [BAM] [2014-09-17 17:12:51,756]  INFO {org.wso2.carbon.core.ServerManagement} -  Stopped all transport listeners {org.wso2.carbon.core.ServerManagement}
TID: [0] [BAM] [2014-09-17 17:12:51,756]  INFO {org.wso2.carbon.core.ServerManagement} -  Waiting for request service completion... {org.wso2.carbon.core.ServerManagement}
TID: [0] [BAM] [2014-09-17 17:12:51,757]  INFO {org.wso2.carbon.core.ServerManagement} -  All requests have been served. {org.wso2.carbon.core.ServerManagement}
TID: [0] [BAM] [2014-09-17 17:12:51,758]  INFO {org.wso2.carbon.core.ServerManagement} -  Waiting for deployment completion... {org.wso2.carbon.core.ServerManagement}
TID: [0] [BAM] [2014-09-17 17:12:51,778]  INFO {org.wso2.carbon.webapp.mgt.WebApplication} -  Unloaded webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/STRATOS_ROOT] {org.wso2.carbon.webapp.mgt.WebApplication}
TID: [0] [BAM] [2014-09-17 17:12:51,784]  INFO {org.springframework.web.context.support.XmlWebApplicationContext} -  Closing Root WebApplicationContext: startup date [Wed Sep 17 17:12:29 IST 2014]; root of context hierarchy {org.springframework.web.context.support.XmlWebApplicationContext}
TID: [0] [BAM] [2014-09-17 17:12:51,786]  INFO {org.springframework.beans.factory.support.DefaultListableBeanFactory} -  Destroying singletons in org.springframework.beans.factory.support.DefaultListableBeanFactory@59311a3e: defining beans [cxf,org.apache.cxf.bus.spring.BusWiringBeanFactoryPostProcessor,org.apache.cxf.bus.spring.Jsr250BeanPostProcessor,org.apache.cxf.bus.spring.BusExtensionPostProcessor,dataReceiverStreamsService,dataReceiverStreamService,streamsBean,streamBean]; root of factory hierarchy {org.springframework.beans.factory.support.DefaultListableBeanFactory}
TID: [0] [BAM] [2014-09-17 17:12:51,812]  INFO {org.wso2.carbon.webapp.mgt.WebApplication} -  Unloaded webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/datareceiver] {org.wso2.carbon.webapp.mgt.WebApplication}
TID: [0] [BAM] [2014-09-17 17:12:51,825]  INFO {org.wso2.carbon.webapp.mgt.WebApplication} -  Unloaded webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/bamdashboards] {org.wso2.carbon.webapp.mgt.WebApplication}
TID: [0] [BAM] [2014-09-17 17:12:51,843]  INFO {org.wso2.carbon.webapp.mgt.WebApplication} -  Unloaded webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/activitymonitoring] {org.wso2.carbon.webapp.mgt.WebApplication}
TID: [0] [BAM] [2014-09-17 17:12:51,843]  INFO {org.wso2.carbon.core.ServerManagement} -  All deployment tasks have been completed. {org.wso2.carbon.core.ServerManagement}
TID: [0] [BAM] [2014-09-17 17:12:51,843]  INFO {org.wso2.carbon.core.ServerManagement} -  Waiting for server task completion... {org.wso2.carbon.core.ServerManagement}
TID: [0] [BAM] [2014-09-17 17:12:51,849]  INFO {org.wso2.carbon.core.ServerManagement} -  All server tasks have been completed. {org.wso2.carbon.core.ServerManagement}
TID: [0] [BAM] [2014-09-17 17:12:51,849]  INFO {org.wso2.carbon.core.init.CarbonServerManager} -  Shutting down WSO2 Business Activity Monitor... {org.wso2.carbon.core.init.CarbonServerManager}
TID: [0] [BAM] [2014-09-17 17:12:51,849]  INFO {org.wso2.carbon.core.init.CarbonServerManager} -  Shutting down OSGi framework... {org.wso2.carbon.core.init.CarbonServerManager}
TID: [0] [BAM] [2014-09-17 17:12:51,879]  INFO {org.wso2.carbon.databridge.receiver.thrift.internal.ThriftDataReceiverDS} -  Thrift server shutting down... {org.wso2.carbon.databridge.receiver.thrift.internal.ThriftDataReceiverDS}
TID: [0] [BAM] [2014-09-17 17:12:52,743]  WARN {me.prettyprint.cassandra.connection.CassandraHostRetryService} -  Downed localhost(127.0.0.1):9160 host still appears to be down: Unable to open transport to localhost(127.0.0.1):9160 , java.net.ConnectException: Connection refused {me.prettyprint.cassandra.connection.CassandraHostRetryService}
TID: [0] [BAM] [2014-09-17 17:12:52,754]  INFO {org.apache.cassandra.net.MessagingService} -  Waiting for messaging service to quiesce {org.apache.cassandra.net.MessagingService}
TID: [0] [BAM] [2014-09-17 17:12:52,755]  INFO {org.apache.cassandra.net.MessagingService} -  MessagingService shutting down server thread. {org.apache.cassandra.net.MessagingService}
TID: [0] [BAM] [2014-09-17 17:12:52,861]  WARN {me.prettyprint.cassandra.connection.CassandraHostRetryService} -  Downed localhost(127.0.0.1):9160 host still appears to be down: Unable to open transport to localhost(127.0.0.1):9160 , java.net.ConnectException: Connection refused {me.prettyprint.cassandra.connection.CassandraHostRetryService}
TID: [0] [BAM] [2014-09-17 17:12:53,013]  WARN {me.prettyprint.cassandra.connection.CassandraHostRetryService} -  Downed localhost(127.0.0.1):9160 host still appears to be down: Unable to open transport to localhost(127.0.0.1):9160 , java.net.ConnectException: Connection refused {me.prettyprint.cassandra.connection.CassandraHostRetryService}
TID: [0] [BAM] [2014-09-17 17:12:54,096]  INFO {org.wso2.carbon.core.init.CarbonServerManager} -  Stopping CarbonServerManager... {org.wso2.carbon.core.init.CarbonServerManager}
TID: [0] [BAM] [2014-09-17 17:12:54,097]  INFO {org.apache.axis2.transport.tcp.TCPTransportSender} -  TCP Sender Shutdown {org.apache.axis2.transport.tcp.TCPTransportSender}
TID: [0] [BAM] [2014-09-17 17:12:54,370]  INFO {org.wso2.carbon.tomcat.ext.internal.CarbonTomcatServiceComponent} -  Stopping the carbon web-app registered under : / {org.wso2.carbon.tomcat.ext.internal.CarbonTomcatServiceComponent}
TID: [0] [BAM] [2014-09-17 17:12:54,696]  INFO {org.wso2.carbon.core.init.CarbonServerManager} -  Shutdown complete {org.wso2.carbon.core.init.CarbonServerManager}
TID: [0] [BAM] [2014-09-17 17:12:54,696]  INFO {org.wso2.carbon.core.init.CarbonServerManager} -  Halting JVM {org.wso2.carbon.core.init.CarbonServerManager}
TID: [0] [BAM] [2014-09-17 17:15:07,155]  INFO {org.wso2.carbon.core.internal.CarbonCoreActivator} -  Starting WSO2 Carbon... {org.wso2.carbon.core.internal.CarbonCoreActivator}
TID: [0] [BAM] [2014-09-17 17:15:07,156]  INFO {org.wso2.carbon.core.internal.CarbonCoreActivator} -  Operating System : Linux 3.13.0-24-generic, amd64 {org.wso2.carbon.core.internal.CarbonCoreActivator}
TID: [0] [BAM] [2014-09-17 17:15:07,156]  INFO {org.wso2.carbon.core.internal.CarbonCoreActivator} -  Java Home        : /usr/lib/jvm/java-6-oracle/jre {org.wso2.carbon.core.internal.CarbonCoreActivator}
TID: [0] [BAM] [2014-09-17 17:15:07,156]  INFO {org.wso2.carbon.core.internal.CarbonCoreActivator} -  Java Version     : 1.6.0_45 {org.wso2.carbon.core.internal.CarbonCoreActivator}
TID: [0] [BAM] [2014-09-17 17:15:07,157]  INFO {org.wso2.carbon.core.internal.CarbonCoreActivator} -  Java VM          : Java HotSpot(TM) 64-Bit Server VM 20.45-b01,Sun Microsystems Inc. {org.wso2.carbon.core.internal.CarbonCoreActivator}
TID: [0] [BAM] [2014-09-17 17:15:07,157]  INFO {org.wso2.carbon.core.internal.CarbonCoreActivator} -  Carbon Home      : /home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0 {org.wso2.carbon.core.internal.CarbonCoreActivator}
TID: [0] [BAM] [2014-09-17 17:15:07,157]  INFO {org.wso2.carbon.core.internal.CarbonCoreActivator} -  Java Temp Dir    : /home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/tmp {org.wso2.carbon.core.internal.CarbonCoreActivator}
TID: [0] [BAM] [2014-09-17 17:15:07,157]  INFO {org.wso2.carbon.core.internal.CarbonCoreActivator} -  User             : denuwanthi, en-US, Asia/Colombo {org.wso2.carbon.core.internal.CarbonCoreActivator}
TID: [0] [BAM] [2014-09-17 17:15:07,209]  WARN {org.wso2.carbon.core.bootup.validator.util.ValidationResultPrinter} -  The default keystore (wso2carbon.jks) is currently being used. To maximize security when deploying to a production environment, configure a new keystore with a unique password in the production server profile. {org.wso2.carbon.core.bootup.validator.util.ValidationResultPrinter}
TID: [0] [BAM] [2014-09-17 17:15:07,231]  INFO {org.wso2.carbon.databridge.agent.thrift.AgentHolder} -  Agent created ! {org.wso2.carbon.databridge.agent.thrift.AgentHolder}
TID: [0] [BAM] [2014-09-17 17:15:07,290]  INFO {org.wso2.carbon.databridge.agent.thrift.internal.AgentDS} -  Successfully deployed Agent Client {org.wso2.carbon.databridge.agent.thrift.internal.AgentDS}
TID: [0] [BAM] [2014-09-17 17:15:08,457]  INFO {org.wso2.carbon.bam.toolbox.deployer.internal.DataBridgeRecieverServiceComponent} -  Successfully setted data bridge reciever service {org.wso2.carbon.bam.toolbox.deployer.internal.DataBridgeRecieverServiceComponent}
TID: [0] [BAM] [2014-09-17 17:15:08,466]  INFO {org.wso2.carbon.databridge.core.internal.DataBridgeDS} -  Successfully deployed Agent Server  {org.wso2.carbon.databridge.core.internal.DataBridgeDS}
TID: [0] [BAM] [2014-09-17 17:15:08,617]  INFO {org.wso2.carbon.registry.core.jdbc.EmbeddedRegistryService} -  Configured Registry in 62ms {org.wso2.carbon.registry.core.jdbc.EmbeddedRegistryService}
TID: [0] [BAM] [2014-09-17 17:15:08,742]  INFO {org.wso2.carbon.registry.core.internal.RegistryCoreServiceComponent} -  Registry Mode    : READ-WRITE {org.wso2.carbon.registry.core.internal.RegistryCoreServiceComponent}
TID: [0] [BAM] [2014-09-17 17:15:09,352]  INFO {org.wso2.carbon.user.core.internal.UserStoreMgtDSComponent} -  Carbon UserStoreMgtDSComponent activated successfully. {org.wso2.carbon.user.core.internal.UserStoreMgtDSComponent}
TID: [0] [BAM] [2014-09-17 17:15:09,768]  INFO {org.apache.cassandra.net.MessagingService} -  Starting Messaging Service on port 7001 {org.apache.cassandra.net.MessagingService}
TID: [0] [BAM] [2014-09-17 17:15:09,807]  INFO {org.apache.cassandra.thrift.CassandraDaemon} -  Binding thrift service to localhost/127.0.0.1:9161 {org.apache.cassandra.thrift.CassandraDaemon}
TID: [0] [BAM] [2014-09-17 17:15:09,808]  INFO {org.apache.cassandra.thrift.CassandraDaemon} -  Using TFastFramedTransport with a max frame size of 15728640 bytes. {org.apache.cassandra.thrift.CassandraDaemon}
TID: [0] [BAM] [2014-09-17 17:15:09,810]  INFO {org.apache.cassandra.thrift.CassandraDaemon} -  Using synchronous/threadpool thrift server on localhost/127.0.0.1 : 9161 {org.apache.cassandra.thrift.CassandraDaemon}
TID: [0] [BAM] [2014-09-17 17:15:09,810]  INFO {org.wso2.carbon.cassandra.server.CassandraServerController} -  Cassandra Server Controller Thread was destroyed successfully {org.wso2.carbon.cassandra.server.CassandraServerController}
TID: [0] [BAM] [2014-09-17 17:15:09,810]  INFO {org.apache.cassandra.thrift.CassandraDaemon} -  Listening for thrift clients... {org.apache.cassandra.thrift.CassandraDaemon}
TID: [0] [BAM] [2014-09-17 17:15:13,550]  INFO {org.apache.axis2.deployment.ClusterBuilder} -  Clustering has been disabled {org.apache.axis2.deployment.ClusterBuilder}
TID: [0] [BAM] [2014-09-17 17:15:13,716]  INFO {org.wso2.carbon.identity.user.store.configuration.deployer.UserStoreConfigurationDeployer} -  User Store Configuration Deployer initiated. {org.wso2.carbon.identity.user.store.configuration.deployer.UserStoreConfigurationDeployer}
TID: [0] [BAM] [2014-09-17 17:15:13,748]  INFO {org.wso2.carbon.stratos.landing.page.deployer.LandingPageWebappDeployer} -  Deployed product landing page webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/home] {org.wso2.carbon.stratos.landing.page.deployer.LandingPageWebappDeployer}
TID: [0] [BAM] [2014-09-17 17:15:13,752]  INFO {org.apache.axis2.transport.tcp.TCPTransportSender} -  TCP Sender started {org.apache.axis2.transport.tcp.TCPTransportSender}
TID: [0] [BAM] [2014-09-17 17:15:13,783]  INFO {org.wso2.carbon.webapp.mgt.TomcatGenericWebappsDeployer} -  Deployed webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/STRATOS_ROOT].File[/home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/repository/deployment/server/webapps/STRATOS_ROOT] {org.wso2.carbon.webapp.mgt.TomcatGenericWebappsDeployer}
TID: [0] [BAM] [2014-09-17 17:15:14,373]  INFO {org.springframework.web.context.support.XmlWebApplicationContext} -  Refreshing Root WebApplicationContext: startup date [Wed Sep 17 17:15:14 IST 2014]; root of context hierarchy {org.springframework.web.context.support.XmlWebApplicationContext}
TID: [0] [BAM] [2014-09-17 17:15:14,414]  INFO {org.springframework.beans.factory.xml.XmlBeanDefinitionReader} -  Loading XML bean definitions from class path resource [META-INF/cxf/cxf.xml] {org.springframework.beans.factory.xml.XmlBeanDefinitionReader}
TID: [0] [BAM] [2014-09-17 17:15:14,478]  INFO {org.springframework.beans.factory.xml.XmlBeanDefinitionReader} -  Loading XML bean definitions from URL [jndi:/localhost/datareceiver/WEB-INF/cxf-servlet.xml] {org.springframework.beans.factory.xml.XmlBeanDefinitionReader}
TID: [0] [BAM] [2014-09-17 17:15:14,709]  INFO {org.springframework.beans.factory.support.DefaultListableBeanFactory} -  Pre-instantiating singletons in org.springframework.beans.factory.support.DefaultListableBeanFactory@2ec18c31: defining beans [cxf,org.apache.cxf.bus.spring.BusWiringBeanFactoryPostProcessor,org.apache.cxf.bus.spring.Jsr250BeanPostProcessor,org.apache.cxf.bus.spring.BusExtensionPostProcessor,dataReceiverStreamsService,dataReceiverStreamService,streamsBean,streamBean]; root of factory hierarchy {org.springframework.beans.factory.support.DefaultListableBeanFactory}
TID: [0] [BAM] [2014-09-17 17:15:14,997]  INFO {org.apache.cxf.endpoint.ServerImpl} -  Setting the server's publish address to be /streams {org.apache.cxf.endpoint.ServerImpl}
TID: [0] [BAM] [2014-09-17 17:15:15,048]  INFO {org.apache.cxf.endpoint.ServerImpl} -  Setting the server's publish address to be /stream {org.apache.cxf.endpoint.ServerImpl}
TID: [0] [BAM] [2014-09-17 17:15:15,054]  INFO {org.wso2.carbon.webapp.mgt.TomcatGenericWebappsDeployer} -  Deployed webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/datareceiver].File[/home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/repository/deployment/server/webapps/datareceiver.war] {org.wso2.carbon.webapp.mgt.TomcatGenericWebappsDeployer}
TID: [0] [BAM] [2014-09-17 17:15:15,655]  INFO {org.jaggeryjs.jaggery.app.mgt.TomcatJaggeryWebappsDeployer} -  Deployed webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/bamdashboards].File[/home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/repository/deployment/server/jaggeryapps/bamdashboards] {org.jaggeryjs.jaggery.app.mgt.TomcatJaggeryWebappsDeployer}
TID: [0] [BAM] [2014-09-17 17:15:15,700]  INFO {org.jaggeryjs.jaggery.app.mgt.TomcatJaggeryWebappsDeployer} -  Deployed webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/activitymonitoring].File[/home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/repository/deployment/server/jaggeryapps/activitymonitoring] {org.jaggeryjs.jaggery.app.mgt.TomcatJaggeryWebappsDeployer}
TID: [0] [BAM] [2014-09-17 17:15:15,787]  INFO {org.apache.axis2.deployment.ModuleDeployer} -  Deploying module: rampart-1.6.1-wso2v10 - file:/home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/repository/deployment/client/modules/rampart-1.6.1-wso2v10.mar {org.apache.axis2.deployment.ModuleDeployer}
TID: [0] [BAM] [2014-09-17 17:15:15,791]  INFO {org.apache.axis2.deployment.ModuleDeployer} -  Deploying module: addressing-1.6.1-wso2v10 - file:/home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/repository/deployment/client/modules/addressing-1.6.1-wso2v10.mar {org.apache.axis2.deployment.ModuleDeployer}
TID: [0] [BAM] [2014-09-17 17:15:15,793]  INFO {org.apache.axis2.transport.tcp.TCPTransportSender} -  TCP Sender started {org.apache.axis2.transport.tcp.TCPTransportSender}
TID: [0] [BAM] [2014-09-17 17:15:16,014]  INFO {org.wso2.carbon.core.deployment.DeploymentInterceptor} -  Deploying Axis2 service: BAMMessageStoreService {super-tenant} {org.wso2.carbon.core.deployment.DeploymentInterceptor}
TID: [0] [BAM] [2014-09-17 17:15:16,069]  INFO {org.apache.axis2.deployment.DeploymentEngine} -  Deploying Web service: org.wso2.carbon.bam.messagestore -  {org.apache.axis2.deployment.DeploymentEngine}
TID: [0] [BAM] [2014-09-17 17:15:16,275]  INFO {org.wso2.carbon.core.deployment.DeploymentInterceptor} -  Deploying Axis2 service: CassandraSearchAdmin {super-tenant} {org.wso2.carbon.core.deployment.DeploymentInterceptor}
TID: [0] [BAM] [2014-09-17 17:15:16,408]  INFO {org.apache.axis2.deployment.DeploymentEngine} -  Deploying Web service: org.wso2.carbon.cassandra.search.mgt -  {org.apache.axis2.deployment.DeploymentEngine}
TID: [0] [BAM] [2014-09-17 17:15:17,124]  INFO {org.wso2.carbon.core.init.CarbonServerManager} -  Repository       : /home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/repository/deployment/server/ {org.wso2.carbon.core.init.CarbonServerManager}
TID: [0] [BAM] [2014-09-17 17:15:17,147]  INFO {org.wso2.carbon.bam.toolbox.deployer.internal.BAMToolBoxDeployerComponent} -  Successfully Started BAM Toolbox Deployer {org.wso2.carbon.bam.toolbox.deployer.internal.BAMToolBoxDeployerComponent}
TID: [0] [BAM] [2014-09-17 17:15:17,182]  INFO {org.wso2.carbon.core.internal.permission.update.PermissionUpdater} -  Permission cache updated for tenant -1234 {org.wso2.carbon.core.internal.permission.update.PermissionUpdater}
TID: [0] [BAM] [2014-09-17 17:15:17,196]  INFO {org.wso2.carbon.bam.toolbox.deployer.internal.DashboardServiceComponent} -  Successfully setted dashboard services {org.wso2.carbon.bam.toolbox.deployer.internal.DashboardServiceComponent}
TID: [0] [BAM] [2014-09-17 17:15:17,298]  INFO {org.wso2.carbon.databridge.receiver.thrift.internal.ThriftDataReceiver} -  Thrift Server started at 10.100.5.90 {org.wso2.carbon.databridge.receiver.thrift.internal.ThriftDataReceiver}
TID: [0] [BAM] [2014-09-17 17:15:17,304]  INFO {org.wso2.carbon.databridge.receiver.thrift.internal.ThriftDataReceiver} -  Thrift SSL port : 7712 {org.wso2.carbon.databridge.receiver.thrift.internal.ThriftDataReceiver}
TID: [0] [BAM] [2014-09-17 17:15:17,364]  INFO {org.wso2.carbon.databridge.receiver.thrift.internal.ThriftDataReceiver} -  Thrift port : 7612 {org.wso2.carbon.databridge.receiver.thrift.internal.ThriftDataReceiver}
TID: [0] [BAM] [2014-09-17 17:15:17,557]  INFO {org.wso2.carbon.core.transports.http.HttpsTransportListener} -  HTTPS port       : 9444 {org.wso2.carbon.core.transports.http.HttpsTransportListener}
TID: [0] [BAM] [2014-09-17 17:15:17,557]  INFO {org.wso2.carbon.core.transports.http.HttpTransportListener} -  HTTP port        : 9764 {org.wso2.carbon.core.transports.http.HttpTransportListener}
TID: [0] [BAM] [2014-09-17 17:15:17,639]  INFO {org.wso2.carbon.ntask.core.service.impl.TaskServiceImpl} -  Task service starting in STANDALONE mode... {org.wso2.carbon.ntask.core.service.impl.TaskServiceImpl}
TID: [0] [BAM] [2014-09-17 17:15:17,752]  INFO {org.wso2.carbon.core.init.JMXServerManager} -  JMX Service URL  : service:jmx:rmi://localhost:11112/jndi/rmi://localhost:10000/jmxrmi {org.wso2.carbon.core.init.JMXServerManager}
TID: [0] [BAM] [2014-09-17 17:15:17,752]  INFO {org.wso2.carbon.bam.toolbox.deployer.internal.ServerStartUpInspector} -  BAM Toolbox is ready to do deployments {org.wso2.carbon.bam.toolbox.deployer.internal.ServerStartUpInspector}
TID: [0] [BAM] [2014-09-17 17:15:17,757]  INFO {org.wso2.carbon.bam.toolbox.deployer.core.BAMToolBoxDeployer} -  /home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/repository/deployment/server/bam-toolbox {org.wso2.carbon.bam.toolbox.deployer.core.BAMToolBoxDeployer}
TID: [0] [BAM] [2014-09-17 17:15:17,780]  INFO {org.wso2.carbon.core.internal.StartupFinalizerServiceComponent} -  Server           :  WSO2 Business Activity Monitor-2.4.0 {org.wso2.carbon.core.internal.StartupFinalizerServiceComponent}
TID: [0] [BAM] [2014-09-17 17:15:17,780]  INFO {org.wso2.carbon.core.internal.StartupFinalizerServiceComponent} -  WSO2 Carbon started in 13 sec {org.wso2.carbon.core.internal.StartupFinalizerServiceComponent}
TID: [0] [BAM] [2014-09-17 17:15:18,719]  INFO {org.wso2.carbon.dashboard.common.oauth.GSOAuthModule} -  Using random key for OAuth client-side state encryption {org.wso2.carbon.dashboard.common.oauth.GSOAuthModule}
TID: [0] [BAM] [2014-09-17 17:15:19,014]  INFO {org.wso2.carbon.ui.internal.CarbonUIServiceComponent} -  Mgt Console URL  : https://10.100.5.90:9444/carbon/ {org.wso2.carbon.ui.internal.CarbonUIServiceComponent}
TID: [0] [BAM] [2014-09-17 17:15:19,014]  INFO {org.wso2.carbon.ui.internal.CarbonUIServiceComponent} -  Gadget Server Default Context : http://10.100.5.90:9764/portal {org.wso2.carbon.ui.internal.CarbonUIServiceComponent}
TID: [0] [BAM] [2014-09-17 17:15:39,521]  INFO {org.wso2.carbon.databridge.core.DataBridge} -  admin connected {org.wso2.carbon.databridge.core.DataBridge}
TID: [0] [BAM] [2014-09-17 17:15:51,156]  INFO {org.wso2.carbon.databridge.persistence.cassandra.datastore.ClusterFactory} -  Initializing cluster {org.wso2.carbon.databridge.persistence.cassandra.datastore.ClusterFactory}
TID: [0] [BAM] [2014-09-17 17:15:51,626]  INFO {org.wso2.carbon.databridge.persistence.cassandra.datastore.CassandraConnector} -  Saving Stream Definition : GitHub_Stream:1.0.0 {org.wso2.carbon.databridge.persistence.cassandra.datastore.CassandraConnector}
TID: [0] [BAM] [2014-09-17 17:15:51,646]  INFO {org.wso2.carbon.databridge.core.DataBridge} -  admin connected {org.wso2.carbon.databridge.core.DataBridge}
TID: [0] [BAM] [2014-09-17 17:15:51,849]  INFO {org.wso2.carbon.databridge.persistence.cassandra.datastore.CassandraConnector} -  Saving Stream Definition : GitHub_Commits_Stream:1.0.0 {org.wso2.carbon.databridge.persistence.cassandra.datastore.CassandraConnector}
TID: [0] [BAM] [2014-09-17 17:15:51,853]  INFO {org.wso2.carbon.databridge.core.DataBridge} -  admin connected {org.wso2.carbon.databridge.core.DataBridge}
TID: [0] [BAM] [2014-09-17 17:15:52,430]  INFO {org.wso2.carbon.databridge.persistence.cassandra.datastore.CassandraConnector} -  Saving Stream Definition : GitHub_Committers_Stream:1.0.0 {org.wso2.carbon.databridge.persistence.cassandra.datastore.CassandraConnector}
TID: [0] [BAM] [2014-09-17 17:15:52,439]  INFO {org.wso2.carbon.databridge.core.DataBridge} -  admin connected {org.wso2.carbon.databridge.core.DataBridge}
TID: [0] [BAM] [2014-09-17 17:15:52,604]  INFO {org.wso2.carbon.databridge.core.DataBridge} -  edae8739-e728-4b8a-83a7-d2f779181ab0 disconnected {org.wso2.carbon.databridge.core.DataBridge}
TID: [0] [BAM] [2014-09-17 17:16:35,680]  INFO {org.wso2.carbon.core.services.util.CarbonAuthenticationUtil} -  'admin@carbon.super [-1234]' logged in at [2014-09-17 17:16:35,680+0530] {org.wso2.carbon.core.services.util.CarbonAuthenticationUtil}
TID: [0] [BAM] [2014-09-17 17:17:20,112]  INFO {org.wso2.carbon.analytics.hive.ui.servlet.SaveCronExpression} -  10 * * * * ? * {org.wso2.carbon.analytics.hive.ui.servlet.SaveCronExpression}
TID: [0] [BAM] [2014-09-17 17:17:22,320]  INFO {org.wso2.carbon.ntask.core.impl.AbstractQuartzTaskManager} -  Task scheduled: [-1234][HIVE_TASK][ Github_Committers_MySQL] {org.wso2.carbon.ntask.core.impl.AbstractQuartzTaskManager}
TID: [0] [BAM] [2014-09-17 17:17:57,578]  INFO {org.wso2.carbon.analytics.hive.ui.servlet.SaveCronExpression} -  10 * * * * ? * {org.wso2.carbon.analytics.hive.ui.servlet.SaveCronExpression}
TID: [0] [BAM] [2014-09-17 17:17:59,075]  INFO {org.wso2.carbon.ntask.core.impl.AbstractQuartzTaskManager} -  Task scheduled: [-1234][HIVE_TASK][Github_Commits_MySQL] {org.wso2.carbon.ntask.core.impl.AbstractQuartzTaskManager}
TID: [0] [BAM] [2014-09-17 17:18:10,016]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 17:18:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:18:10,016]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 17:18:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:18:10,883] ERROR {org.apache.hadoop.hive.metastore.HiveMetaStore} -  JDO datastore error. Retrying metastore command after 1000 ms (attempt 1 of 1) {org.apache.hadoop.hive.metastore.HiveMetaStore}
TID: [0] [BAM] [2014-09-17 17:18:11,276] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.GithubCommitsTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:18:11,282] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.SummarizedGithubCommitsTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:18:11,391] ERROR {org.apache.hadoop.hive.cassandra.CassandraProxyClient} -  Error while trying to connect to cassandra host:localhost {org.apache.hadoop.hive.cassandra.CassandraProxyClient}
org.apache.hadoop.hive.cassandra.CassandraException: unable to connect to server
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:57)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.<init>(CassandraClientHolder.java:37)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.createConnection(CassandraProxyClient.java:181)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:207)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:183)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:54)
	... 25 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:351)
	at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:213)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:200)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
	at java.net.Socket.connect(Socket.java:529)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:178)
	... 27 more
TID: [0] [BAM] [2014-09-17 17:18:11,393] ERROR {org.apache.hadoop.hive.ql.exec.Task} -  FAILED: Error in metadata: java.lang.NullPointerException
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:546)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:223)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	... 17 more
 {org.apache.hadoop.hive.ql.exec.Task}
TID: [0] [BAM] [2014-09-17 17:18:11,394] ERROR {org.apache.hadoop.hive.ql.Driver} -  FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.apache.hadoop.hive.ql.Driver}
TID: [0] [BAM] [2014-09-17 17:18:11,395] ERROR {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl} -  Error while executing Hive script.
Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl}
java.sql.SQLException: Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:189)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:18:11,396] ERROR {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Error while executing script : Github_Commits_MySQL {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
org.wso2.carbon.analytics.hive.exception.HiveExecutionException: Error while executing Hive script.Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl.execute(HiveExecutorServiceImpl.java:115)
	at org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask.execute(HiveScriptExecutorTask.java:60)
	at org.wso2.carbon.ntask.core.impl.TaskQuartzJobAdapter.execute(TaskQuartzJobAdapter.java:67)
	at org.quartz.core.JobRunShell.run(JobRunShell.java:213)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:18:11,927] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.GitCommittersTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:18:11,941] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.summarizedGitCommittersTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:18:11,985] ERROR {org.apache.hadoop.hive.cassandra.CassandraProxyClient} -  Error while trying to connect to cassandra host:localhost {org.apache.hadoop.hive.cassandra.CassandraProxyClient}
org.apache.hadoop.hive.cassandra.CassandraException: unable to connect to server
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:57)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.<init>(CassandraClientHolder.java:37)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.createConnection(CassandraProxyClient.java:181)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:207)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:183)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:54)
	... 25 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:351)
	at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:213)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:200)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
	at java.net.Socket.connect(Socket.java:529)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:178)
	... 27 more
TID: [0] [BAM] [2014-09-17 17:18:11,987] ERROR {org.apache.hadoop.hive.ql.exec.Task} -  FAILED: Error in metadata: java.lang.NullPointerException
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:546)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:223)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	... 17 more
 {org.apache.hadoop.hive.ql.exec.Task}
TID: [0] [BAM] [2014-09-17 17:18:11,987] ERROR {org.apache.hadoop.hive.ql.Driver} -  FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.apache.hadoop.hive.ql.Driver}
TID: [0] [BAM] [2014-09-17 17:18:11,988] ERROR {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl} -  Error while executing Hive script.
Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl}
java.sql.SQLException: Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:189)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:18:11,988] ERROR {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Error while executing script :  Github_Committers_MySQL {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
org.wso2.carbon.analytics.hive.exception.HiveExecutionException: Error while executing Hive script.Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl.execute(HiveExecutorServiceImpl.java:115)
	at org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask.execute(HiveScriptExecutorTask.java:60)
	at org.wso2.carbon.ntask.core.impl.TaskQuartzJobAdapter.execute(TaskQuartzJobAdapter.java:67)
	at org.quartz.core.JobRunShell.run(JobRunShell.java:213)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:18:23,318]  INFO {org.wso2.carbon.analytics.hive.ui.servlet.SaveCronExpression} -  1 * * * * ? * {org.wso2.carbon.analytics.hive.ui.servlet.SaveCronExpression}
TID: [0] [BAM] [2014-09-17 17:18:24,542]  INFO {org.wso2.carbon.ntask.core.impl.AbstractQuartzTaskManager} -  Task scheduled: [-1234][HIVE_TASK][Gituhub_MySQL] {org.wso2.carbon.ntask.core.impl.AbstractQuartzTaskManager}
TID: [0] [BAM] [2014-09-17 17:19:01,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 17:19:01 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:19:01,040] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.GitStatsTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:19:01,044] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.summarizedGitTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:19:01,083] ERROR {org.apache.hadoop.hive.cassandra.CassandraProxyClient} -  Error while trying to connect to cassandra host:localhost {org.apache.hadoop.hive.cassandra.CassandraProxyClient}
org.apache.hadoop.hive.cassandra.CassandraException: unable to connect to server
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:57)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.<init>(CassandraClientHolder.java:37)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.createConnection(CassandraProxyClient.java:181)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:207)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:183)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:54)
	... 25 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:351)
	at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:213)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:200)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
	at java.net.Socket.connect(Socket.java:529)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:178)
	... 27 more
TID: [0] [BAM] [2014-09-17 17:19:01,085] ERROR {org.apache.hadoop.hive.ql.exec.Task} -  FAILED: Error in metadata: java.lang.NullPointerException
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:546)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:223)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	... 17 more
 {org.apache.hadoop.hive.ql.exec.Task}
TID: [0] [BAM] [2014-09-17 17:19:01,085] ERROR {org.apache.hadoop.hive.ql.Driver} -  FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.apache.hadoop.hive.ql.Driver}
TID: [0] [BAM] [2014-09-17 17:19:01,085] ERROR {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl} -  Error while executing Hive script.
Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl}
java.sql.SQLException: Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:189)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:19:01,086] ERROR {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Error while executing script : Gituhub_MySQL {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
org.wso2.carbon.analytics.hive.exception.HiveExecutionException: Error while executing Hive script.Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl.execute(HiveExecutorServiceImpl.java:115)
	at org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask.execute(HiveScriptExecutorTask.java:60)
	at org.wso2.carbon.ntask.core.impl.TaskQuartzJobAdapter.execute(TaskQuartzJobAdapter.java:67)
	at org.quartz.core.JobRunShell.run(JobRunShell.java:213)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:19:02,687]  INFO {org.wso2.carbon.analytics.hive.ui.servlet.SaveCronExpression} -  10 * * * * ? * {org.wso2.carbon.analytics.hive.ui.servlet.SaveCronExpression}
TID: [0] [BAM] [2014-09-17 17:19:02,726]  INFO {org.wso2.carbon.ntask.core.impl.AbstractQuartzTaskManager} -  Task deleted: [-1234][HIVE_TASK][Gituhub_MySQL] {org.wso2.carbon.ntask.core.impl.AbstractQuartzTaskManager}
TID: [0] [BAM] [2014-09-17 17:19:02,739]  INFO {org.wso2.carbon.ntask.core.impl.AbstractQuartzTaskManager} -  Task scheduled: [-1234][HIVE_TASK][Gituhub_MySQL] {org.wso2.carbon.ntask.core.impl.AbstractQuartzTaskManager}
TID: [0] [BAM] [2014-09-17 17:19:05,125] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.GitCommittersTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:19:05,129] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.summarizedGitCommittersTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:19:05,175] ERROR {org.apache.hadoop.hive.cassandra.CassandraProxyClient} -  Error while trying to connect to cassandra host:localhost {org.apache.hadoop.hive.cassandra.CassandraProxyClient}
org.apache.hadoop.hive.cassandra.CassandraException: unable to connect to server
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:57)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.<init>(CassandraClientHolder.java:37)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.createConnection(CassandraProxyClient.java:181)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:207)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:183)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:54)
	... 25 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:351)
	at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:213)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:200)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
	at java.net.Socket.connect(Socket.java:529)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:178)
	... 27 more
TID: [0] [BAM] [2014-09-17 17:19:05,176] ERROR {org.apache.hadoop.hive.ql.exec.Task} -  FAILED: Error in metadata: java.lang.NullPointerException
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:546)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:223)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	... 17 more
 {org.apache.hadoop.hive.ql.exec.Task}
TID: [0] [BAM] [2014-09-17 17:19:05,177] ERROR {org.apache.hadoop.hive.ql.Driver} -  FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.apache.hadoop.hive.ql.Driver}
TID: [0] [BAM] [2014-09-17 17:19:05,177] ERROR {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl} -  Error while executing Hive script.
Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl}
java.sql.SQLException: Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:189)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:19:05,187] ERROR {org.wso2.carbon.analytics.hive.ui.client.HiveExecutionClient} -  Error while executing Hive script.Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.wso2.carbon.analytics.hive.ui.client.HiveExecutionClient}
org.wso2.carbon.analytics.hive.stub.HiveExecutionServiceHiveExecutionException: HiveExecutionServiceHiveExecutionException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
	at java.lang.Class.newInstance0(Class.java:357)
	at java.lang.Class.newInstance(Class.java:310)
	at org.wso2.carbon.analytics.hive.stub.HiveExecutionServiceStub.executeHiveScript(HiveExecutionServiceStub.java:216)
	at org.wso2.carbon.analytics.hive.ui.client.HiveExecutionClient.executeScript(HiveExecutionClient.java:66)
	at org.apache.jsp.hive_002dexplorer.executeQuery_jsp._jspService(org.apache.jsp.hive_002dexplorer.executeQuery_jsp:129)
	at org.apache.jasper.runtime.HttpJspBase.service(HttpJspBase.java:111)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.apache.jasper.servlet.JspServletWrapper.service(JspServletWrapper.java:403)
	at org.apache.jasper.servlet.JspServlet.serviceJspFile(JspServlet.java:492)
	at org.apache.jasper.servlet.JspServlet.service(JspServlet.java:378)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.wso2.carbon.ui.JspServlet.service(JspServlet.java:155)
	at org.wso2.carbon.ui.TilesJspServlet.service(TilesJspServlet.java:80)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.eclipse.equinox.http.helper.ContextPathServletAdaptor.service(ContextPathServletAdaptor.java:37)
	at org.eclipse.equinox.http.servlet.internal.ServletRegistration.service(ServletRegistration.java:61)
	at org.eclipse.equinox.http.servlet.internal.ProxyServlet.processAlias(ProxyServlet.java:128)
	at org.eclipse.equinox.http.servlet.internal.ProxyServlet.service(ProxyServlet.java:68)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.wso2.carbon.tomcat.ext.servlet.DelegationServlet.service(DelegationServlet.java:68)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:305)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.apache.catalina.core.ApplicationDispatcher.invoke(ApplicationDispatcher.java:749)
	at org.apache.catalina.core.ApplicationDispatcher.doInclude(ApplicationDispatcher.java:605)
	at org.apache.catalina.core.ApplicationDispatcher.include(ApplicationDispatcher.java:544)
	at org.eclipse.equinox.http.servlet.internal.RequestDispatcherAdaptor.include(RequestDispatcherAdaptor.java:37)
	at org.eclipse.equinox.http.helper.ContextPathServletAdaptor$RequestDispatcherAdaptor.include(ContextPathServletAdaptor.java:369)
	at org.apache.jasper.runtime.JspRuntimeLibrary.include(JspRuntimeLibrary.java:1015)
	at org.apache.jasper.runtime.PageContextImpl.include(PageContextImpl.java:700)
	at sun.reflect.GeneratedMethodAccessor51.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.tiles.jsp.context.JspUtil.doInclude(JspUtil.java:87)
	at org.apache.tiles.jsp.context.JspTilesRequestContext.include(JspTilesRequestContext.java:88)
	at org.apache.tiles.jsp.context.JspTilesRequestContext.dispatch(JspTilesRequestContext.java:82)
	at org.apache.tiles.impl.BasicTilesContainer.render(BasicTilesContainer.java:465)
	at org.apache.tiles.jsp.taglib.InsertAttributeTag.render(InsertAttributeTag.java:140)
	at org.apache.tiles.jsp.taglib.InsertAttributeTag.render(InsertAttributeTag.java:117)
	at org.apache.tiles.jsp.taglib.RenderTagSupport.execute(RenderTagSupport.java:171)
	at org.apache.tiles.jsp.taglib.RoleSecurityTagSupport.doEndTag(RoleSecurityTagSupport.java:75)
	at org.apache.tiles.jsp.taglib.ContainerTagSupport.doEndTag(ContainerTagSupport.java:80)
	at org.apache.jsp.admin.layout.template_jsp._jspx_meth_tiles_insertAttribute_7(org.apache.jsp.admin.layout.template_jsp:603)
	at org.apache.jsp.admin.layout.template_jsp._jspService(org.apache.jsp.admin.layout.template_jsp:335)
	at org.apache.jasper.runtime.HttpJspBase.service(HttpJspBase.java:111)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.apache.jasper.servlet.JspServletWrapper.service(JspServletWrapper.java:403)
	at org.apache.jasper.servlet.JspServlet.serviceJspFile(JspServlet.java:492)
	at org.apache.jasper.servlet.JspServlet.service(JspServlet.java:378)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.wso2.carbon.ui.JspServlet.service(JspServlet.java:155)
	at org.wso2.carbon.ui.TilesJspServlet.service(TilesJspServlet.java:80)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.eclipse.equinox.http.helper.ContextPathServletAdaptor.service(ContextPathServletAdaptor.java:37)
	at org.eclipse.equinox.http.servlet.internal.ServletRegistration.service(ServletRegistration.java:61)
	at org.eclipse.equinox.http.servlet.internal.ProxyServlet.processAlias(ProxyServlet.java:128)
	at org.eclipse.equinox.http.servlet.internal.ProxyServlet.service(ProxyServlet.java:68)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.wso2.carbon.tomcat.ext.servlet.DelegationServlet.service(DelegationServlet.java:68)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:305)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.apache.catalina.core.ApplicationDispatcher.invoke(ApplicationDispatcher.java:749)
	at org.apache.catalina.core.ApplicationDispatcher.processRequest(ApplicationDispatcher.java:487)
	at org.apache.catalina.core.ApplicationDispatcher.doForward(ApplicationDispatcher.java:412)
	at org.apache.catalina.core.ApplicationDispatcher.forward(ApplicationDispatcher.java:339)
	at org.eclipse.equinox.http.servlet.internal.RequestDispatcherAdaptor.forward(RequestDispatcherAdaptor.java:30)
	at org.eclipse.equinox.http.helper.ContextPathServletAdaptor$RequestDispatcherAdaptor.forward(ContextPathServletAdaptor.java:362)
	at org.apache.tiles.servlet.context.ServletTilesRequestContext.forward(ServletTilesRequestContext.java:198)
	at org.apache.tiles.servlet.context.ServletTilesRequestContext.dispatch(ServletTilesRequestContext.java:185)
	at org.apache.tiles.impl.BasicTilesContainer.render(BasicTilesContainer.java:419)
	at org.apache.tiles.impl.BasicTilesContainer.render(BasicTilesContainer.java:370)
	at org.wso2.carbon.ui.action.ActionHelper.render(ActionHelper.java:52)
	at org.wso2.carbon.ui.TilesJspServlet.service(TilesJspServlet.java:101)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.eclipse.equinox.http.helper.ContextPathServletAdaptor.service(ContextPathServletAdaptor.java:37)
	at org.eclipse.equinox.http.servlet.internal.ServletRegistration.service(ServletRegistration.java:61)
	at org.eclipse.equinox.http.servlet.internal.ProxyServlet.processAlias(ProxyServlet.java:128)
	at org.eclipse.equinox.http.servlet.internal.ProxyServlet.service(ProxyServlet.java:68)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.wso2.carbon.tomcat.ext.servlet.DelegationServlet.service(DelegationServlet.java:68)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:305)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.wso2.carbon.tomcat.ext.filter.CharacterSetFilter.doFilter(CharacterSetFilter.java:61)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:222)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:123)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:472)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:171)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:99)
	at org.wso2.carbon.tomcat.ext.valves.CompositeValve.continueInvocation(CompositeValve.java:178)
	at org.wso2.carbon.tomcat.ext.valves.CarbonTomcatValve$1.invoke(CarbonTomcatValve.java:47)
	at org.wso2.carbon.webapp.mgt.TenantLazyLoaderValve.invoke(TenantLazyLoaderValve.java:56)
	at org.wso2.carbon.tomcat.ext.valves.TomcatValveContainer.invokeValves(TomcatValveContainer.java:47)
	at org.wso2.carbon.tomcat.ext.valves.CompositeValve.invoke(CompositeValve.java:141)
	at org.wso2.carbon.tomcat.ext.valves.CarbonStuckThreadDetectionValve.invoke(CarbonStuckThreadDetectionValve.java:156)
	at org.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:936)
	at org.wso2.carbon.tomcat.ext.valves.CarbonContextCreatorValve.invoke(CarbonContextCreatorValve.java:52)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:118)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:407)
	at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1004)
	at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:589)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1653)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:19:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 17:19:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:19:10,007]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 17:19:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:19:10,010]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 17:19:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:19:10,033] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.GitCommittersTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:19:10,041] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.summarizedGitCommittersTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:19:10,042] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.GithubCommitsTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:19:10,056] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.SummarizedGithubCommitsTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:19:10,056] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.GitStatsTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:19:10,070] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.summarizedGitTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:19:10,117] ERROR {org.apache.hadoop.hive.cassandra.CassandraProxyClient} -  Error while trying to connect to cassandra host:localhost {org.apache.hadoop.hive.cassandra.CassandraProxyClient}
org.apache.hadoop.hive.cassandra.CassandraException: unable to connect to server
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:57)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.<init>(CassandraClientHolder.java:37)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.createConnection(CassandraProxyClient.java:181)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:207)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:183)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:54)
	... 25 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:351)
	at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:213)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:200)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
	at java.net.Socket.connect(Socket.java:529)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:178)
	... 27 more
TID: [0] [BAM] [2014-09-17 17:19:10,119] ERROR {org.apache.hadoop.hive.ql.exec.Task} -  FAILED: Error in metadata: java.lang.NullPointerException
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:546)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:223)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	... 17 more
 {org.apache.hadoop.hive.ql.exec.Task}
TID: [0] [BAM] [2014-09-17 17:19:10,119] ERROR {org.apache.hadoop.hive.ql.Driver} -  FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.apache.hadoop.hive.ql.Driver}
TID: [0] [BAM] [2014-09-17 17:19:10,119] ERROR {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl} -  Error while executing Hive script.
Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl}
java.sql.SQLException: Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:189)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:19:10,120] ERROR {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Error while executing script :  Github_Committers_MySQL {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
org.wso2.carbon.analytics.hive.exception.HiveExecutionException: Error while executing Hive script.Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl.execute(HiveExecutorServiceImpl.java:115)
	at org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask.execute(HiveScriptExecutorTask.java:60)
	at org.wso2.carbon.ntask.core.impl.TaskQuartzJobAdapter.execute(TaskQuartzJobAdapter.java:67)
	at org.quartz.core.JobRunShell.run(JobRunShell.java:213)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:19:10,161] ERROR {org.apache.hadoop.hive.cassandra.CassandraProxyClient} -  Error while trying to connect to cassandra host:localhost {org.apache.hadoop.hive.cassandra.CassandraProxyClient}
org.apache.hadoop.hive.cassandra.CassandraException: unable to connect to server
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:57)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.<init>(CassandraClientHolder.java:37)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.createConnection(CassandraProxyClient.java:181)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:207)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:183)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:54)
	... 25 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:351)
	at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:213)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:200)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
	at java.net.Socket.connect(Socket.java:529)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:178)
	... 27 more
TID: [0] [BAM] [2014-09-17 17:19:10,162] ERROR {org.apache.hadoop.hive.ql.exec.Task} -  FAILED: Error in metadata: java.lang.NullPointerException
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:546)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:223)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	... 17 more
 {org.apache.hadoop.hive.ql.exec.Task}
TID: [0] [BAM] [2014-09-17 17:19:10,163] ERROR {org.apache.hadoop.hive.ql.Driver} -  FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.apache.hadoop.hive.ql.Driver}
TID: [0] [BAM] [2014-09-17 17:19:10,163] ERROR {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl} -  Error while executing Hive script.
Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl}
java.sql.SQLException: Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:189)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:19:10,164] ERROR {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Error while executing script : Github_Commits_MySQL {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
org.wso2.carbon.analytics.hive.exception.HiveExecutionException: Error while executing Hive script.Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl.execute(HiveExecutorServiceImpl.java:115)
	at org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask.execute(HiveScriptExecutorTask.java:60)
	at org.wso2.carbon.ntask.core.impl.TaskQuartzJobAdapter.execute(TaskQuartzJobAdapter.java:67)
	at org.quartz.core.JobRunShell.run(JobRunShell.java:213)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:19:10,166] ERROR {org.apache.hadoop.hive.cassandra.CassandraProxyClient} -  Error while trying to connect to cassandra host:localhost {org.apache.hadoop.hive.cassandra.CassandraProxyClient}
org.apache.hadoop.hive.cassandra.CassandraException: unable to connect to server
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:57)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.<init>(CassandraClientHolder.java:37)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.createConnection(CassandraProxyClient.java:181)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:207)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:183)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:54)
	... 25 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:351)
	at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:213)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:200)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
	at java.net.Socket.connect(Socket.java:529)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:178)
	... 27 more
TID: [0] [BAM] [2014-09-17 17:19:10,167] ERROR {org.apache.hadoop.hive.ql.exec.Task} -  FAILED: Error in metadata: java.lang.NullPointerException
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:546)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:223)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	... 17 more
 {org.apache.hadoop.hive.ql.exec.Task}
TID: [0] [BAM] [2014-09-17 17:19:10,167] ERROR {org.apache.hadoop.hive.ql.Driver} -  FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.apache.hadoop.hive.ql.Driver}
TID: [0] [BAM] [2014-09-17 17:19:10,167] ERROR {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl} -  Error while executing Hive script.
Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl}
java.sql.SQLException: Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:189)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:19:10,168] ERROR {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Error while executing script : Gituhub_MySQL {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
org.wso2.carbon.analytics.hive.exception.HiveExecutionException: Error while executing Hive script.Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl.execute(HiveExecutorServiceImpl.java:115)
	at org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask.execute(HiveScriptExecutorTask.java:60)
	at org.wso2.carbon.ntask.core.impl.TaskQuartzJobAdapter.execute(TaskQuartzJobAdapter.java:67)
	at org.quartz.core.JobRunShell.run(JobRunShell.java:213)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:19:34,774]  INFO {org.apache.cassandra.thrift.CassandraDaemon} -  Stop listening to thrift clients {org.apache.cassandra.thrift.CassandraDaemon}
TID: [0] [BAM] [2014-09-17 17:19:34,777]  INFO {org.wso2.carbon.core.init.CarbonServerManager} -  Shutdown hook triggered.... {org.wso2.carbon.core.init.CarbonServerManager}
TID: [0] [BAM] [2014-09-17 17:19:34,781]  INFO {org.wso2.carbon.core.init.CarbonServerManager} -  Gracefully shutting down WSO2 Business Activity Monitor... {org.wso2.carbon.core.init.CarbonServerManager}
TID: [0] [BAM] [2014-09-17 17:19:34,781]  INFO {org.apache.cassandra.gms.Gossiper} -  Announcing shutdown {org.apache.cassandra.gms.Gossiper}
TID: [0] [BAM] [2014-09-17 17:19:34,787]  INFO {org.wso2.carbon.core.ServerManagement} -  Starting to switch to maintenance mode... {org.wso2.carbon.core.ServerManagement}
TID: [0] [BAM] [2014-09-17 17:19:34,788]  INFO {org.wso2.carbon.core.ServerManagement} -  Stopped all transport listeners {org.wso2.carbon.core.ServerManagement}
TID: [0] [BAM] [2014-09-17 17:19:34,788]  INFO {org.wso2.carbon.core.ServerManagement} -  Waiting for request service completion... {org.wso2.carbon.core.ServerManagement}
TID: [0] [BAM] [2014-09-17 17:19:34,792]  INFO {org.wso2.carbon.core.ServerManagement} -  All requests have been served. {org.wso2.carbon.core.ServerManagement}
TID: [0] [BAM] [2014-09-17 17:19:34,792]  INFO {org.wso2.carbon.core.ServerManagement} -  Waiting for deployment completion... {org.wso2.carbon.core.ServerManagement}
TID: [0] [BAM] [2014-09-17 17:19:34,837]  INFO {org.wso2.carbon.webapp.mgt.WebApplication} -  Unloaded webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/STRATOS_ROOT] {org.wso2.carbon.webapp.mgt.WebApplication}
TID: [0] [BAM] [2014-09-17 17:19:34,839]  INFO {org.springframework.web.context.support.XmlWebApplicationContext} -  Closing Root WebApplicationContext: startup date [Wed Sep 17 17:15:14 IST 2014]; root of context hierarchy {org.springframework.web.context.support.XmlWebApplicationContext}
TID: [0] [BAM] [2014-09-17 17:19:34,848]  INFO {org.springframework.beans.factory.support.DefaultListableBeanFactory} -  Destroying singletons in org.springframework.beans.factory.support.DefaultListableBeanFactory@2ec18c31: defining beans [cxf,org.apache.cxf.bus.spring.BusWiringBeanFactoryPostProcessor,org.apache.cxf.bus.spring.Jsr250BeanPostProcessor,org.apache.cxf.bus.spring.BusExtensionPostProcessor,dataReceiverStreamsService,dataReceiverStreamService,streamsBean,streamBean]; root of factory hierarchy {org.springframework.beans.factory.support.DefaultListableBeanFactory}
TID: [0] [BAM] [2014-09-17 17:19:34,879]  INFO {org.wso2.carbon.webapp.mgt.WebApplication} -  Unloaded webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/datareceiver] {org.wso2.carbon.webapp.mgt.WebApplication}
TID: [0] [BAM] [2014-09-17 17:19:34,895]  INFO {org.wso2.carbon.webapp.mgt.WebApplication} -  Unloaded webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/bamdashboards] {org.wso2.carbon.webapp.mgt.WebApplication}
TID: [0] [BAM] [2014-09-17 17:19:34,905]  INFO {org.wso2.carbon.webapp.mgt.WebApplication} -  Unloaded webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/activitymonitoring] {org.wso2.carbon.webapp.mgt.WebApplication}
TID: [0] [BAM] [2014-09-17 17:19:34,906]  INFO {org.wso2.carbon.core.ServerManagement} -  All deployment tasks have been completed. {org.wso2.carbon.core.ServerManagement}
TID: [0] [BAM] [2014-09-17 17:19:34,906]  INFO {org.wso2.carbon.core.ServerManagement} -  Waiting for server task completion... {org.wso2.carbon.core.ServerManagement}
TID: [0] [BAM] [2014-09-17 17:19:34,912]  INFO {org.wso2.carbon.core.ServerManagement} -  All server tasks have been completed. {org.wso2.carbon.core.ServerManagement}
TID: [0] [BAM] [2014-09-17 17:19:34,912]  INFO {org.wso2.carbon.core.init.CarbonServerManager} -  Shutting down WSO2 Business Activity Monitor... {org.wso2.carbon.core.init.CarbonServerManager}
TID: [0] [BAM] [2014-09-17 17:19:34,912]  INFO {org.wso2.carbon.core.init.CarbonServerManager} -  Shutting down OSGi framework... {org.wso2.carbon.core.init.CarbonServerManager}
TID: [0] [BAM] [2014-09-17 17:19:34,946]  INFO {org.wso2.carbon.databridge.receiver.thrift.internal.ThriftDataReceiverDS} -  Thrift server shutting down... {org.wso2.carbon.databridge.receiver.thrift.internal.ThriftDataReceiverDS}
TID: [0] [BAM] [2014-09-17 17:19:35,782]  INFO {org.apache.cassandra.net.MessagingService} -  Waiting for messaging service to quiesce {org.apache.cassandra.net.MessagingService}
TID: [0] [BAM] [2014-09-17 17:19:35,783]  INFO {org.apache.cassandra.net.MessagingService} -  MessagingService shutting down server thread. {org.apache.cassandra.net.MessagingService}
TID: [0] [BAM] [2014-09-17 17:19:37,123]  INFO {org.wso2.carbon.core.init.CarbonServerManager} -  Stopping CarbonServerManager... {org.wso2.carbon.core.init.CarbonServerManager}
TID: [0] [BAM] [2014-09-17 17:19:37,124]  INFO {org.apache.axis2.transport.tcp.TCPTransportSender} -  TCP Sender Shutdown {org.apache.axis2.transport.tcp.TCPTransportSender}
TID: [0] [BAM] [2014-09-17 17:19:37,371]  INFO {org.wso2.carbon.tomcat.ext.internal.CarbonTomcatServiceComponent} -  Stopping the carbon web-app registered under : / {org.wso2.carbon.tomcat.ext.internal.CarbonTomcatServiceComponent}
TID: [0] [BAM] [2014-09-17 17:19:37,748]  INFO {org.wso2.carbon.core.init.CarbonServerManager} -  Shutdown complete {org.wso2.carbon.core.init.CarbonServerManager}
TID: [0] [BAM] [2014-09-17 17:19:37,748]  INFO {org.wso2.carbon.core.init.CarbonServerManager} -  Halting JVM {org.wso2.carbon.core.init.CarbonServerManager}
TID: [0] [BAM] [2014-09-17 17:20:01,841]  INFO {org.wso2.carbon.core.internal.CarbonCoreActivator} -  Starting WSO2 Carbon... {org.wso2.carbon.core.internal.CarbonCoreActivator}
TID: [0] [BAM] [2014-09-17 17:20:01,842]  INFO {org.wso2.carbon.core.internal.CarbonCoreActivator} -  Operating System : Linux 3.13.0-24-generic, amd64 {org.wso2.carbon.core.internal.CarbonCoreActivator}
TID: [0] [BAM] [2014-09-17 17:20:01,842]  INFO {org.wso2.carbon.core.internal.CarbonCoreActivator} -  Java Home        : /usr/lib/jvm/java-6-oracle/jre {org.wso2.carbon.core.internal.CarbonCoreActivator}
TID: [0] [BAM] [2014-09-17 17:20:01,843]  INFO {org.wso2.carbon.core.internal.CarbonCoreActivator} -  Java Version     : 1.6.0_45 {org.wso2.carbon.core.internal.CarbonCoreActivator}
TID: [0] [BAM] [2014-09-17 17:20:01,843]  INFO {org.wso2.carbon.core.internal.CarbonCoreActivator} -  Java VM          : Java HotSpot(TM) 64-Bit Server VM 20.45-b01,Sun Microsystems Inc. {org.wso2.carbon.core.internal.CarbonCoreActivator}
TID: [0] [BAM] [2014-09-17 17:20:01,843]  INFO {org.wso2.carbon.core.internal.CarbonCoreActivator} -  Carbon Home      : /home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0 {org.wso2.carbon.core.internal.CarbonCoreActivator}
TID: [0] [BAM] [2014-09-17 17:20:01,843]  INFO {org.wso2.carbon.core.internal.CarbonCoreActivator} -  Java Temp Dir    : /home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/tmp {org.wso2.carbon.core.internal.CarbonCoreActivator}
TID: [0] [BAM] [2014-09-17 17:20:01,843]  INFO {org.wso2.carbon.core.internal.CarbonCoreActivator} -  User             : denuwanthi, en-US, Asia/Colombo {org.wso2.carbon.core.internal.CarbonCoreActivator}
TID: [0] [BAM] [2014-09-17 17:20:01,899]  WARN {org.wso2.carbon.core.bootup.validator.util.ValidationResultPrinter} -  The default keystore (wso2carbon.jks) is currently being used. To maximize security when deploying to a production environment, configure a new keystore with a unique password in the production server profile. {org.wso2.carbon.core.bootup.validator.util.ValidationResultPrinter}
TID: [0] [BAM] [2014-09-17 17:20:01,925]  INFO {org.wso2.carbon.databridge.agent.thrift.AgentHolder} -  Agent created ! {org.wso2.carbon.databridge.agent.thrift.AgentHolder}
TID: [0] [BAM] [2014-09-17 17:20:01,984]  INFO {org.wso2.carbon.databridge.agent.thrift.internal.AgentDS} -  Successfully deployed Agent Client {org.wso2.carbon.databridge.agent.thrift.internal.AgentDS}
TID: [0] [BAM] [2014-09-17 17:20:03,151]  INFO {org.wso2.carbon.bam.toolbox.deployer.internal.DataBridgeRecieverServiceComponent} -  Successfully setted data bridge reciever service {org.wso2.carbon.bam.toolbox.deployer.internal.DataBridgeRecieverServiceComponent}
TID: [0] [BAM] [2014-09-17 17:20:03,160]  INFO {org.wso2.carbon.databridge.core.internal.DataBridgeDS} -  Successfully deployed Agent Server  {org.wso2.carbon.databridge.core.internal.DataBridgeDS}
TID: [0] [BAM] [2014-09-17 17:20:03,318]  INFO {org.wso2.carbon.registry.core.jdbc.EmbeddedRegistryService} -  Configured Registry in 65ms {org.wso2.carbon.registry.core.jdbc.EmbeddedRegistryService}
TID: [0] [BAM] [2014-09-17 17:20:03,438]  INFO {org.wso2.carbon.registry.core.internal.RegistryCoreServiceComponent} -  Registry Mode    : READ-WRITE {org.wso2.carbon.registry.core.internal.RegistryCoreServiceComponent}
TID: [0] [BAM] [2014-09-17 17:20:03,978]  INFO {org.wso2.carbon.user.core.internal.UserStoreMgtDSComponent} -  Carbon UserStoreMgtDSComponent activated successfully. {org.wso2.carbon.user.core.internal.UserStoreMgtDSComponent}
TID: [0] [BAM] [2014-09-17 17:20:04,547]  INFO {org.apache.cassandra.net.MessagingService} -  Starting Messaging Service on port 7001 {org.apache.cassandra.net.MessagingService}
TID: [0] [BAM] [2014-09-17 17:20:04,592]  INFO {org.apache.cassandra.thrift.CassandraDaemon} -  Binding thrift service to localhost/127.0.0.1:9161 {org.apache.cassandra.thrift.CassandraDaemon}
TID: [0] [BAM] [2014-09-17 17:20:04,592]  INFO {org.apache.cassandra.thrift.CassandraDaemon} -  Using TFastFramedTransport with a max frame size of 15728640 bytes. {org.apache.cassandra.thrift.CassandraDaemon}
TID: [0] [BAM] [2014-09-17 17:20:04,594]  INFO {org.apache.cassandra.thrift.CassandraDaemon} -  Using synchronous/threadpool thrift server on localhost/127.0.0.1 : 9161 {org.apache.cassandra.thrift.CassandraDaemon}
TID: [0] [BAM] [2014-09-17 17:20:04,594]  INFO {org.wso2.carbon.cassandra.server.CassandraServerController} -  Cassandra Server Controller Thread was destroyed successfully {org.wso2.carbon.cassandra.server.CassandraServerController}
TID: [0] [BAM] [2014-09-17 17:20:04,594]  INFO {org.apache.cassandra.thrift.CassandraDaemon} -  Listening for thrift clients... {org.apache.cassandra.thrift.CassandraDaemon}
TID: [0] [BAM] [2014-09-17 17:20:07,901]  INFO {org.apache.axis2.deployment.ClusterBuilder} -  Clustering has been disabled {org.apache.axis2.deployment.ClusterBuilder}
TID: [0] [BAM] [2014-09-17 17:20:08,058]  INFO {org.wso2.carbon.identity.user.store.configuration.deployer.UserStoreConfigurationDeployer} -  User Store Configuration Deployer initiated. {org.wso2.carbon.identity.user.store.configuration.deployer.UserStoreConfigurationDeployer}
TID: [0] [BAM] [2014-09-17 17:20:08,093]  INFO {org.wso2.carbon.stratos.landing.page.deployer.LandingPageWebappDeployer} -  Deployed product landing page webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/home] {org.wso2.carbon.stratos.landing.page.deployer.LandingPageWebappDeployer}
TID: [0] [BAM] [2014-09-17 17:20:08,098]  INFO {org.apache.axis2.transport.tcp.TCPTransportSender} -  TCP Sender started {org.apache.axis2.transport.tcp.TCPTransportSender}
TID: [0] [BAM] [2014-09-17 17:20:08,130]  INFO {org.wso2.carbon.webapp.mgt.TomcatGenericWebappsDeployer} -  Deployed webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/STRATOS_ROOT].File[/home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/repository/deployment/server/webapps/STRATOS_ROOT] {org.wso2.carbon.webapp.mgt.TomcatGenericWebappsDeployer}
TID: [0] [BAM] [2014-09-17 17:20:08,717]  INFO {org.springframework.web.context.support.XmlWebApplicationContext} -  Refreshing Root WebApplicationContext: startup date [Wed Sep 17 17:20:08 IST 2014]; root of context hierarchy {org.springframework.web.context.support.XmlWebApplicationContext}
TID: [0] [BAM] [2014-09-17 17:20:08,759]  INFO {org.springframework.beans.factory.xml.XmlBeanDefinitionReader} -  Loading XML bean definitions from class path resource [META-INF/cxf/cxf.xml] {org.springframework.beans.factory.xml.XmlBeanDefinitionReader}
TID: [0] [BAM] [2014-09-17 17:20:08,825]  INFO {org.springframework.beans.factory.xml.XmlBeanDefinitionReader} -  Loading XML bean definitions from URL [jndi:/localhost/datareceiver/WEB-INF/cxf-servlet.xml] {org.springframework.beans.factory.xml.XmlBeanDefinitionReader}
TID: [0] [BAM] [2014-09-17 17:20:09,053]  INFO {org.springframework.beans.factory.support.DefaultListableBeanFactory} -  Pre-instantiating singletons in org.springframework.beans.factory.support.DefaultListableBeanFactory@385144d5: defining beans [cxf,org.apache.cxf.bus.spring.BusWiringBeanFactoryPostProcessor,org.apache.cxf.bus.spring.Jsr250BeanPostProcessor,org.apache.cxf.bus.spring.BusExtensionPostProcessor,dataReceiverStreamsService,dataReceiverStreamService,streamsBean,streamBean]; root of factory hierarchy {org.springframework.beans.factory.support.DefaultListableBeanFactory}
TID: [0] [BAM] [2014-09-17 17:20:09,329]  INFO {org.apache.cxf.endpoint.ServerImpl} -  Setting the server's publish address to be /streams {org.apache.cxf.endpoint.ServerImpl}
TID: [0] [BAM] [2014-09-17 17:20:09,373]  INFO {org.apache.cxf.endpoint.ServerImpl} -  Setting the server's publish address to be /stream {org.apache.cxf.endpoint.ServerImpl}
TID: [0] [BAM] [2014-09-17 17:20:09,379]  INFO {org.wso2.carbon.webapp.mgt.TomcatGenericWebappsDeployer} -  Deployed webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/datareceiver].File[/home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/repository/deployment/server/webapps/datareceiver.war] {org.wso2.carbon.webapp.mgt.TomcatGenericWebappsDeployer}
TID: [0] [BAM] [2014-09-17 17:20:09,963]  INFO {org.jaggeryjs.jaggery.app.mgt.TomcatJaggeryWebappsDeployer} -  Deployed webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/bamdashboards].File[/home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/repository/deployment/server/jaggeryapps/bamdashboards] {org.jaggeryjs.jaggery.app.mgt.TomcatJaggeryWebappsDeployer}
TID: [0] [BAM] [2014-09-17 17:20:10,006]  INFO {org.jaggeryjs.jaggery.app.mgt.TomcatJaggeryWebappsDeployer} -  Deployed webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/activitymonitoring].File[/home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/repository/deployment/server/jaggeryapps/activitymonitoring] {org.jaggeryjs.jaggery.app.mgt.TomcatJaggeryWebappsDeployer}
TID: [0] [BAM] [2014-09-17 17:20:10,099]  INFO {org.apache.axis2.deployment.ModuleDeployer} -  Deploying module: rampart-1.6.1-wso2v10 - file:/home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/repository/deployment/client/modules/rampart-1.6.1-wso2v10.mar {org.apache.axis2.deployment.ModuleDeployer}
TID: [0] [BAM] [2014-09-17 17:20:10,103]  INFO {org.apache.axis2.deployment.ModuleDeployer} -  Deploying module: addressing-1.6.1-wso2v10 - file:/home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/repository/deployment/client/modules/addressing-1.6.1-wso2v10.mar {org.apache.axis2.deployment.ModuleDeployer}
TID: [0] [BAM] [2014-09-17 17:20:10,105]  INFO {org.apache.axis2.transport.tcp.TCPTransportSender} -  TCP Sender started {org.apache.axis2.transport.tcp.TCPTransportSender}
TID: [0] [BAM] [2014-09-17 17:20:10,327]  INFO {org.wso2.carbon.core.deployment.DeploymentInterceptor} -  Deploying Axis2 service: BAMMessageStoreService {super-tenant} {org.wso2.carbon.core.deployment.DeploymentInterceptor}
TID: [0] [BAM] [2014-09-17 17:20:10,382]  INFO {org.apache.axis2.deployment.DeploymentEngine} -  Deploying Web service: org.wso2.carbon.bam.messagestore -  {org.apache.axis2.deployment.DeploymentEngine}
TID: [0] [BAM] [2014-09-17 17:20:10,581]  INFO {org.wso2.carbon.core.deployment.DeploymentInterceptor} -  Deploying Axis2 service: CassandraSearchAdmin {super-tenant} {org.wso2.carbon.core.deployment.DeploymentInterceptor}
TID: [0] [BAM] [2014-09-17 17:20:10,723]  INFO {org.apache.axis2.deployment.DeploymentEngine} -  Deploying Web service: org.wso2.carbon.cassandra.search.mgt -  {org.apache.axis2.deployment.DeploymentEngine}
TID: [0] [BAM] [2014-09-17 17:20:11,441]  INFO {org.wso2.carbon.core.init.CarbonServerManager} -  Repository       : /home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/repository/deployment/server/ {org.wso2.carbon.core.init.CarbonServerManager}
TID: [0] [BAM] [2014-09-17 17:20:11,464]  INFO {org.wso2.carbon.bam.toolbox.deployer.internal.BAMToolBoxDeployerComponent} -  Successfully Started BAM Toolbox Deployer {org.wso2.carbon.bam.toolbox.deployer.internal.BAMToolBoxDeployerComponent}
TID: [0] [BAM] [2014-09-17 17:20:11,496]  INFO {org.wso2.carbon.core.internal.permission.update.PermissionUpdater} -  Permission cache updated for tenant -1234 {org.wso2.carbon.core.internal.permission.update.PermissionUpdater}
TID: [0] [BAM] [2014-09-17 17:20:11,510]  INFO {org.wso2.carbon.bam.toolbox.deployer.internal.DashboardServiceComponent} -  Successfully setted dashboard services {org.wso2.carbon.bam.toolbox.deployer.internal.DashboardServiceComponent}
TID: [0] [BAM] [2014-09-17 17:20:11,607]  INFO {org.wso2.carbon.databridge.receiver.thrift.internal.ThriftDataReceiver} -  Thrift Server started at 10.100.5.90 {org.wso2.carbon.databridge.receiver.thrift.internal.ThriftDataReceiver}
TID: [0] [BAM] [2014-09-17 17:20:11,612]  INFO {org.wso2.carbon.databridge.receiver.thrift.internal.ThriftDataReceiver} -  Thrift SSL port : 7712 {org.wso2.carbon.databridge.receiver.thrift.internal.ThriftDataReceiver}
TID: [0] [BAM] [2014-09-17 17:20:11,615]  INFO {org.wso2.carbon.databridge.receiver.thrift.internal.ThriftDataReceiver} -  Thrift port : 7612 {org.wso2.carbon.databridge.receiver.thrift.internal.ThriftDataReceiver}
TID: [0] [BAM] [2014-09-17 17:20:11,853]  INFO {org.wso2.carbon.core.transports.http.HttpsTransportListener} -  HTTPS port       : 9444 {org.wso2.carbon.core.transports.http.HttpsTransportListener}
TID: [0] [BAM] [2014-09-17 17:20:11,853]  INFO {org.wso2.carbon.core.transports.http.HttpTransportListener} -  HTTP port        : 9764 {org.wso2.carbon.core.transports.http.HttpTransportListener}
TID: [0] [BAM] [2014-09-17 17:20:11,935]  INFO {org.wso2.carbon.ntask.core.service.impl.TaskServiceImpl} -  Task service starting in STANDALONE mode... {org.wso2.carbon.ntask.core.service.impl.TaskServiceImpl}
TID: [0] [BAM] [2014-09-17 17:20:12,051]  INFO {org.wso2.carbon.core.init.JMXServerManager} -  JMX Service URL  : service:jmx:rmi://localhost:11112/jndi/rmi://localhost:10000/jmxrmi {org.wso2.carbon.core.init.JMXServerManager}
TID: [0] [BAM] [2014-09-17 17:20:12,051]  INFO {org.wso2.carbon.bam.toolbox.deployer.internal.ServerStartUpInspector} -  BAM Toolbox is ready to do deployments {org.wso2.carbon.bam.toolbox.deployer.internal.ServerStartUpInspector}
TID: [0] [BAM] [2014-09-17 17:20:12,055]  INFO {org.wso2.carbon.bam.toolbox.deployer.core.BAMToolBoxDeployer} -  /home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/repository/deployment/server/bam-toolbox {org.wso2.carbon.bam.toolbox.deployer.core.BAMToolBoxDeployer}
TID: [0] [BAM] [2014-09-17 17:20:12,097]  INFO {org.wso2.carbon.ntask.core.impl.AbstractQuartzTaskManager} -  Task scheduled: [-1234][HIVE_TASK][ Github_Committers_MySQL] {org.wso2.carbon.ntask.core.impl.AbstractQuartzTaskManager}
TID: [0] [BAM] [2014-09-17 17:20:12,099]  INFO {org.wso2.carbon.ntask.core.impl.AbstractQuartzTaskManager} -  Task scheduled: [-1234][HIVE_TASK][Github_Commits_MySQL] {org.wso2.carbon.ntask.core.impl.AbstractQuartzTaskManager}
TID: [0] [BAM] [2014-09-17 17:20:12,101]  INFO {org.wso2.carbon.ntask.core.impl.AbstractQuartzTaskManager} -  Task scheduled: [-1234][HIVE_TASK][Gituhub_MySQL] {org.wso2.carbon.ntask.core.impl.AbstractQuartzTaskManager}
TID: [0] [BAM] [2014-09-17 17:20:12,101]  INFO {org.wso2.carbon.core.internal.StartupFinalizerServiceComponent} -  Server           :  WSO2 Business Activity Monitor-2.4.0 {org.wso2.carbon.core.internal.StartupFinalizerServiceComponent}
TID: [0] [BAM] [2014-09-17 17:20:12,102]  INFO {org.wso2.carbon.core.internal.StartupFinalizerServiceComponent} -  WSO2 Carbon started in 12 sec {org.wso2.carbon.core.internal.StartupFinalizerServiceComponent}
TID: [0] [BAM] [2014-09-17 17:20:13,088]  INFO {org.wso2.carbon.dashboard.common.oauth.GSOAuthModule} -  Using random key for OAuth client-side state encryption {org.wso2.carbon.dashboard.common.oauth.GSOAuthModule}
TID: [0] [BAM] [2014-09-17 17:20:13,369]  INFO {org.wso2.carbon.ui.internal.CarbonUIServiceComponent} -  Mgt Console URL  : https://10.100.5.90:9444/carbon/ {org.wso2.carbon.ui.internal.CarbonUIServiceComponent}
TID: [0] [BAM] [2014-09-17 17:20:13,370]  INFO {org.wso2.carbon.ui.internal.CarbonUIServiceComponent} -  Gadget Server Default Context : http://10.100.5.90:9764/portal {org.wso2.carbon.ui.internal.CarbonUIServiceComponent}
TID: [0] [BAM] [2014-09-17 17:21:10,010]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 17:21:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:21:10,010]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 17:21:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:21:10,010]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 17:21:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:21:11,380] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.GitStatsTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:21:11,380] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.GitCommittersTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:21:11,380] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.GithubCommitsTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:21:11,396] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.SummarizedGithubCommitsTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:21:11,396] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.summarizedGitTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:21:11,397] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.summarizedGitCommittersTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:21:11,568] ERROR {org.apache.hadoop.hive.cassandra.CassandraProxyClient} -  Error while trying to connect to cassandra host:localhost {org.apache.hadoop.hive.cassandra.CassandraProxyClient}
org.apache.hadoop.hive.cassandra.CassandraException: unable to connect to server
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:57)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.<init>(CassandraClientHolder.java:37)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.createConnection(CassandraProxyClient.java:181)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:207)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:183)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:54)
	... 25 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:351)
	at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:213)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:200)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
	at java.net.Socket.connect(Socket.java:529)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:178)
	... 27 more
TID: [0] [BAM] [2014-09-17 17:21:11,570] ERROR {org.apache.hadoop.hive.ql.exec.Task} -  FAILED: Error in metadata: java.lang.NullPointerException
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:546)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:223)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	... 17 more
 {org.apache.hadoop.hive.ql.exec.Task}
TID: [0] [BAM] [2014-09-17 17:21:11,571] ERROR {org.apache.hadoop.hive.ql.Driver} -  FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.apache.hadoop.hive.ql.Driver}
TID: [0] [BAM] [2014-09-17 17:21:11,573] ERROR {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl} -  Error while executing Hive script.
Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl}
java.sql.SQLException: Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:189)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:21:11,573] ERROR {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Error while executing script : Gituhub_MySQL {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
org.wso2.carbon.analytics.hive.exception.HiveExecutionException: Error while executing Hive script.Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl.execute(HiveExecutorServiceImpl.java:115)
	at org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask.execute(HiveScriptExecutorTask.java:60)
	at org.wso2.carbon.ntask.core.impl.TaskQuartzJobAdapter.execute(TaskQuartzJobAdapter.java:67)
	at org.quartz.core.JobRunShell.run(JobRunShell.java:213)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:21:11,584] ERROR {org.apache.hadoop.hive.cassandra.CassandraProxyClient} -  Error while trying to connect to cassandra host:localhost {org.apache.hadoop.hive.cassandra.CassandraProxyClient}
org.apache.hadoop.hive.cassandra.CassandraException: unable to connect to server
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:57)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.<init>(CassandraClientHolder.java:37)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.createConnection(CassandraProxyClient.java:181)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:207)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:183)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:54)
	... 25 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:351)
	at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:213)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:200)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
	at java.net.Socket.connect(Socket.java:529)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:178)
	... 27 more
TID: [0] [BAM] [2014-09-17 17:21:11,585] ERROR {org.apache.hadoop.hive.cassandra.CassandraProxyClient} -  Error while trying to connect to cassandra host:localhost {org.apache.hadoop.hive.cassandra.CassandraProxyClient}
org.apache.hadoop.hive.cassandra.CassandraException: unable to connect to server
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:57)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.<init>(CassandraClientHolder.java:37)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.createConnection(CassandraProxyClient.java:181)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:207)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:183)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:54)
	... 25 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:351)
	at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:213)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:200)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
	at java.net.Socket.connect(Socket.java:529)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:178)
	... 27 more
TID: [0] [BAM] [2014-09-17 17:21:11,586] ERROR {org.apache.hadoop.hive.ql.exec.Task} -  FAILED: Error in metadata: java.lang.NullPointerException
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:546)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:223)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	... 17 more
 {org.apache.hadoop.hive.ql.exec.Task}
TID: [0] [BAM] [2014-09-17 17:21:11,588] ERROR {org.apache.hadoop.hive.ql.exec.Task} -  FAILED: Error in metadata: java.lang.NullPointerException
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:546)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:223)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	... 17 more
 {org.apache.hadoop.hive.ql.exec.Task}
TID: [0] [BAM] [2014-09-17 17:21:11,588] ERROR {org.apache.hadoop.hive.ql.Driver} -  FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.apache.hadoop.hive.ql.Driver}
TID: [0] [BAM] [2014-09-17 17:21:11,589] ERROR {org.apache.hadoop.hive.ql.Driver} -  FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.apache.hadoop.hive.ql.Driver}
TID: [0] [BAM] [2014-09-17 17:21:11,590] ERROR {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl} -  Error while executing Hive script.
Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl}
java.sql.SQLException: Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:189)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:21:11,590] ERROR {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl} -  Error while executing Hive script.
Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl}
java.sql.SQLException: Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:189)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:21:11,590] ERROR {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Error while executing script :  Github_Committers_MySQL {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
org.wso2.carbon.analytics.hive.exception.HiveExecutionException: Error while executing Hive script.Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl.execute(HiveExecutorServiceImpl.java:115)
	at org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask.execute(HiveScriptExecutorTask.java:60)
	at org.wso2.carbon.ntask.core.impl.TaskQuartzJobAdapter.execute(TaskQuartzJobAdapter.java:67)
	at org.quartz.core.JobRunShell.run(JobRunShell.java:213)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:21:11,591] ERROR {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Error while executing script : Github_Commits_MySQL {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
org.wso2.carbon.analytics.hive.exception.HiveExecutionException: Error while executing Hive script.Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl.execute(HiveExecutorServiceImpl.java:115)
	at org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask.execute(HiveScriptExecutorTask.java:60)
	at org.wso2.carbon.ntask.core.impl.TaskQuartzJobAdapter.execute(TaskQuartzJobAdapter.java:67)
	at org.quartz.core.JobRunShell.run(JobRunShell.java:213)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:21:15,131]  INFO {org.wso2.carbon.core.services.util.CarbonAuthenticationUtil} -  'admin@carbon.super [-1234]' logged in at [2014-09-17 17:21:15,130+0530] {org.wso2.carbon.core.services.util.CarbonAuthenticationUtil}
TID: [0] [BAM] [2014-09-17 17:21:23,431] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.GitCommittersTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:21:23,436] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.summarizedGitCommittersTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:21:23,482] ERROR {org.apache.hadoop.hive.cassandra.CassandraProxyClient} -  Error while trying to connect to cassandra host:localhost {org.apache.hadoop.hive.cassandra.CassandraProxyClient}
org.apache.hadoop.hive.cassandra.CassandraException: unable to connect to server
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:57)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.<init>(CassandraClientHolder.java:37)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.createConnection(CassandraProxyClient.java:181)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:207)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:183)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:54)
	... 25 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:351)
	at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:213)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:200)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
	at java.net.Socket.connect(Socket.java:529)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:178)
	... 27 more
TID: [0] [BAM] [2014-09-17 17:21:23,483] ERROR {org.apache.hadoop.hive.ql.exec.Task} -  FAILED: Error in metadata: java.lang.NullPointerException
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:546)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:223)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	... 17 more
 {org.apache.hadoop.hive.ql.exec.Task}
TID: [0] [BAM] [2014-09-17 17:21:23,483] ERROR {org.apache.hadoop.hive.ql.Driver} -  FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.apache.hadoop.hive.ql.Driver}
TID: [0] [BAM] [2014-09-17 17:21:23,483] ERROR {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl} -  Error while executing Hive script.
Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl}
java.sql.SQLException: Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:189)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:21:23,493] ERROR {org.wso2.carbon.analytics.hive.ui.client.HiveExecutionClient} -  Error while executing Hive script.Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.wso2.carbon.analytics.hive.ui.client.HiveExecutionClient}
org.wso2.carbon.analytics.hive.stub.HiveExecutionServiceHiveExecutionException: HiveExecutionServiceHiveExecutionException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
	at java.lang.Class.newInstance0(Class.java:357)
	at java.lang.Class.newInstance(Class.java:310)
	at org.wso2.carbon.analytics.hive.stub.HiveExecutionServiceStub.executeHiveScript(HiveExecutionServiceStub.java:216)
	at org.wso2.carbon.analytics.hive.ui.client.HiveExecutionClient.executeScript(HiveExecutionClient.java:66)
	at org.apache.jsp.hive_002dexplorer.executeQuery_jsp._jspService(org.apache.jsp.hive_002dexplorer.executeQuery_jsp:129)
	at org.apache.jasper.runtime.HttpJspBase.service(HttpJspBase.java:111)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.apache.jasper.servlet.JspServletWrapper.service(JspServletWrapper.java:403)
	at org.apache.jasper.servlet.JspServlet.serviceJspFile(JspServlet.java:492)
	at org.apache.jasper.servlet.JspServlet.service(JspServlet.java:378)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.wso2.carbon.ui.JspServlet.service(JspServlet.java:155)
	at org.wso2.carbon.ui.TilesJspServlet.service(TilesJspServlet.java:80)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.eclipse.equinox.http.helper.ContextPathServletAdaptor.service(ContextPathServletAdaptor.java:37)
	at org.eclipse.equinox.http.servlet.internal.ServletRegistration.service(ServletRegistration.java:61)
	at org.eclipse.equinox.http.servlet.internal.ProxyServlet.processAlias(ProxyServlet.java:128)
	at org.eclipse.equinox.http.servlet.internal.ProxyServlet.service(ProxyServlet.java:68)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.wso2.carbon.tomcat.ext.servlet.DelegationServlet.service(DelegationServlet.java:68)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:305)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.apache.catalina.core.ApplicationDispatcher.invoke(ApplicationDispatcher.java:749)
	at org.apache.catalina.core.ApplicationDispatcher.doInclude(ApplicationDispatcher.java:605)
	at org.apache.catalina.core.ApplicationDispatcher.include(ApplicationDispatcher.java:544)
	at org.eclipse.equinox.http.servlet.internal.RequestDispatcherAdaptor.include(RequestDispatcherAdaptor.java:37)
	at org.eclipse.equinox.http.helper.ContextPathServletAdaptor$RequestDispatcherAdaptor.include(ContextPathServletAdaptor.java:369)
	at org.apache.jasper.runtime.JspRuntimeLibrary.include(JspRuntimeLibrary.java:1015)
	at org.apache.jasper.runtime.PageContextImpl.include(PageContextImpl.java:700)
	at sun.reflect.GeneratedMethodAccessor45.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.tiles.jsp.context.JspUtil.doInclude(JspUtil.java:87)
	at org.apache.tiles.jsp.context.JspTilesRequestContext.include(JspTilesRequestContext.java:88)
	at org.apache.tiles.jsp.context.JspTilesRequestContext.dispatch(JspTilesRequestContext.java:82)
	at org.apache.tiles.impl.BasicTilesContainer.render(BasicTilesContainer.java:465)
	at org.apache.tiles.jsp.taglib.InsertAttributeTag.render(InsertAttributeTag.java:140)
	at org.apache.tiles.jsp.taglib.InsertAttributeTag.render(InsertAttributeTag.java:117)
	at org.apache.tiles.jsp.taglib.RenderTagSupport.execute(RenderTagSupport.java:171)
	at org.apache.tiles.jsp.taglib.RoleSecurityTagSupport.doEndTag(RoleSecurityTagSupport.java:75)
	at org.apache.tiles.jsp.taglib.ContainerTagSupport.doEndTag(ContainerTagSupport.java:80)
	at org.apache.jsp.admin.layout.template_jsp._jspx_meth_tiles_insertAttribute_7(org.apache.jsp.admin.layout.template_jsp:603)
	at org.apache.jsp.admin.layout.template_jsp._jspService(org.apache.jsp.admin.layout.template_jsp:335)
	at org.apache.jasper.runtime.HttpJspBase.service(HttpJspBase.java:111)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.apache.jasper.servlet.JspServletWrapper.service(JspServletWrapper.java:403)
	at org.apache.jasper.servlet.JspServlet.serviceJspFile(JspServlet.java:492)
	at org.apache.jasper.servlet.JspServlet.service(JspServlet.java:378)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.wso2.carbon.ui.JspServlet.service(JspServlet.java:155)
	at org.wso2.carbon.ui.TilesJspServlet.service(TilesJspServlet.java:80)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.eclipse.equinox.http.helper.ContextPathServletAdaptor.service(ContextPathServletAdaptor.java:37)
	at org.eclipse.equinox.http.servlet.internal.ServletRegistration.service(ServletRegistration.java:61)
	at org.eclipse.equinox.http.servlet.internal.ProxyServlet.processAlias(ProxyServlet.java:128)
	at org.eclipse.equinox.http.servlet.internal.ProxyServlet.service(ProxyServlet.java:68)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.wso2.carbon.tomcat.ext.servlet.DelegationServlet.service(DelegationServlet.java:68)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:305)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.apache.catalina.core.ApplicationDispatcher.invoke(ApplicationDispatcher.java:749)
	at org.apache.catalina.core.ApplicationDispatcher.processRequest(ApplicationDispatcher.java:487)
	at org.apache.catalina.core.ApplicationDispatcher.doForward(ApplicationDispatcher.java:412)
	at org.apache.catalina.core.ApplicationDispatcher.forward(ApplicationDispatcher.java:339)
	at org.eclipse.equinox.http.servlet.internal.RequestDispatcherAdaptor.forward(RequestDispatcherAdaptor.java:30)
	at org.eclipse.equinox.http.helper.ContextPathServletAdaptor$RequestDispatcherAdaptor.forward(ContextPathServletAdaptor.java:362)
	at org.apache.tiles.servlet.context.ServletTilesRequestContext.forward(ServletTilesRequestContext.java:198)
	at org.apache.tiles.servlet.context.ServletTilesRequestContext.dispatch(ServletTilesRequestContext.java:185)
	at org.apache.tiles.impl.BasicTilesContainer.render(BasicTilesContainer.java:419)
	at org.apache.tiles.impl.BasicTilesContainer.render(BasicTilesContainer.java:370)
	at org.wso2.carbon.ui.action.ActionHelper.render(ActionHelper.java:52)
	at org.wso2.carbon.ui.TilesJspServlet.service(TilesJspServlet.java:101)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.eclipse.equinox.http.helper.ContextPathServletAdaptor.service(ContextPathServletAdaptor.java:37)
	at org.eclipse.equinox.http.servlet.internal.ServletRegistration.service(ServletRegistration.java:61)
	at org.eclipse.equinox.http.servlet.internal.ProxyServlet.processAlias(ProxyServlet.java:128)
	at org.eclipse.equinox.http.servlet.internal.ProxyServlet.service(ProxyServlet.java:68)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.wso2.carbon.tomcat.ext.servlet.DelegationServlet.service(DelegationServlet.java:68)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:305)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.wso2.carbon.tomcat.ext.filter.CharacterSetFilter.doFilter(CharacterSetFilter.java:61)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:222)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:123)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:472)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:171)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:99)
	at org.wso2.carbon.tomcat.ext.valves.CompositeValve.continueInvocation(CompositeValve.java:178)
	at org.wso2.carbon.tomcat.ext.valves.CarbonTomcatValve$1.invoke(CarbonTomcatValve.java:47)
	at org.wso2.carbon.webapp.mgt.TenantLazyLoaderValve.invoke(TenantLazyLoaderValve.java:56)
	at org.wso2.carbon.tomcat.ext.valves.TomcatValveContainer.invokeValves(TomcatValveContainer.java:47)
	at org.wso2.carbon.tomcat.ext.valves.CompositeValve.invoke(CompositeValve.java:141)
	at org.wso2.carbon.tomcat.ext.valves.CarbonStuckThreadDetectionValve.invoke(CarbonStuckThreadDetectionValve.java:156)
	at org.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:936)
	at org.wso2.carbon.tomcat.ext.valves.CarbonContextCreatorValve.invoke(CarbonContextCreatorValve.java:52)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:118)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:407)
	at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1004)
	at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:589)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1653)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:21:38,227] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.GithubCommitsTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:21:38,232] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.SummarizedGithubCommitsTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:21:38,277] ERROR {org.apache.hadoop.hive.cassandra.CassandraProxyClient} -  Error while trying to connect to cassandra host:localhost {org.apache.hadoop.hive.cassandra.CassandraProxyClient}
org.apache.hadoop.hive.cassandra.CassandraException: unable to connect to server
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:57)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.<init>(CassandraClientHolder.java:37)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.createConnection(CassandraProxyClient.java:181)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:207)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:183)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:54)
	... 25 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:351)
	at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:213)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:200)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
	at java.net.Socket.connect(Socket.java:529)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:178)
	... 27 more
TID: [0] [BAM] [2014-09-17 17:21:38,278] ERROR {org.apache.hadoop.hive.ql.exec.Task} -  FAILED: Error in metadata: java.lang.NullPointerException
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:546)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:223)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	... 17 more
 {org.apache.hadoop.hive.ql.exec.Task}
TID: [0] [BAM] [2014-09-17 17:21:38,278] ERROR {org.apache.hadoop.hive.ql.Driver} -  FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.apache.hadoop.hive.ql.Driver}
TID: [0] [BAM] [2014-09-17 17:21:38,278] ERROR {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl} -  Error while executing Hive script.
Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl}
java.sql.SQLException: Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:189)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:21:38,281] ERROR {org.wso2.carbon.analytics.hive.ui.client.HiveExecutionClient} -  Error while executing Hive script.Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.wso2.carbon.analytics.hive.ui.client.HiveExecutionClient}
org.wso2.carbon.analytics.hive.stub.HiveExecutionServiceHiveExecutionException: HiveExecutionServiceHiveExecutionException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
	at java.lang.Class.newInstance0(Class.java:357)
	at java.lang.Class.newInstance(Class.java:310)
	at org.wso2.carbon.analytics.hive.stub.HiveExecutionServiceStub.executeHiveScript(HiveExecutionServiceStub.java:216)
	at org.wso2.carbon.analytics.hive.ui.client.HiveExecutionClient.executeScript(HiveExecutionClient.java:66)
	at org.apache.jsp.hive_002dexplorer.executeQuery_jsp._jspService(org.apache.jsp.hive_002dexplorer.executeQuery_jsp:129)
	at org.apache.jasper.runtime.HttpJspBase.service(HttpJspBase.java:111)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.apache.jasper.servlet.JspServletWrapper.service(JspServletWrapper.java:403)
	at org.apache.jasper.servlet.JspServlet.serviceJspFile(JspServlet.java:492)
	at org.apache.jasper.servlet.JspServlet.service(JspServlet.java:378)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.wso2.carbon.ui.JspServlet.service(JspServlet.java:155)
	at org.wso2.carbon.ui.TilesJspServlet.service(TilesJspServlet.java:80)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.eclipse.equinox.http.helper.ContextPathServletAdaptor.service(ContextPathServletAdaptor.java:37)
	at org.eclipse.equinox.http.servlet.internal.ServletRegistration.service(ServletRegistration.java:61)
	at org.eclipse.equinox.http.servlet.internal.ProxyServlet.processAlias(ProxyServlet.java:128)
	at org.eclipse.equinox.http.servlet.internal.ProxyServlet.service(ProxyServlet.java:68)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.wso2.carbon.tomcat.ext.servlet.DelegationServlet.service(DelegationServlet.java:68)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:305)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.apache.catalina.core.ApplicationDispatcher.invoke(ApplicationDispatcher.java:749)
	at org.apache.catalina.core.ApplicationDispatcher.doInclude(ApplicationDispatcher.java:605)
	at org.apache.catalina.core.ApplicationDispatcher.include(ApplicationDispatcher.java:544)
	at org.eclipse.equinox.http.servlet.internal.RequestDispatcherAdaptor.include(RequestDispatcherAdaptor.java:37)
	at org.eclipse.equinox.http.helper.ContextPathServletAdaptor$RequestDispatcherAdaptor.include(ContextPathServletAdaptor.java:369)
	at org.apache.jasper.runtime.JspRuntimeLibrary.include(JspRuntimeLibrary.java:1015)
	at org.apache.jasper.runtime.PageContextImpl.include(PageContextImpl.java:700)
	at sun.reflect.GeneratedMethodAccessor45.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.tiles.jsp.context.JspUtil.doInclude(JspUtil.java:87)
	at org.apache.tiles.jsp.context.JspTilesRequestContext.include(JspTilesRequestContext.java:88)
	at org.apache.tiles.jsp.context.JspTilesRequestContext.dispatch(JspTilesRequestContext.java:82)
	at org.apache.tiles.impl.BasicTilesContainer.render(BasicTilesContainer.java:465)
	at org.apache.tiles.jsp.taglib.InsertAttributeTag.render(InsertAttributeTag.java:140)
	at org.apache.tiles.jsp.taglib.InsertAttributeTag.render(InsertAttributeTag.java:117)
	at org.apache.tiles.jsp.taglib.RenderTagSupport.execute(RenderTagSupport.java:171)
	at org.apache.tiles.jsp.taglib.RoleSecurityTagSupport.doEndTag(RoleSecurityTagSupport.java:75)
	at org.apache.tiles.jsp.taglib.ContainerTagSupport.doEndTag(ContainerTagSupport.java:80)
	at org.apache.jsp.admin.layout.template_jsp._jspx_meth_tiles_insertAttribute_7(org.apache.jsp.admin.layout.template_jsp:603)
	at org.apache.jsp.admin.layout.template_jsp._jspService(org.apache.jsp.admin.layout.template_jsp:335)
	at org.apache.jasper.runtime.HttpJspBase.service(HttpJspBase.java:111)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.apache.jasper.servlet.JspServletWrapper.service(JspServletWrapper.java:403)
	at org.apache.jasper.servlet.JspServlet.serviceJspFile(JspServlet.java:492)
	at org.apache.jasper.servlet.JspServlet.service(JspServlet.java:378)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.wso2.carbon.ui.JspServlet.service(JspServlet.java:155)
	at org.wso2.carbon.ui.TilesJspServlet.service(TilesJspServlet.java:80)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.eclipse.equinox.http.helper.ContextPathServletAdaptor.service(ContextPathServletAdaptor.java:37)
	at org.eclipse.equinox.http.servlet.internal.ServletRegistration.service(ServletRegistration.java:61)
	at org.eclipse.equinox.http.servlet.internal.ProxyServlet.processAlias(ProxyServlet.java:128)
	at org.eclipse.equinox.http.servlet.internal.ProxyServlet.service(ProxyServlet.java:68)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.wso2.carbon.tomcat.ext.servlet.DelegationServlet.service(DelegationServlet.java:68)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:305)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.apache.catalina.core.ApplicationDispatcher.invoke(ApplicationDispatcher.java:749)
	at org.apache.catalina.core.ApplicationDispatcher.processRequest(ApplicationDispatcher.java:487)
	at org.apache.catalina.core.ApplicationDispatcher.doForward(ApplicationDispatcher.java:412)
	at org.apache.catalina.core.ApplicationDispatcher.forward(ApplicationDispatcher.java:339)
	at org.eclipse.equinox.http.servlet.internal.RequestDispatcherAdaptor.forward(RequestDispatcherAdaptor.java:30)
	at org.eclipse.equinox.http.helper.ContextPathServletAdaptor$RequestDispatcherAdaptor.forward(ContextPathServletAdaptor.java:362)
	at org.apache.tiles.servlet.context.ServletTilesRequestContext.forward(ServletTilesRequestContext.java:198)
	at org.apache.tiles.servlet.context.ServletTilesRequestContext.dispatch(ServletTilesRequestContext.java:185)
	at org.apache.tiles.impl.BasicTilesContainer.render(BasicTilesContainer.java:419)
	at org.apache.tiles.impl.BasicTilesContainer.render(BasicTilesContainer.java:370)
	at org.wso2.carbon.ui.action.ActionHelper.render(ActionHelper.java:52)
	at org.wso2.carbon.ui.TilesJspServlet.service(TilesJspServlet.java:101)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.eclipse.equinox.http.helper.ContextPathServletAdaptor.service(ContextPathServletAdaptor.java:37)
	at org.eclipse.equinox.http.servlet.internal.ServletRegistration.service(ServletRegistration.java:61)
	at org.eclipse.equinox.http.servlet.internal.ProxyServlet.processAlias(ProxyServlet.java:128)
	at org.eclipse.equinox.http.servlet.internal.ProxyServlet.service(ProxyServlet.java:68)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.wso2.carbon.tomcat.ext.servlet.DelegationServlet.service(DelegationServlet.java:68)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:305)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.wso2.carbon.tomcat.ext.filter.CharacterSetFilter.doFilter(CharacterSetFilter.java:61)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:222)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:123)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:472)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:171)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:99)
	at org.wso2.carbon.tomcat.ext.valves.CompositeValve.continueInvocation(CompositeValve.java:178)
	at org.wso2.carbon.tomcat.ext.valves.CarbonTomcatValve$1.invoke(CarbonTomcatValve.java:47)
	at org.wso2.carbon.webapp.mgt.TenantLazyLoaderValve.invoke(TenantLazyLoaderValve.java:56)
	at org.wso2.carbon.tomcat.ext.valves.TomcatValveContainer.invokeValves(TomcatValveContainer.java:47)
	at org.wso2.carbon.tomcat.ext.valves.CompositeValve.invoke(CompositeValve.java:141)
	at org.wso2.carbon.tomcat.ext.valves.CarbonStuckThreadDetectionValve.invoke(CarbonStuckThreadDetectionValve.java:156)
	at org.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:936)
	at org.wso2.carbon.tomcat.ext.valves.CarbonContextCreatorValve.invoke(CarbonContextCreatorValve.java:52)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:118)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:407)
	at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1004)
	at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:589)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1653)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:21:41,672] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.GitStatsTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:21:41,678] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.summarizedGitTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:21:41,717] ERROR {org.apache.hadoop.hive.cassandra.CassandraProxyClient} -  Error while trying to connect to cassandra host:localhost {org.apache.hadoop.hive.cassandra.CassandraProxyClient}
org.apache.hadoop.hive.cassandra.CassandraException: unable to connect to server
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:57)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.<init>(CassandraClientHolder.java:37)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.createConnection(CassandraProxyClient.java:181)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:207)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:183)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:54)
	... 25 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:351)
	at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:213)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:200)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
	at java.net.Socket.connect(Socket.java:529)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:178)
	... 27 more
TID: [0] [BAM] [2014-09-17 17:21:41,718] ERROR {org.apache.hadoop.hive.ql.exec.Task} -  FAILED: Error in metadata: java.lang.NullPointerException
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:546)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:223)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	... 17 more
 {org.apache.hadoop.hive.ql.exec.Task}
TID: [0] [BAM] [2014-09-17 17:21:41,718] ERROR {org.apache.hadoop.hive.ql.Driver} -  FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.apache.hadoop.hive.ql.Driver}
TID: [0] [BAM] [2014-09-17 17:21:41,719] ERROR {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl} -  Error while executing Hive script.
Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl}
java.sql.SQLException: Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:189)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:21:41,721] ERROR {org.wso2.carbon.analytics.hive.ui.client.HiveExecutionClient} -  Error while executing Hive script.Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.wso2.carbon.analytics.hive.ui.client.HiveExecutionClient}
org.wso2.carbon.analytics.hive.stub.HiveExecutionServiceHiveExecutionException: HiveExecutionServiceHiveExecutionException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
	at java.lang.Class.newInstance0(Class.java:357)
	at java.lang.Class.newInstance(Class.java:310)
	at org.wso2.carbon.analytics.hive.stub.HiveExecutionServiceStub.executeHiveScript(HiveExecutionServiceStub.java:216)
	at org.wso2.carbon.analytics.hive.ui.client.HiveExecutionClient.executeScript(HiveExecutionClient.java:66)
	at org.apache.jsp.hive_002dexplorer.executeQuery_jsp._jspService(org.apache.jsp.hive_002dexplorer.executeQuery_jsp:129)
	at org.apache.jasper.runtime.HttpJspBase.service(HttpJspBase.java:111)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.apache.jasper.servlet.JspServletWrapper.service(JspServletWrapper.java:403)
	at org.apache.jasper.servlet.JspServlet.serviceJspFile(JspServlet.java:492)
	at org.apache.jasper.servlet.JspServlet.service(JspServlet.java:378)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.wso2.carbon.ui.JspServlet.service(JspServlet.java:155)
	at org.wso2.carbon.ui.TilesJspServlet.service(TilesJspServlet.java:80)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.eclipse.equinox.http.helper.ContextPathServletAdaptor.service(ContextPathServletAdaptor.java:37)
	at org.eclipse.equinox.http.servlet.internal.ServletRegistration.service(ServletRegistration.java:61)
	at org.eclipse.equinox.http.servlet.internal.ProxyServlet.processAlias(ProxyServlet.java:128)
	at org.eclipse.equinox.http.servlet.internal.ProxyServlet.service(ProxyServlet.java:68)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.wso2.carbon.tomcat.ext.servlet.DelegationServlet.service(DelegationServlet.java:68)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:305)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.apache.catalina.core.ApplicationDispatcher.invoke(ApplicationDispatcher.java:749)
	at org.apache.catalina.core.ApplicationDispatcher.doInclude(ApplicationDispatcher.java:605)
	at org.apache.catalina.core.ApplicationDispatcher.include(ApplicationDispatcher.java:544)
	at org.eclipse.equinox.http.servlet.internal.RequestDispatcherAdaptor.include(RequestDispatcherAdaptor.java:37)
	at org.eclipse.equinox.http.helper.ContextPathServletAdaptor$RequestDispatcherAdaptor.include(ContextPathServletAdaptor.java:369)
	at org.apache.jasper.runtime.JspRuntimeLibrary.include(JspRuntimeLibrary.java:1015)
	at org.apache.jasper.runtime.PageContextImpl.include(PageContextImpl.java:700)
	at sun.reflect.GeneratedMethodAccessor45.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.tiles.jsp.context.JspUtil.doInclude(JspUtil.java:87)
	at org.apache.tiles.jsp.context.JspTilesRequestContext.include(JspTilesRequestContext.java:88)
	at org.apache.tiles.jsp.context.JspTilesRequestContext.dispatch(JspTilesRequestContext.java:82)
	at org.apache.tiles.impl.BasicTilesContainer.render(BasicTilesContainer.java:465)
	at org.apache.tiles.jsp.taglib.InsertAttributeTag.render(InsertAttributeTag.java:140)
	at org.apache.tiles.jsp.taglib.InsertAttributeTag.render(InsertAttributeTag.java:117)
	at org.apache.tiles.jsp.taglib.RenderTagSupport.execute(RenderTagSupport.java:171)
	at org.apache.tiles.jsp.taglib.RoleSecurityTagSupport.doEndTag(RoleSecurityTagSupport.java:75)
	at org.apache.tiles.jsp.taglib.ContainerTagSupport.doEndTag(ContainerTagSupport.java:80)
	at org.apache.jsp.admin.layout.template_jsp._jspx_meth_tiles_insertAttribute_7(org.apache.jsp.admin.layout.template_jsp:603)
	at org.apache.jsp.admin.layout.template_jsp._jspService(org.apache.jsp.admin.layout.template_jsp:335)
	at org.apache.jasper.runtime.HttpJspBase.service(HttpJspBase.java:111)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.apache.jasper.servlet.JspServletWrapper.service(JspServletWrapper.java:403)
	at org.apache.jasper.servlet.JspServlet.serviceJspFile(JspServlet.java:492)
	at org.apache.jasper.servlet.JspServlet.service(JspServlet.java:378)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.wso2.carbon.ui.JspServlet.service(JspServlet.java:155)
	at org.wso2.carbon.ui.TilesJspServlet.service(TilesJspServlet.java:80)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.eclipse.equinox.http.helper.ContextPathServletAdaptor.service(ContextPathServletAdaptor.java:37)
	at org.eclipse.equinox.http.servlet.internal.ServletRegistration.service(ServletRegistration.java:61)
	at org.eclipse.equinox.http.servlet.internal.ProxyServlet.processAlias(ProxyServlet.java:128)
	at org.eclipse.equinox.http.servlet.internal.ProxyServlet.service(ProxyServlet.java:68)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.wso2.carbon.tomcat.ext.servlet.DelegationServlet.service(DelegationServlet.java:68)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:305)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.apache.catalina.core.ApplicationDispatcher.invoke(ApplicationDispatcher.java:749)
	at org.apache.catalina.core.ApplicationDispatcher.processRequest(ApplicationDispatcher.java:487)
	at org.apache.catalina.core.ApplicationDispatcher.doForward(ApplicationDispatcher.java:412)
	at org.apache.catalina.core.ApplicationDispatcher.forward(ApplicationDispatcher.java:339)
	at org.eclipse.equinox.http.servlet.internal.RequestDispatcherAdaptor.forward(RequestDispatcherAdaptor.java:30)
	at org.eclipse.equinox.http.helper.ContextPathServletAdaptor$RequestDispatcherAdaptor.forward(ContextPathServletAdaptor.java:362)
	at org.apache.tiles.servlet.context.ServletTilesRequestContext.forward(ServletTilesRequestContext.java:198)
	at org.apache.tiles.servlet.context.ServletTilesRequestContext.dispatch(ServletTilesRequestContext.java:185)
	at org.apache.tiles.impl.BasicTilesContainer.render(BasicTilesContainer.java:419)
	at org.apache.tiles.impl.BasicTilesContainer.render(BasicTilesContainer.java:370)
	at org.wso2.carbon.ui.action.ActionHelper.render(ActionHelper.java:52)
	at org.wso2.carbon.ui.TilesJspServlet.service(TilesJspServlet.java:101)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.eclipse.equinox.http.helper.ContextPathServletAdaptor.service(ContextPathServletAdaptor.java:37)
	at org.eclipse.equinox.http.servlet.internal.ServletRegistration.service(ServletRegistration.java:61)
	at org.eclipse.equinox.http.servlet.internal.ProxyServlet.processAlias(ProxyServlet.java:128)
	at org.eclipse.equinox.http.servlet.internal.ProxyServlet.service(ProxyServlet.java:68)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.wso2.carbon.tomcat.ext.servlet.DelegationServlet.service(DelegationServlet.java:68)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:305)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.wso2.carbon.tomcat.ext.filter.CharacterSetFilter.doFilter(CharacterSetFilter.java:61)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:222)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:123)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:472)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:171)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:99)
	at org.wso2.carbon.tomcat.ext.valves.CompositeValve.continueInvocation(CompositeValve.java:178)
	at org.wso2.carbon.tomcat.ext.valves.CarbonTomcatValve$1.invoke(CarbonTomcatValve.java:47)
	at org.wso2.carbon.webapp.mgt.TenantLazyLoaderValve.invoke(TenantLazyLoaderValve.java:56)
	at org.wso2.carbon.tomcat.ext.valves.TomcatValveContainer.invokeValves(TomcatValveContainer.java:47)
	at org.wso2.carbon.tomcat.ext.valves.CompositeValve.invoke(CompositeValve.java:141)
	at org.wso2.carbon.tomcat.ext.valves.CarbonStuckThreadDetectionValve.invoke(CarbonStuckThreadDetectionValve.java:156)
	at org.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:936)
	at org.wso2.carbon.tomcat.ext.valves.CarbonContextCreatorValve.invoke(CarbonContextCreatorValve.java:52)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:118)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:407)
	at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1004)
	at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:589)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1653)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:21:47,401]  INFO {org.wso2.carbon.core.init.CarbonServerManager} -  Shutdown hook triggered.... {org.wso2.carbon.core.init.CarbonServerManager}
TID: [0] [BAM] [2014-09-17 17:21:47,402]  INFO {org.wso2.carbon.core.init.CarbonServerManager} -  Gracefully shutting down WSO2 Business Activity Monitor... {org.wso2.carbon.core.init.CarbonServerManager}
TID: [0] [BAM] [2014-09-17 17:21:47,403]  INFO {org.apache.cassandra.thrift.CassandraDaemon} -  Stop listening to thrift clients {org.apache.cassandra.thrift.CassandraDaemon}
TID: [0] [BAM] [2014-09-17 17:21:47,404]  INFO {org.wso2.carbon.core.ServerManagement} -  Starting to switch to maintenance mode... {org.wso2.carbon.core.ServerManagement}
TID: [0] [BAM] [2014-09-17 17:21:47,404]  INFO {org.wso2.carbon.core.ServerManagement} -  Stopped all transport listeners {org.wso2.carbon.core.ServerManagement}
TID: [0] [BAM] [2014-09-17 17:21:47,404]  INFO {org.wso2.carbon.core.ServerManagement} -  Waiting for request service completion... {org.wso2.carbon.core.ServerManagement}
TID: [0] [BAM] [2014-09-17 17:21:47,404]  INFO {org.apache.cassandra.gms.Gossiper} -  Announcing shutdown {org.apache.cassandra.gms.Gossiper}
TID: [0] [BAM] [2014-09-17 17:21:47,407]  INFO {org.wso2.carbon.core.ServerManagement} -  All requests have been served. {org.wso2.carbon.core.ServerManagement}
TID: [0] [BAM] [2014-09-17 17:21:47,407]  INFO {org.wso2.carbon.core.ServerManagement} -  Waiting for deployment completion... {org.wso2.carbon.core.ServerManagement}
TID: [0] [BAM] [2014-09-17 17:21:47,431]  INFO {org.wso2.carbon.webapp.mgt.WebApplication} -  Unloaded webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/STRATOS_ROOT] {org.wso2.carbon.webapp.mgt.WebApplication}
TID: [0] [BAM] [2014-09-17 17:21:47,436]  INFO {org.springframework.web.context.support.XmlWebApplicationContext} -  Closing Root WebApplicationContext: startup date [Wed Sep 17 17:20:08 IST 2014]; root of context hierarchy {org.springframework.web.context.support.XmlWebApplicationContext}
TID: [0] [BAM] [2014-09-17 17:21:47,437]  INFO {org.springframework.beans.factory.support.DefaultListableBeanFactory} -  Destroying singletons in org.springframework.beans.factory.support.DefaultListableBeanFactory@385144d5: defining beans [cxf,org.apache.cxf.bus.spring.BusWiringBeanFactoryPostProcessor,org.apache.cxf.bus.spring.Jsr250BeanPostProcessor,org.apache.cxf.bus.spring.BusExtensionPostProcessor,dataReceiverStreamsService,dataReceiverStreamService,streamsBean,streamBean]; root of factory hierarchy {org.springframework.beans.factory.support.DefaultListableBeanFactory}
TID: [0] [BAM] [2014-09-17 17:21:47,454]  INFO {org.wso2.carbon.webapp.mgt.WebApplication} -  Unloaded webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/datareceiver] {org.wso2.carbon.webapp.mgt.WebApplication}
TID: [0] [BAM] [2014-09-17 17:21:47,473]  INFO {org.wso2.carbon.webapp.mgt.WebApplication} -  Unloaded webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/bamdashboards] {org.wso2.carbon.webapp.mgt.WebApplication}
TID: [0] [BAM] [2014-09-17 17:21:47,498]  INFO {org.wso2.carbon.webapp.mgt.WebApplication} -  Unloaded webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/activitymonitoring] {org.wso2.carbon.webapp.mgt.WebApplication}
TID: [0] [BAM] [2014-09-17 17:21:47,499]  INFO {org.wso2.carbon.core.ServerManagement} -  All deployment tasks have been completed. {org.wso2.carbon.core.ServerManagement}
TID: [0] [BAM] [2014-09-17 17:21:47,499]  INFO {org.wso2.carbon.core.ServerManagement} -  Waiting for server task completion... {org.wso2.carbon.core.ServerManagement}
TID: [0] [BAM] [2014-09-17 17:21:47,502]  INFO {org.wso2.carbon.core.ServerManagement} -  All server tasks have been completed. {org.wso2.carbon.core.ServerManagement}
TID: [0] [BAM] [2014-09-17 17:21:47,502]  INFO {org.wso2.carbon.core.init.CarbonServerManager} -  Shutting down WSO2 Business Activity Monitor... {org.wso2.carbon.core.init.CarbonServerManager}
TID: [0] [BAM] [2014-09-17 17:21:47,502]  INFO {org.wso2.carbon.core.init.CarbonServerManager} -  Shutting down OSGi framework... {org.wso2.carbon.core.init.CarbonServerManager}
TID: [0] [BAM] [2014-09-17 17:21:47,570]  INFO {org.wso2.carbon.databridge.receiver.thrift.internal.ThriftDataReceiverDS} -  Thrift server shutting down... {org.wso2.carbon.databridge.receiver.thrift.internal.ThriftDataReceiverDS}
TID: [0] [BAM] [2014-09-17 17:21:48,405]  INFO {org.apache.cassandra.net.MessagingService} -  Waiting for messaging service to quiesce {org.apache.cassandra.net.MessagingService}
TID: [0] [BAM] [2014-09-17 17:21:48,407]  INFO {org.apache.cassandra.net.MessagingService} -  MessagingService shutting down server thread. {org.apache.cassandra.net.MessagingService}
TID: [0] [BAM] [2014-09-17 17:21:49,763]  INFO {org.wso2.carbon.core.init.CarbonServerManager} -  Stopping CarbonServerManager... {org.wso2.carbon.core.init.CarbonServerManager}
TID: [0] [BAM] [2014-09-17 17:21:49,764]  INFO {org.apache.axis2.transport.tcp.TCPTransportSender} -  TCP Sender Shutdown {org.apache.axis2.transport.tcp.TCPTransportSender}
TID: [0] [BAM] [2014-09-17 17:21:49,978]  INFO {org.wso2.carbon.tomcat.ext.internal.CarbonTomcatServiceComponent} -  Stopping the carbon web-app registered under : / {org.wso2.carbon.tomcat.ext.internal.CarbonTomcatServiceComponent}
TID: [0] [BAM] [2014-09-17 17:21:50,375]  INFO {org.wso2.carbon.core.init.CarbonServerManager} -  Shutdown complete {org.wso2.carbon.core.init.CarbonServerManager}
TID: [0] [BAM] [2014-09-17 17:21:50,376]  INFO {org.wso2.carbon.core.init.CarbonServerManager} -  Halting JVM {org.wso2.carbon.core.init.CarbonServerManager}
TID: [0] [BAM] [2014-09-17 17:22:00,216]  INFO {org.wso2.carbon.core.internal.CarbonCoreActivator} -  Starting WSO2 Carbon... {org.wso2.carbon.core.internal.CarbonCoreActivator}
TID: [0] [BAM] [2014-09-17 17:22:00,217]  INFO {org.wso2.carbon.core.internal.CarbonCoreActivator} -  Operating System : Linux 3.13.0-24-generic, amd64 {org.wso2.carbon.core.internal.CarbonCoreActivator}
TID: [0] [BAM] [2014-09-17 17:22:00,217]  INFO {org.wso2.carbon.core.internal.CarbonCoreActivator} -  Java Home        : /usr/lib/jvm/java-6-oracle/jre {org.wso2.carbon.core.internal.CarbonCoreActivator}
TID: [0] [BAM] [2014-09-17 17:22:00,217]  INFO {org.wso2.carbon.core.internal.CarbonCoreActivator} -  Java Version     : 1.6.0_45 {org.wso2.carbon.core.internal.CarbonCoreActivator}
TID: [0] [BAM] [2014-09-17 17:22:00,217]  INFO {org.wso2.carbon.core.internal.CarbonCoreActivator} -  Java VM          : Java HotSpot(TM) 64-Bit Server VM 20.45-b01,Sun Microsystems Inc. {org.wso2.carbon.core.internal.CarbonCoreActivator}
TID: [0] [BAM] [2014-09-17 17:22:00,217]  INFO {org.wso2.carbon.core.internal.CarbonCoreActivator} -  Carbon Home      : /home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0 {org.wso2.carbon.core.internal.CarbonCoreActivator}
TID: [0] [BAM] [2014-09-17 17:22:00,217]  INFO {org.wso2.carbon.core.internal.CarbonCoreActivator} -  Java Temp Dir    : /home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/tmp {org.wso2.carbon.core.internal.CarbonCoreActivator}
TID: [0] [BAM] [2014-09-17 17:22:00,217]  INFO {org.wso2.carbon.core.internal.CarbonCoreActivator} -  User             : denuwanthi, en-US, Asia/Colombo {org.wso2.carbon.core.internal.CarbonCoreActivator}
TID: [0] [BAM] [2014-09-17 17:22:00,269]  WARN {org.wso2.carbon.core.bootup.validator.util.ValidationResultPrinter} -  The default keystore (wso2carbon.jks) is currently being used. To maximize security when deploying to a production environment, configure a new keystore with a unique password in the production server profile. {org.wso2.carbon.core.bootup.validator.util.ValidationResultPrinter}
TID: [0] [BAM] [2014-09-17 17:22:00,296]  INFO {org.wso2.carbon.databridge.agent.thrift.AgentHolder} -  Agent created ! {org.wso2.carbon.databridge.agent.thrift.AgentHolder}
TID: [0] [BAM] [2014-09-17 17:22:00,356]  INFO {org.wso2.carbon.databridge.agent.thrift.internal.AgentDS} -  Successfully deployed Agent Client {org.wso2.carbon.databridge.agent.thrift.internal.AgentDS}
TID: [0] [BAM] [2014-09-17 17:22:01,521]  INFO {org.wso2.carbon.bam.toolbox.deployer.internal.DataBridgeRecieverServiceComponent} -  Successfully setted data bridge reciever service {org.wso2.carbon.bam.toolbox.deployer.internal.DataBridgeRecieverServiceComponent}
TID: [0] [BAM] [2014-09-17 17:22:01,528]  INFO {org.wso2.carbon.databridge.core.internal.DataBridgeDS} -  Successfully deployed Agent Server  {org.wso2.carbon.databridge.core.internal.DataBridgeDS}
TID: [0] [BAM] [2014-09-17 17:22:01,658]  INFO {org.wso2.carbon.registry.core.jdbc.EmbeddedRegistryService} -  Configured Registry in 51ms {org.wso2.carbon.registry.core.jdbc.EmbeddedRegistryService}
TID: [0] [BAM] [2014-09-17 17:22:01,781]  INFO {org.wso2.carbon.registry.core.internal.RegistryCoreServiceComponent} -  Registry Mode    : READ-WRITE {org.wso2.carbon.registry.core.internal.RegistryCoreServiceComponent}
TID: [0] [BAM] [2014-09-17 17:22:02,380]  INFO {org.wso2.carbon.user.core.internal.UserStoreMgtDSComponent} -  Carbon UserStoreMgtDSComponent activated successfully. {org.wso2.carbon.user.core.internal.UserStoreMgtDSComponent}
TID: [0] [BAM] [2014-09-17 17:22:02,859]  INFO {org.apache.cassandra.net.MessagingService} -  Starting Messaging Service on port 7001 {org.apache.cassandra.net.MessagingService}
TID: [0] [BAM] [2014-09-17 17:22:02,905]  INFO {org.apache.cassandra.thrift.CassandraDaemon} -  Binding thrift service to localhost/127.0.0.1:9161 {org.apache.cassandra.thrift.CassandraDaemon}
TID: [0] [BAM] [2014-09-17 17:22:02,907]  INFO {org.apache.cassandra.thrift.CassandraDaemon} -  Using TFastFramedTransport with a max frame size of 15728640 bytes. {org.apache.cassandra.thrift.CassandraDaemon}
TID: [0] [BAM] [2014-09-17 17:22:02,909]  INFO {org.apache.cassandra.thrift.CassandraDaemon} -  Using synchronous/threadpool thrift server on localhost/127.0.0.1 : 9161 {org.apache.cassandra.thrift.CassandraDaemon}
TID: [0] [BAM] [2014-09-17 17:22:02,909]  INFO {org.wso2.carbon.cassandra.server.CassandraServerController} -  Cassandra Server Controller Thread was destroyed successfully {org.wso2.carbon.cassandra.server.CassandraServerController}
TID: [0] [BAM] [2014-09-17 17:22:02,909]  INFO {org.apache.cassandra.thrift.CassandraDaemon} -  Listening for thrift clients... {org.apache.cassandra.thrift.CassandraDaemon}
TID: [0] [BAM] [2014-09-17 17:22:06,493]  INFO {org.apache.axis2.deployment.ClusterBuilder} -  Clustering has been disabled {org.apache.axis2.deployment.ClusterBuilder}
TID: [0] [BAM] [2014-09-17 17:22:06,663]  INFO {org.wso2.carbon.identity.user.store.configuration.deployer.UserStoreConfigurationDeployer} -  User Store Configuration Deployer initiated. {org.wso2.carbon.identity.user.store.configuration.deployer.UserStoreConfigurationDeployer}
TID: [0] [BAM] [2014-09-17 17:22:06,695]  INFO {org.wso2.carbon.stratos.landing.page.deployer.LandingPageWebappDeployer} -  Deployed product landing page webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/home] {org.wso2.carbon.stratos.landing.page.deployer.LandingPageWebappDeployer}
TID: [0] [BAM] [2014-09-17 17:22:06,698]  INFO {org.apache.axis2.transport.tcp.TCPTransportSender} -  TCP Sender started {org.apache.axis2.transport.tcp.TCPTransportSender}
TID: [0] [BAM] [2014-09-17 17:22:06,727]  INFO {org.wso2.carbon.webapp.mgt.TomcatGenericWebappsDeployer} -  Deployed webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/STRATOS_ROOT].File[/home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/repository/deployment/server/webapps/STRATOS_ROOT] {org.wso2.carbon.webapp.mgt.TomcatGenericWebappsDeployer}
TID: [0] [BAM] [2014-09-17 17:22:07,305]  INFO {org.springframework.web.context.support.XmlWebApplicationContext} -  Refreshing Root WebApplicationContext: startup date [Wed Sep 17 17:22:07 IST 2014]; root of context hierarchy {org.springframework.web.context.support.XmlWebApplicationContext}
TID: [0] [BAM] [2014-09-17 17:22:07,347]  INFO {org.springframework.beans.factory.xml.XmlBeanDefinitionReader} -  Loading XML bean definitions from class path resource [META-INF/cxf/cxf.xml] {org.springframework.beans.factory.xml.XmlBeanDefinitionReader}
TID: [0] [BAM] [2014-09-17 17:22:07,409]  INFO {org.springframework.beans.factory.xml.XmlBeanDefinitionReader} -  Loading XML bean definitions from URL [jndi:/localhost/datareceiver/WEB-INF/cxf-servlet.xml] {org.springframework.beans.factory.xml.XmlBeanDefinitionReader}
TID: [0] [BAM] [2014-09-17 17:22:07,651]  INFO {org.springframework.beans.factory.support.DefaultListableBeanFactory} -  Pre-instantiating singletons in org.springframework.beans.factory.support.DefaultListableBeanFactory@718f7af7: defining beans [cxf,org.apache.cxf.bus.spring.BusWiringBeanFactoryPostProcessor,org.apache.cxf.bus.spring.Jsr250BeanPostProcessor,org.apache.cxf.bus.spring.BusExtensionPostProcessor,dataReceiverStreamsService,dataReceiverStreamService,streamsBean,streamBean]; root of factory hierarchy {org.springframework.beans.factory.support.DefaultListableBeanFactory}
TID: [0] [BAM] [2014-09-17 17:22:07,929]  INFO {org.apache.cxf.endpoint.ServerImpl} -  Setting the server's publish address to be /streams {org.apache.cxf.endpoint.ServerImpl}
TID: [0] [BAM] [2014-09-17 17:22:07,973]  INFO {org.apache.cxf.endpoint.ServerImpl} -  Setting the server's publish address to be /stream {org.apache.cxf.endpoint.ServerImpl}
TID: [0] [BAM] [2014-09-17 17:22:07,978]  INFO {org.wso2.carbon.webapp.mgt.TomcatGenericWebappsDeployer} -  Deployed webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/datareceiver].File[/home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/repository/deployment/server/webapps/datareceiver.war] {org.wso2.carbon.webapp.mgt.TomcatGenericWebappsDeployer}
TID: [0] [BAM] [2014-09-17 17:22:08,571]  INFO {org.jaggeryjs.jaggery.app.mgt.TomcatJaggeryWebappsDeployer} -  Deployed webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/bamdashboards].File[/home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/repository/deployment/server/jaggeryapps/bamdashboards] {org.jaggeryjs.jaggery.app.mgt.TomcatJaggeryWebappsDeployer}
TID: [0] [BAM] [2014-09-17 17:22:08,615]  INFO {org.jaggeryjs.jaggery.app.mgt.TomcatJaggeryWebappsDeployer} -  Deployed webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/activitymonitoring].File[/home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/repository/deployment/server/jaggeryapps/activitymonitoring] {org.jaggeryjs.jaggery.app.mgt.TomcatJaggeryWebappsDeployer}
TID: [0] [BAM] [2014-09-17 17:22:08,705]  INFO {org.apache.axis2.deployment.ModuleDeployer} -  Deploying module: rampart-1.6.1-wso2v10 - file:/home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/repository/deployment/client/modules/rampart-1.6.1-wso2v10.mar {org.apache.axis2.deployment.ModuleDeployer}
TID: [0] [BAM] [2014-09-17 17:22:08,708]  INFO {org.apache.axis2.deployment.ModuleDeployer} -  Deploying module: addressing-1.6.1-wso2v10 - file:/home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/repository/deployment/client/modules/addressing-1.6.1-wso2v10.mar {org.apache.axis2.deployment.ModuleDeployer}
TID: [0] [BAM] [2014-09-17 17:22:08,711]  INFO {org.apache.axis2.transport.tcp.TCPTransportSender} -  TCP Sender started {org.apache.axis2.transport.tcp.TCPTransportSender}
TID: [0] [BAM] [2014-09-17 17:22:08,931]  INFO {org.wso2.carbon.core.deployment.DeploymentInterceptor} -  Deploying Axis2 service: BAMMessageStoreService {super-tenant} {org.wso2.carbon.core.deployment.DeploymentInterceptor}
TID: [0] [BAM] [2014-09-17 17:22:08,987]  INFO {org.apache.axis2.deployment.DeploymentEngine} -  Deploying Web service: org.wso2.carbon.bam.messagestore -  {org.apache.axis2.deployment.DeploymentEngine}
TID: [0] [BAM] [2014-09-17 17:22:09,187]  INFO {org.wso2.carbon.core.deployment.DeploymentInterceptor} -  Deploying Axis2 service: CassandraSearchAdmin {super-tenant} {org.wso2.carbon.core.deployment.DeploymentInterceptor}
TID: [0] [BAM] [2014-09-17 17:22:09,354]  INFO {org.apache.axis2.deployment.DeploymentEngine} -  Deploying Web service: org.wso2.carbon.cassandra.search.mgt -  {org.apache.axis2.deployment.DeploymentEngine}
TID: [0] [BAM] [2014-09-17 17:22:10,091]  INFO {org.wso2.carbon.core.init.CarbonServerManager} -  Repository       : /home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/repository/deployment/server/ {org.wso2.carbon.core.init.CarbonServerManager}
TID: [0] [BAM] [2014-09-17 17:22:10,116]  INFO {org.wso2.carbon.bam.toolbox.deployer.internal.BAMToolBoxDeployerComponent} -  Successfully Started BAM Toolbox Deployer {org.wso2.carbon.bam.toolbox.deployer.internal.BAMToolBoxDeployerComponent}
TID: [0] [BAM] [2014-09-17 17:22:10,149]  INFO {org.wso2.carbon.core.internal.permission.update.PermissionUpdater} -  Permission cache updated for tenant -1234 {org.wso2.carbon.core.internal.permission.update.PermissionUpdater}
TID: [0] [BAM] [2014-09-17 17:22:10,161]  INFO {org.wso2.carbon.bam.toolbox.deployer.internal.DashboardServiceComponent} -  Successfully setted dashboard services {org.wso2.carbon.bam.toolbox.deployer.internal.DashboardServiceComponent}
TID: [0] [BAM] [2014-09-17 17:22:10,260]  INFO {org.wso2.carbon.databridge.receiver.thrift.internal.ThriftDataReceiver} -  Thrift Server started at 10.100.5.90 {org.wso2.carbon.databridge.receiver.thrift.internal.ThriftDataReceiver}
TID: [0] [BAM] [2014-09-17 17:22:10,265]  INFO {org.wso2.carbon.databridge.receiver.thrift.internal.ThriftDataReceiver} -  Thrift SSL port : 7712 {org.wso2.carbon.databridge.receiver.thrift.internal.ThriftDataReceiver}
TID: [0] [BAM] [2014-09-17 17:22:10,268]  INFO {org.wso2.carbon.databridge.receiver.thrift.internal.ThriftDataReceiver} -  Thrift port : 7612 {org.wso2.carbon.databridge.receiver.thrift.internal.ThriftDataReceiver}
TID: [0] [BAM] [2014-09-17 17:22:10,515]  INFO {org.wso2.carbon.core.transports.http.HttpsTransportListener} -  HTTPS port       : 9444 {org.wso2.carbon.core.transports.http.HttpsTransportListener}
TID: [0] [BAM] [2014-09-17 17:22:10,515]  INFO {org.wso2.carbon.core.transports.http.HttpTransportListener} -  HTTP port        : 9764 {org.wso2.carbon.core.transports.http.HttpTransportListener}
TID: [0] [BAM] [2014-09-17 17:22:10,596]  INFO {org.wso2.carbon.ntask.core.service.impl.TaskServiceImpl} -  Task service starting in STANDALONE mode... {org.wso2.carbon.ntask.core.service.impl.TaskServiceImpl}
TID: [0] [BAM] [2014-09-17 17:22:10,709]  INFO {org.wso2.carbon.core.init.JMXServerManager} -  JMX Service URL  : service:jmx:rmi://localhost:11112/jndi/rmi://localhost:10000/jmxrmi {org.wso2.carbon.core.init.JMXServerManager}
TID: [0] [BAM] [2014-09-17 17:22:10,710]  INFO {org.wso2.carbon.bam.toolbox.deployer.internal.ServerStartUpInspector} -  BAM Toolbox is ready to do deployments {org.wso2.carbon.bam.toolbox.deployer.internal.ServerStartUpInspector}
TID: [0] [BAM] [2014-09-17 17:22:10,714]  INFO {org.wso2.carbon.bam.toolbox.deployer.core.BAMToolBoxDeployer} -  /home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/repository/deployment/server/bam-toolbox {org.wso2.carbon.bam.toolbox.deployer.core.BAMToolBoxDeployer}
TID: [0] [BAM] [2014-09-17 17:22:10,756]  INFO {org.wso2.carbon.ntask.core.impl.AbstractQuartzTaskManager} -  Task scheduled: [-1234][HIVE_TASK][ Github_Committers_MySQL] {org.wso2.carbon.ntask.core.impl.AbstractQuartzTaskManager}
TID: [0] [BAM] [2014-09-17 17:22:10,760]  INFO {org.wso2.carbon.ntask.core.impl.AbstractQuartzTaskManager} -  Task scheduled: [-1234][HIVE_TASK][Github_Commits_MySQL] {org.wso2.carbon.ntask.core.impl.AbstractQuartzTaskManager}
TID: [0] [BAM] [2014-09-17 17:22:10,764]  INFO {org.wso2.carbon.ntask.core.impl.AbstractQuartzTaskManager} -  Task scheduled: [-1234][HIVE_TASK][Gituhub_MySQL] {org.wso2.carbon.ntask.core.impl.AbstractQuartzTaskManager}
TID: [0] [BAM] [2014-09-17 17:22:10,764]  INFO {org.wso2.carbon.core.internal.StartupFinalizerServiceComponent} -  Server           :  WSO2 Business Activity Monitor-2.4.0 {org.wso2.carbon.core.internal.StartupFinalizerServiceComponent}
TID: [0] [BAM] [2014-09-17 17:22:10,765]  INFO {org.wso2.carbon.core.internal.StartupFinalizerServiceComponent} -  WSO2 Carbon started in 13 sec {org.wso2.carbon.core.internal.StartupFinalizerServiceComponent}
TID: [0] [BAM] [2014-09-17 17:22:10,771]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 17:22:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:22:10,771]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 17:22:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:22:10,772]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 17:22:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:22:12,001]  INFO {org.wso2.carbon.dashboard.common.oauth.GSOAuthModule} -  Using random key for OAuth client-side state encryption {org.wso2.carbon.dashboard.common.oauth.GSOAuthModule}
TID: [0] [BAM] [2014-09-17 17:22:12,262] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.GithubCommitsTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:22:12,262] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.GitCommittersTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:22:12,262] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.GitStatsTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:22:12,281] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.summarizedGitTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:22:12,281] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.SummarizedGithubCommitsTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:22:12,283] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.summarizedGitCommittersTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:22:12,480] ERROR {org.apache.hadoop.hive.cassandra.CassandraProxyClient} -  Error while trying to connect to cassandra host:localhost {org.apache.hadoop.hive.cassandra.CassandraProxyClient}
org.apache.hadoop.hive.cassandra.CassandraException: unable to connect to server
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:57)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.<init>(CassandraClientHolder.java:37)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.createConnection(CassandraProxyClient.java:181)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:207)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:183)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:54)
	... 25 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:351)
	at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:213)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:200)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
	at java.net.Socket.connect(Socket.java:529)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:178)
	... 27 more
TID: [0] [BAM] [2014-09-17 17:22:12,483] ERROR {org.apache.hadoop.hive.ql.exec.Task} -  FAILED: Error in metadata: java.lang.NullPointerException
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:546)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:223)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	... 17 more
 {org.apache.hadoop.hive.ql.exec.Task}
TID: [0] [BAM] [2014-09-17 17:22:12,484] ERROR {org.apache.hadoop.hive.ql.Driver} -  FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.apache.hadoop.hive.ql.Driver}
TID: [0] [BAM] [2014-09-17 17:22:12,485] ERROR {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl} -  Error while executing Hive script.
Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl}
java.sql.SQLException: Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:189)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:22:12,486] ERROR {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Error while executing script : Github_Commits_MySQL {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
org.wso2.carbon.analytics.hive.exception.HiveExecutionException: Error while executing Hive script.Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl.execute(HiveExecutorServiceImpl.java:115)
	at org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask.execute(HiveScriptExecutorTask.java:60)
	at org.wso2.carbon.ntask.core.impl.TaskQuartzJobAdapter.execute(TaskQuartzJobAdapter.java:67)
	at org.quartz.core.JobRunShell.run(JobRunShell.java:213)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:22:12,494] ERROR {org.apache.hadoop.hive.cassandra.CassandraProxyClient} -  Error while trying to connect to cassandra host:localhost {org.apache.hadoop.hive.cassandra.CassandraProxyClient}
org.apache.hadoop.hive.cassandra.CassandraException: unable to connect to server
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:57)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.<init>(CassandraClientHolder.java:37)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.createConnection(CassandraProxyClient.java:181)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:207)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:183)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:54)
	... 25 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:351)
	at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:213)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:200)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
	at java.net.Socket.connect(Socket.java:529)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:178)
	... 27 more
TID: [0] [BAM] [2014-09-17 17:22:12,496] ERROR {org.apache.hadoop.hive.ql.exec.Task} -  FAILED: Error in metadata: java.lang.NullPointerException
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:546)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:223)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	... 17 more
 {org.apache.hadoop.hive.ql.exec.Task}
TID: [0] [BAM] [2014-09-17 17:22:12,497] ERROR {org.apache.hadoop.hive.ql.Driver} -  FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.apache.hadoop.hive.ql.Driver}
TID: [0] [BAM] [2014-09-17 17:22:12,498] ERROR {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl} -  Error while executing Hive script.
Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl}
java.sql.SQLException: Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:189)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:22:12,499] ERROR {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Error while executing script :  Github_Committers_MySQL {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
org.wso2.carbon.analytics.hive.exception.HiveExecutionException: Error while executing Hive script.Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl.execute(HiveExecutorServiceImpl.java:115)
	at org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask.execute(HiveScriptExecutorTask.java:60)
	at org.wso2.carbon.ntask.core.impl.TaskQuartzJobAdapter.execute(TaskQuartzJobAdapter.java:67)
	at org.quartz.core.JobRunShell.run(JobRunShell.java:213)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:22:12,499] ERROR {org.apache.hadoop.hive.cassandra.CassandraProxyClient} -  Error while trying to connect to cassandra host:localhost {org.apache.hadoop.hive.cassandra.CassandraProxyClient}
org.apache.hadoop.hive.cassandra.CassandraException: unable to connect to server
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:57)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.<init>(CassandraClientHolder.java:37)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.createConnection(CassandraProxyClient.java:181)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:207)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:183)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:54)
	... 25 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:351)
	at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:213)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:200)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
	at java.net.Socket.connect(Socket.java:529)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:178)
	... 27 more
TID: [0] [BAM] [2014-09-17 17:22:12,502] ERROR {org.apache.hadoop.hive.ql.exec.Task} -  FAILED: Error in metadata: java.lang.NullPointerException
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:546)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:223)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	... 17 more
 {org.apache.hadoop.hive.ql.exec.Task}
TID: [0] [BAM] [2014-09-17 17:22:12,502] ERROR {org.apache.hadoop.hive.ql.Driver} -  FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.apache.hadoop.hive.ql.Driver}
TID: [0] [BAM] [2014-09-17 17:22:12,503] ERROR {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl} -  Error while executing Hive script.
Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl}
java.sql.SQLException: Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:189)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:22:12,503] ERROR {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Error while executing script : Gituhub_MySQL {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
org.wso2.carbon.analytics.hive.exception.HiveExecutionException: Error while executing Hive script.Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl.execute(HiveExecutorServiceImpl.java:115)
	at org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask.execute(HiveScriptExecutorTask.java:60)
	at org.wso2.carbon.ntask.core.impl.TaskQuartzJobAdapter.execute(TaskQuartzJobAdapter.java:67)
	at org.quartz.core.JobRunShell.run(JobRunShell.java:213)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:22:12,836]  INFO {org.wso2.carbon.ui.internal.CarbonUIServiceComponent} -  Mgt Console URL  : https://10.100.5.90:9444/carbon/ {org.wso2.carbon.ui.internal.CarbonUIServiceComponent}
TID: [0] [BAM] [2014-09-17 17:22:12,836]  INFO {org.wso2.carbon.ui.internal.CarbonUIServiceComponent} -  Gadget Server Default Context : http://10.100.5.90:9764/portal {org.wso2.carbon.ui.internal.CarbonUIServiceComponent}
TID: [0] [BAM] [2014-09-17 17:22:24,417]  INFO {org.wso2.carbon.core.services.util.CarbonAuthenticationUtil} -  'admin@carbon.super [-1234]' logged in at [2014-09-17 17:22:24,417+0530] {org.wso2.carbon.core.services.util.CarbonAuthenticationUtil}
TID: [0] [BAM] [2014-09-17 17:23:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 17:23:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:23:10,004]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 17:23:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:23:10,006]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 17:23:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:23:10,042] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.GitStatsTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:23:10,042] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.GithubCommitsTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:23:10,047] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.summarizedGitTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:23:10,047] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.SummarizedGithubCommitsTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:23:10,053] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.GitCommittersTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:23:10,062] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.summarizedGitCommittersTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:23:10,179] ERROR {org.apache.hadoop.hive.cassandra.CassandraProxyClient} -  Error while trying to connect to cassandra host:localhost {org.apache.hadoop.hive.cassandra.CassandraProxyClient}
org.apache.hadoop.hive.cassandra.CassandraException: unable to connect to server
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:57)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.<init>(CassandraClientHolder.java:37)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.createConnection(CassandraProxyClient.java:181)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:207)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:183)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:54)
	... 25 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:351)
	at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:213)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:200)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
	at java.net.Socket.connect(Socket.java:529)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:178)
	... 27 more
TID: [0] [BAM] [2014-09-17 17:23:10,181] ERROR {org.apache.hadoop.hive.ql.exec.Task} -  FAILED: Error in metadata: java.lang.NullPointerException
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:546)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:223)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	... 17 more
 {org.apache.hadoop.hive.ql.exec.Task}
TID: [0] [BAM] [2014-09-17 17:23:10,182] ERROR {org.apache.hadoop.hive.ql.Driver} -  FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.apache.hadoop.hive.ql.Driver}
TID: [0] [BAM] [2014-09-17 17:23:10,182] ERROR {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl} -  Error while executing Hive script.
Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl}
java.sql.SQLException: Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:189)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:23:10,182] ERROR {org.apache.hadoop.hive.cassandra.CassandraProxyClient} -  Error while trying to connect to cassandra host:localhost {org.apache.hadoop.hive.cassandra.CassandraProxyClient}
org.apache.hadoop.hive.cassandra.CassandraException: unable to connect to server
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:57)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.<init>(CassandraClientHolder.java:37)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.createConnection(CassandraProxyClient.java:181)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:207)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:183)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:54)
	... 25 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:351)
	at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:213)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:200)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
	at java.net.Socket.connect(Socket.java:529)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:178)
	... 27 more
TID: [0] [BAM] [2014-09-17 17:23:10,183] ERROR {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Error while executing script : Gituhub_MySQL {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
org.wso2.carbon.analytics.hive.exception.HiveExecutionException: Error while executing Hive script.Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl.execute(HiveExecutorServiceImpl.java:115)
	at org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask.execute(HiveScriptExecutorTask.java:60)
	at org.wso2.carbon.ntask.core.impl.TaskQuartzJobAdapter.execute(TaskQuartzJobAdapter.java:67)
	at org.quartz.core.JobRunShell.run(JobRunShell.java:213)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:23:10,185] ERROR {org.apache.hadoop.hive.ql.exec.Task} -  FAILED: Error in metadata: java.lang.NullPointerException
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:546)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:223)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	... 17 more
 {org.apache.hadoop.hive.ql.exec.Task}
TID: [0] [BAM] [2014-09-17 17:23:10,185] ERROR {org.apache.hadoop.hive.ql.Driver} -  FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.apache.hadoop.hive.ql.Driver}
TID: [0] [BAM] [2014-09-17 17:23:10,186] ERROR {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl} -  Error while executing Hive script.
Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl}
java.sql.SQLException: Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:189)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:23:10,187] ERROR {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Error while executing script : Github_Commits_MySQL {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
org.wso2.carbon.analytics.hive.exception.HiveExecutionException: Error while executing Hive script.Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl.execute(HiveExecutorServiceImpl.java:115)
	at org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask.execute(HiveScriptExecutorTask.java:60)
	at org.wso2.carbon.ntask.core.impl.TaskQuartzJobAdapter.execute(TaskQuartzJobAdapter.java:67)
	at org.quartz.core.JobRunShell.run(JobRunShell.java:213)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:23:10,194] ERROR {org.apache.hadoop.hive.cassandra.CassandraProxyClient} -  Error while trying to connect to cassandra host:localhost {org.apache.hadoop.hive.cassandra.CassandraProxyClient}
org.apache.hadoop.hive.cassandra.CassandraException: unable to connect to server
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:57)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.<init>(CassandraClientHolder.java:37)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.createConnection(CassandraProxyClient.java:181)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:207)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:183)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:54)
	... 25 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:351)
	at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:213)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:200)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
	at java.net.Socket.connect(Socket.java:529)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:178)
	... 27 more
TID: [0] [BAM] [2014-09-17 17:23:10,195] ERROR {org.apache.hadoop.hive.ql.exec.Task} -  FAILED: Error in metadata: java.lang.NullPointerException
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:546)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:223)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	... 17 more
 {org.apache.hadoop.hive.ql.exec.Task}
TID: [0] [BAM] [2014-09-17 17:23:10,196] ERROR {org.apache.hadoop.hive.ql.Driver} -  FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.apache.hadoop.hive.ql.Driver}
TID: [0] [BAM] [2014-09-17 17:23:10,196] ERROR {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl} -  Error while executing Hive script.
Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl}
java.sql.SQLException: Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:189)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:23:10,197] ERROR {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Error while executing script :  Github_Committers_MySQL {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
org.wso2.carbon.analytics.hive.exception.HiveExecutionException: Error while executing Hive script.Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl.execute(HiveExecutorServiceImpl.java:115)
	at org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask.execute(HiveScriptExecutorTask.java:60)
	at org.wso2.carbon.ntask.core.impl.TaskQuartzJobAdapter.execute(TaskQuartzJobAdapter.java:67)
	at org.quartz.core.JobRunShell.run(JobRunShell.java:213)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:24:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 17:24:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:24:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 17:24:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:24:10,005]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 17:24:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:24:10,038] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.GithubCommitsTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:24:10,038] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.GitStatsTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:24:10,039] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.GitCommittersTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:24:10,043] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.SummarizedGithubCommitsTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:24:10,043] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.summarizedGitTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:24:10,044] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.summarizedGitCommittersTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:24:10,138] ERROR {org.apache.hadoop.hive.cassandra.CassandraProxyClient} -  Error while trying to connect to cassandra host:localhost {org.apache.hadoop.hive.cassandra.CassandraProxyClient}
org.apache.hadoop.hive.cassandra.CassandraException: unable to connect to server
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:57)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.<init>(CassandraClientHolder.java:37)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.createConnection(CassandraProxyClient.java:181)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:207)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:183)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:54)
	... 25 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:351)
	at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:213)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:200)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
	at java.net.Socket.connect(Socket.java:529)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:178)
	... 27 more
TID: [0] [BAM] [2014-09-17 17:24:10,140] ERROR {org.apache.hadoop.hive.ql.exec.Task} -  FAILED: Error in metadata: java.lang.NullPointerException
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:546)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:223)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	... 17 more
 {org.apache.hadoop.hive.ql.exec.Task}
TID: [0] [BAM] [2014-09-17 17:24:10,140] ERROR {org.apache.hadoop.hive.ql.Driver} -  FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.apache.hadoop.hive.ql.Driver}
TID: [0] [BAM] [2014-09-17 17:24:10,141] ERROR {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl} -  Error while executing Hive script.
Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl}
java.sql.SQLException: Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:189)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:24:10,141] ERROR {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Error while executing script : Github_Commits_MySQL {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
org.wso2.carbon.analytics.hive.exception.HiveExecutionException: Error while executing Hive script.Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl.execute(HiveExecutorServiceImpl.java:115)
	at org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask.execute(HiveScriptExecutorTask.java:60)
	at org.wso2.carbon.ntask.core.impl.TaskQuartzJobAdapter.execute(TaskQuartzJobAdapter.java:67)
	at org.quartz.core.JobRunShell.run(JobRunShell.java:213)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:24:10,151] ERROR {org.apache.hadoop.hive.cassandra.CassandraProxyClient} -  Error while trying to connect to cassandra host:localhost {org.apache.hadoop.hive.cassandra.CassandraProxyClient}
org.apache.hadoop.hive.cassandra.CassandraException: unable to connect to server
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:57)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.<init>(CassandraClientHolder.java:37)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.createConnection(CassandraProxyClient.java:181)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:207)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:183)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:54)
	... 25 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:351)
	at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:213)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:200)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
	at java.net.Socket.connect(Socket.java:529)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:178)
	... 27 more
TID: [0] [BAM] [2014-09-17 17:24:10,160] ERROR {org.apache.hadoop.hive.ql.exec.Task} -  FAILED: Error in metadata: java.lang.NullPointerException
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:546)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:223)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	... 17 more
 {org.apache.hadoop.hive.ql.exec.Task}
TID: [0] [BAM] [2014-09-17 17:24:10,161] ERROR {org.apache.hadoop.hive.ql.Driver} -  FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.apache.hadoop.hive.ql.Driver}
TID: [0] [BAM] [2014-09-17 17:24:10,161] ERROR {org.apache.hadoop.hive.cassandra.CassandraProxyClient} -  Error while trying to connect to cassandra host:localhost {org.apache.hadoop.hive.cassandra.CassandraProxyClient}
org.apache.hadoop.hive.cassandra.CassandraException: unable to connect to server
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:57)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.<init>(CassandraClientHolder.java:37)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.createConnection(CassandraProxyClient.java:181)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:207)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:183)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:54)
	... 25 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:351)
	at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:213)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:200)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
	at java.net.Socket.connect(Socket.java:529)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:178)
	... 27 more
TID: [0] [BAM] [2014-09-17 17:24:10,161] ERROR {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl} -  Error while executing Hive script.
Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl}
java.sql.SQLException: Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:189)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:24:10,163] ERROR {org.apache.hadoop.hive.ql.exec.Task} -  FAILED: Error in metadata: java.lang.NullPointerException
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:546)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:223)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	... 17 more
 {org.apache.hadoop.hive.ql.exec.Task}
TID: [0] [BAM] [2014-09-17 17:24:10,163] ERROR {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Error while executing script :  Github_Committers_MySQL {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
org.wso2.carbon.analytics.hive.exception.HiveExecutionException: Error while executing Hive script.Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl.execute(HiveExecutorServiceImpl.java:115)
	at org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask.execute(HiveScriptExecutorTask.java:60)
	at org.wso2.carbon.ntask.core.impl.TaskQuartzJobAdapter.execute(TaskQuartzJobAdapter.java:67)
	at org.quartz.core.JobRunShell.run(JobRunShell.java:213)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:24:10,163] ERROR {org.apache.hadoop.hive.ql.Driver} -  FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.apache.hadoop.hive.ql.Driver}
TID: [0] [BAM] [2014-09-17 17:24:10,164] ERROR {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl} -  Error while executing Hive script.
Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl}
java.sql.SQLException: Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:189)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:24:10,164] ERROR {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Error while executing script : Gituhub_MySQL {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
org.wso2.carbon.analytics.hive.exception.HiveExecutionException: Error while executing Hive script.Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl.execute(HiveExecutorServiceImpl.java:115)
	at org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask.execute(HiveScriptExecutorTask.java:60)
	at org.wso2.carbon.ntask.core.impl.TaskQuartzJobAdapter.execute(TaskQuartzJobAdapter.java:67)
	at org.quartz.core.JobRunShell.run(JobRunShell.java:213)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:25:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 17:25:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:25:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 17:25:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:25:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 17:25:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:25:10,025] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.GithubCommitsTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:25:10,026] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.GitCommittersTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:25:10,027] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.GitStatsTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:25:10,031] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.summarizedGitCommittersTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:25:10,031] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.SummarizedGithubCommitsTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:25:10,034] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.summarizedGitTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:25:10,127] ERROR {org.apache.hadoop.hive.cassandra.CassandraProxyClient} -  Error while trying to connect to cassandra host:localhost {org.apache.hadoop.hive.cassandra.CassandraProxyClient}
org.apache.hadoop.hive.cassandra.CassandraException: unable to connect to server
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:57)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.<init>(CassandraClientHolder.java:37)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.createConnection(CassandraProxyClient.java:181)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:207)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:183)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:54)
	... 25 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:351)
	at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:213)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:200)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
	at java.net.Socket.connect(Socket.java:529)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:178)
	... 27 more
TID: [0] [BAM] [2014-09-17 17:25:10,127] ERROR {org.apache.hadoop.hive.cassandra.CassandraProxyClient} -  Error while trying to connect to cassandra host:localhost {org.apache.hadoop.hive.cassandra.CassandraProxyClient}
org.apache.hadoop.hive.cassandra.CassandraException: unable to connect to server
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:57)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.<init>(CassandraClientHolder.java:37)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.createConnection(CassandraProxyClient.java:181)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:207)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:183)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:54)
	... 25 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:351)
	at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:213)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:200)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
	at java.net.Socket.connect(Socket.java:529)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:178)
	... 27 more
TID: [0] [BAM] [2014-09-17 17:25:10,129] ERROR {org.apache.hadoop.hive.ql.exec.Task} -  FAILED: Error in metadata: java.lang.NullPointerException
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:546)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:223)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	... 17 more
 {org.apache.hadoop.hive.ql.exec.Task}
TID: [0] [BAM] [2014-09-17 17:25:10,130] ERROR {org.apache.hadoop.hive.ql.exec.Task} -  FAILED: Error in metadata: java.lang.NullPointerException
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:546)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:223)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	... 17 more
 {org.apache.hadoop.hive.ql.exec.Task}
TID: [0] [BAM] [2014-09-17 17:25:10,130] ERROR {org.apache.hadoop.hive.ql.Driver} -  FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.apache.hadoop.hive.ql.Driver}
TID: [0] [BAM] [2014-09-17 17:25:10,131] ERROR {org.apache.hadoop.hive.ql.Driver} -  FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.apache.hadoop.hive.ql.Driver}
TID: [0] [BAM] [2014-09-17 17:25:10,131] ERROR {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl} -  Error while executing Hive script.
Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl}
java.sql.SQLException: Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:189)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:25:10,131] ERROR {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl} -  Error while executing Hive script.
Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl}
java.sql.SQLException: Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:189)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:25:10,132] ERROR {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Error while executing script :  Github_Committers_MySQL {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
org.wso2.carbon.analytics.hive.exception.HiveExecutionException: Error while executing Hive script.Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl.execute(HiveExecutorServiceImpl.java:115)
	at org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask.execute(HiveScriptExecutorTask.java:60)
	at org.wso2.carbon.ntask.core.impl.TaskQuartzJobAdapter.execute(TaskQuartzJobAdapter.java:67)
	at org.quartz.core.JobRunShell.run(JobRunShell.java:213)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:25:10,132] ERROR {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Error while executing script : Github_Commits_MySQL {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
org.wso2.carbon.analytics.hive.exception.HiveExecutionException: Error while executing Hive script.Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl.execute(HiveExecutorServiceImpl.java:115)
	at org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask.execute(HiveScriptExecutorTask.java:60)
	at org.wso2.carbon.ntask.core.impl.TaskQuartzJobAdapter.execute(TaskQuartzJobAdapter.java:67)
	at org.quartz.core.JobRunShell.run(JobRunShell.java:213)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:25:10,140] ERROR {org.apache.hadoop.hive.cassandra.CassandraProxyClient} -  Error while trying to connect to cassandra host:localhost {org.apache.hadoop.hive.cassandra.CassandraProxyClient}
org.apache.hadoop.hive.cassandra.CassandraException: unable to connect to server
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:57)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.<init>(CassandraClientHolder.java:37)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.createConnection(CassandraProxyClient.java:181)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:207)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:183)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:54)
	... 25 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:351)
	at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:213)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:200)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
	at java.net.Socket.connect(Socket.java:529)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:178)
	... 27 more
TID: [0] [BAM] [2014-09-17 17:25:10,142] ERROR {org.apache.hadoop.hive.ql.exec.Task} -  FAILED: Error in metadata: java.lang.NullPointerException
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:546)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:223)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	... 17 more
 {org.apache.hadoop.hive.ql.exec.Task}
TID: [0] [BAM] [2014-09-17 17:25:10,142] ERROR {org.apache.hadoop.hive.ql.Driver} -  FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.apache.hadoop.hive.ql.Driver}
TID: [0] [BAM] [2014-09-17 17:25:10,143] ERROR {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl} -  Error while executing Hive script.
Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl}
java.sql.SQLException: Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:189)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:25:10,143] ERROR {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Error while executing script : Gituhub_MySQL {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
org.wso2.carbon.analytics.hive.exception.HiveExecutionException: Error while executing Hive script.Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl.execute(HiveExecutorServiceImpl.java:115)
	at org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask.execute(HiveScriptExecutorTask.java:60)
	at org.wso2.carbon.ntask.core.impl.TaskQuartzJobAdapter.execute(TaskQuartzJobAdapter.java:67)
	at org.quartz.core.JobRunShell.run(JobRunShell.java:213)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:26:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 17:26:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:26:10,006]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 17:26:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:26:10,009]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 17:26:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:26:10,036] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.GithubCommitsTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:26:10,036] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.GitCommittersTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:26:10,039] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.GitStatsTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:26:10,042] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.SummarizedGithubCommitsTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:26:10,044] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.summarizedGitCommittersTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:26:10,046] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.summarizedGitTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:26:10,129] ERROR {org.apache.hadoop.hive.cassandra.CassandraProxyClient} -  Error while trying to connect to cassandra host:localhost {org.apache.hadoop.hive.cassandra.CassandraProxyClient}
org.apache.hadoop.hive.cassandra.CassandraException: unable to connect to server
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:57)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.<init>(CassandraClientHolder.java:37)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.createConnection(CassandraProxyClient.java:181)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:207)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:183)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:54)
	... 25 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:351)
	at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:213)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:200)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
	at java.net.Socket.connect(Socket.java:529)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:178)
	... 27 more
TID: [0] [BAM] [2014-09-17 17:26:10,130] ERROR {org.apache.hadoop.hive.ql.exec.Task} -  FAILED: Error in metadata: java.lang.NullPointerException
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:546)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:223)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	... 17 more
 {org.apache.hadoop.hive.ql.exec.Task}
TID: [0] [BAM] [2014-09-17 17:26:10,131] ERROR {org.apache.hadoop.hive.ql.Driver} -  FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.apache.hadoop.hive.ql.Driver}
TID: [0] [BAM] [2014-09-17 17:26:10,131] ERROR {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl} -  Error while executing Hive script.
Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl}
java.sql.SQLException: Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:189)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:26:10,131] ERROR {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Error while executing script : Github_Commits_MySQL {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
org.wso2.carbon.analytics.hive.exception.HiveExecutionException: Error while executing Hive script.Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl.execute(HiveExecutorServiceImpl.java:115)
	at org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask.execute(HiveScriptExecutorTask.java:60)
	at org.wso2.carbon.ntask.core.impl.TaskQuartzJobAdapter.execute(TaskQuartzJobAdapter.java:67)
	at org.quartz.core.JobRunShell.run(JobRunShell.java:213)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:26:10,134] ERROR {org.apache.hadoop.hive.cassandra.CassandraProxyClient} -  Error while trying to connect to cassandra host:localhost {org.apache.hadoop.hive.cassandra.CassandraProxyClient}
org.apache.hadoop.hive.cassandra.CassandraException: unable to connect to server
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:57)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.<init>(CassandraClientHolder.java:37)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.createConnection(CassandraProxyClient.java:181)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:207)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:183)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:54)
	... 25 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:351)
	at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:213)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:200)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
	at java.net.Socket.connect(Socket.java:529)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:178)
	... 27 more
TID: [0] [BAM] [2014-09-17 17:26:10,135] ERROR {org.apache.hadoop.hive.ql.exec.Task} -  FAILED: Error in metadata: java.lang.NullPointerException
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:546)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:223)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	... 17 more
 {org.apache.hadoop.hive.ql.exec.Task}
TID: [0] [BAM] [2014-09-17 17:26:10,136] ERROR {org.apache.hadoop.hive.ql.Driver} -  FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.apache.hadoop.hive.ql.Driver}
TID: [0] [BAM] [2014-09-17 17:26:10,136] ERROR {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl} -  Error while executing Hive script.
Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl}
java.sql.SQLException: Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:189)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:26:10,136] ERROR {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Error while executing script : Gituhub_MySQL {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
org.wso2.carbon.analytics.hive.exception.HiveExecutionException: Error while executing Hive script.Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl.execute(HiveExecutorServiceImpl.java:115)
	at org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask.execute(HiveScriptExecutorTask.java:60)
	at org.wso2.carbon.ntask.core.impl.TaskQuartzJobAdapter.execute(TaskQuartzJobAdapter.java:67)
	at org.quartz.core.JobRunShell.run(JobRunShell.java:213)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:26:10,144] ERROR {org.apache.hadoop.hive.cassandra.CassandraProxyClient} -  Error while trying to connect to cassandra host:localhost {org.apache.hadoop.hive.cassandra.CassandraProxyClient}
org.apache.hadoop.hive.cassandra.CassandraException: unable to connect to server
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:57)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.<init>(CassandraClientHolder.java:37)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.createConnection(CassandraProxyClient.java:181)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:207)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:183)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:54)
	... 25 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:351)
	at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:213)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:200)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
	at java.net.Socket.connect(Socket.java:529)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:178)
	... 27 more
TID: [0] [BAM] [2014-09-17 17:26:10,145] ERROR {org.apache.hadoop.hive.ql.exec.Task} -  FAILED: Error in metadata: java.lang.NullPointerException
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:546)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:223)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	... 17 more
 {org.apache.hadoop.hive.ql.exec.Task}
TID: [0] [BAM] [2014-09-17 17:26:10,145] ERROR {org.apache.hadoop.hive.ql.Driver} -  FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.apache.hadoop.hive.ql.Driver}
TID: [0] [BAM] [2014-09-17 17:26:10,146] ERROR {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl} -  Error while executing Hive script.
Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl}
java.sql.SQLException: Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:189)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:26:10,146] ERROR {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Error while executing script :  Github_Committers_MySQL {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
org.wso2.carbon.analytics.hive.exception.HiveExecutionException: Error while executing Hive script.Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl.execute(HiveExecutorServiceImpl.java:115)
	at org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask.execute(HiveScriptExecutorTask.java:60)
	at org.wso2.carbon.ntask.core.impl.TaskQuartzJobAdapter.execute(TaskQuartzJobAdapter.java:67)
	at org.quartz.core.JobRunShell.run(JobRunShell.java:213)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:27:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 17:27:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:27:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 17:27:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:27:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 17:27:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:27:10,029] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.GitCommittersTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:27:10,033] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.GithubCommitsTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:27:10,033] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.GitStatsTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:27:10,039] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.summarizedGitCommittersTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:27:10,041] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.SummarizedGithubCommitsTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:27:10,043] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.summarizedGitTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:27:10,144] ERROR {org.apache.hadoop.hive.cassandra.CassandraProxyClient} -  Error while trying to connect to cassandra host:localhost {org.apache.hadoop.hive.cassandra.CassandraProxyClient}
org.apache.hadoop.hive.cassandra.CassandraException: unable to connect to server
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:57)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.<init>(CassandraClientHolder.java:37)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.createConnection(CassandraProxyClient.java:181)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:207)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:183)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:54)
	... 25 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:351)
	at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:213)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:200)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
	at java.net.Socket.connect(Socket.java:529)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:178)
	... 27 more
TID: [0] [BAM] [2014-09-17 17:27:10,145] ERROR {org.apache.hadoop.hive.ql.exec.Task} -  FAILED: Error in metadata: java.lang.NullPointerException
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:546)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:223)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	... 17 more
 {org.apache.hadoop.hive.ql.exec.Task}
TID: [0] [BAM] [2014-09-17 17:27:10,146] ERROR {org.apache.hadoop.hive.ql.Driver} -  FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.apache.hadoop.hive.ql.Driver}
TID: [0] [BAM] [2014-09-17 17:27:10,146] ERROR {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl} -  Error while executing Hive script.
Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl}
java.sql.SQLException: Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:189)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:27:10,147] ERROR {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Error while executing script : Gituhub_MySQL {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
org.wso2.carbon.analytics.hive.exception.HiveExecutionException: Error while executing Hive script.Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl.execute(HiveExecutorServiceImpl.java:115)
	at org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask.execute(HiveScriptExecutorTask.java:60)
	at org.wso2.carbon.ntask.core.impl.TaskQuartzJobAdapter.execute(TaskQuartzJobAdapter.java:67)
	at org.quartz.core.JobRunShell.run(JobRunShell.java:213)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:27:10,152] ERROR {org.apache.hadoop.hive.cassandra.CassandraProxyClient} -  Error while trying to connect to cassandra host:localhost {org.apache.hadoop.hive.cassandra.CassandraProxyClient}
org.apache.hadoop.hive.cassandra.CassandraException: unable to connect to server
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:57)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.<init>(CassandraClientHolder.java:37)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.createConnection(CassandraProxyClient.java:181)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:207)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:183)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:54)
	... 25 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:351)
	at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:213)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:200)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
	at java.net.Socket.connect(Socket.java:529)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:178)
	... 27 more
TID: [0] [BAM] [2014-09-17 17:27:10,153] ERROR {org.apache.hadoop.hive.cassandra.CassandraProxyClient} -  Error while trying to connect to cassandra host:localhost {org.apache.hadoop.hive.cassandra.CassandraProxyClient}
org.apache.hadoop.hive.cassandra.CassandraException: unable to connect to server
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:57)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.<init>(CassandraClientHolder.java:37)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.createConnection(CassandraProxyClient.java:181)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:207)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:183)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:54)
	... 25 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:351)
	at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:213)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:200)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
	at java.net.Socket.connect(Socket.java:529)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:178)
	... 27 more
TID: [0] [BAM] [2014-09-17 17:27:10,153] ERROR {org.apache.hadoop.hive.ql.exec.Task} -  FAILED: Error in metadata: java.lang.NullPointerException
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:546)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:223)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	... 17 more
 {org.apache.hadoop.hive.ql.exec.Task}
TID: [0] [BAM] [2014-09-17 17:27:10,154] ERROR {org.apache.hadoop.hive.ql.exec.Task} -  FAILED: Error in metadata: java.lang.NullPointerException
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:546)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:223)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	... 17 more
 {org.apache.hadoop.hive.ql.exec.Task}
TID: [0] [BAM] [2014-09-17 17:27:10,154] ERROR {org.apache.hadoop.hive.ql.Driver} -  FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.apache.hadoop.hive.ql.Driver}
TID: [0] [BAM] [2014-09-17 17:27:10,155] ERROR {org.apache.hadoop.hive.ql.Driver} -  FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.apache.hadoop.hive.ql.Driver}
TID: [0] [BAM] [2014-09-17 17:27:10,155] ERROR {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl} -  Error while executing Hive script.
Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl}
java.sql.SQLException: Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:189)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:27:10,155] ERROR {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl} -  Error while executing Hive script.
Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl}
java.sql.SQLException: Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:189)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:27:10,156] ERROR {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Error while executing script :  Github_Committers_MySQL {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
org.wso2.carbon.analytics.hive.exception.HiveExecutionException: Error while executing Hive script.Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl.execute(HiveExecutorServiceImpl.java:115)
	at org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask.execute(HiveScriptExecutorTask.java:60)
	at org.wso2.carbon.ntask.core.impl.TaskQuartzJobAdapter.execute(TaskQuartzJobAdapter.java:67)
	at org.quartz.core.JobRunShell.run(JobRunShell.java:213)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:27:10,156] ERROR {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Error while executing script : Github_Commits_MySQL {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
org.wso2.carbon.analytics.hive.exception.HiveExecutionException: Error while executing Hive script.Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl.execute(HiveExecutorServiceImpl.java:115)
	at org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask.execute(HiveScriptExecutorTask.java:60)
	at org.wso2.carbon.ntask.core.impl.TaskQuartzJobAdapter.execute(TaskQuartzJobAdapter.java:67)
	at org.quartz.core.JobRunShell.run(JobRunShell.java:213)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:28:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 17:28:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:28:10,006]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 17:28:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:28:10,008]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 17:28:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:28:10,056] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.GitStatsTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:28:10,057] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.GitCommittersTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:28:10,058] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.GithubCommitsTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:28:10,067] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.summarizedGitTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:28:10,068] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.summarizedGitCommittersTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:28:10,078] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.SummarizedGithubCommitsTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:28:10,285] ERROR {org.apache.hadoop.hive.cassandra.CassandraProxyClient} -  Error while trying to connect to cassandra host:localhost {org.apache.hadoop.hive.cassandra.CassandraProxyClient}
org.apache.hadoop.hive.cassandra.CassandraException: unable to connect to server
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:57)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.<init>(CassandraClientHolder.java:37)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.createConnection(CassandraProxyClient.java:181)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:207)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:183)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:54)
	... 25 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:351)
	at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:213)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:200)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
	at java.net.Socket.connect(Socket.java:529)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:178)
	... 27 more
TID: [0] [BAM] [2014-09-17 17:28:10,287] ERROR {org.apache.hadoop.hive.cassandra.CassandraProxyClient} -  Error while trying to connect to cassandra host:localhost {org.apache.hadoop.hive.cassandra.CassandraProxyClient}
org.apache.hadoop.hive.cassandra.CassandraException: unable to connect to server
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:57)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.<init>(CassandraClientHolder.java:37)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.createConnection(CassandraProxyClient.java:181)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:207)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:183)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:54)
	... 25 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:351)
	at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:213)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:200)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
	at java.net.Socket.connect(Socket.java:529)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:178)
	... 27 more
TID: [0] [BAM] [2014-09-17 17:28:10,288] ERROR {org.apache.hadoop.hive.ql.exec.Task} -  FAILED: Error in metadata: java.lang.NullPointerException
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:546)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:223)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	... 17 more
 {org.apache.hadoop.hive.ql.exec.Task}
TID: [0] [BAM] [2014-09-17 17:28:10,290] ERROR {org.apache.hadoop.hive.ql.exec.Task} -  FAILED: Error in metadata: java.lang.NullPointerException
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:546)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:223)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	... 17 more
 {org.apache.hadoop.hive.ql.exec.Task}
TID: [0] [BAM] [2014-09-17 17:28:10,291] ERROR {org.apache.hadoop.hive.ql.Driver} -  FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.apache.hadoop.hive.ql.Driver}
TID: [0] [BAM] [2014-09-17 17:28:10,292] ERROR {org.apache.hadoop.hive.ql.Driver} -  FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.apache.hadoop.hive.ql.Driver}
TID: [0] [BAM] [2014-09-17 17:28:10,294] ERROR {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl} -  Error while executing Hive script.
Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl}
java.sql.SQLException: Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:189)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:28:10,294] ERROR {org.apache.hadoop.hive.cassandra.CassandraProxyClient} -  Error while trying to connect to cassandra host:localhost {org.apache.hadoop.hive.cassandra.CassandraProxyClient}
org.apache.hadoop.hive.cassandra.CassandraException: unable to connect to server
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:57)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.<init>(CassandraClientHolder.java:37)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.createConnection(CassandraProxyClient.java:181)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:207)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:183)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:54)
	... 25 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:351)
	at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:213)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:200)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
	at java.net.Socket.connect(Socket.java:529)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:178)
	... 27 more
TID: [0] [BAM] [2014-09-17 17:28:10,294] ERROR {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl} -  Error while executing Hive script.
Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl}
java.sql.SQLException: Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:189)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:28:10,297] ERROR {org.apache.hadoop.hive.ql.exec.Task} -  FAILED: Error in metadata: java.lang.NullPointerException
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:546)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:223)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	... 17 more
 {org.apache.hadoop.hive.ql.exec.Task}
TID: [0] [BAM] [2014-09-17 17:28:10,294] ERROR {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Error while executing script :  Github_Committers_MySQL {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
org.wso2.carbon.analytics.hive.exception.HiveExecutionException: Error while executing Hive script.Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl.execute(HiveExecutorServiceImpl.java:115)
	at org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask.execute(HiveScriptExecutorTask.java:60)
	at org.wso2.carbon.ntask.core.impl.TaskQuartzJobAdapter.execute(TaskQuartzJobAdapter.java:67)
	at org.quartz.core.JobRunShell.run(JobRunShell.java:213)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:28:10,299] ERROR {org.apache.hadoop.hive.ql.Driver} -  FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.apache.hadoop.hive.ql.Driver}
TID: [0] [BAM] [2014-09-17 17:28:10,298] ERROR {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Error while executing script : Github_Commits_MySQL {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
org.wso2.carbon.analytics.hive.exception.HiveExecutionException: Error while executing Hive script.Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl.execute(HiveExecutorServiceImpl.java:115)
	at org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask.execute(HiveScriptExecutorTask.java:60)
	at org.wso2.carbon.ntask.core.impl.TaskQuartzJobAdapter.execute(TaskQuartzJobAdapter.java:67)
	at org.quartz.core.JobRunShell.run(JobRunShell.java:213)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:28:10,300] ERROR {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl} -  Error while executing Hive script.
Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl}
java.sql.SQLException: Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:189)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:28:10,302] ERROR {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Error while executing script : Gituhub_MySQL {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
org.wso2.carbon.analytics.hive.exception.HiveExecutionException: Error while executing Hive script.Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl.execute(HiveExecutorServiceImpl.java:115)
	at org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask.execute(HiveScriptExecutorTask.java:60)
	at org.wso2.carbon.ntask.core.impl.TaskQuartzJobAdapter.execute(TaskQuartzJobAdapter.java:67)
	at org.quartz.core.JobRunShell.run(JobRunShell.java:213)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:29:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 17:29:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:29:10,005]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 17:29:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:29:10,007]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 17:29:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:29:10,029] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.GithubCommitsTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:29:10,029] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.GitCommittersTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:29:10,029] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.GitStatsTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:29:10,033] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.SummarizedGithubCommitsTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:29:10,033] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.summarizedGitTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:29:10,033] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.summarizedGitCommittersTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:29:10,112] ERROR {org.apache.hadoop.hive.cassandra.CassandraProxyClient} -  Error while trying to connect to cassandra host:localhost {org.apache.hadoop.hive.cassandra.CassandraProxyClient}
org.apache.hadoop.hive.cassandra.CassandraException: unable to connect to server
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:57)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.<init>(CassandraClientHolder.java:37)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.createConnection(CassandraProxyClient.java:181)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:207)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:183)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:54)
	... 25 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:351)
	at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:213)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:200)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
	at java.net.Socket.connect(Socket.java:529)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:178)
	... 27 more
TID: [0] [BAM] [2014-09-17 17:29:10,113] ERROR {org.apache.hadoop.hive.ql.exec.Task} -  FAILED: Error in metadata: java.lang.NullPointerException
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:546)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:223)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	... 17 more
 {org.apache.hadoop.hive.ql.exec.Task}
TID: [0] [BAM] [2014-09-17 17:29:10,114] ERROR {org.apache.hadoop.hive.ql.Driver} -  FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.apache.hadoop.hive.ql.Driver}
TID: [0] [BAM] [2014-09-17 17:29:10,114] ERROR {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl} -  Error while executing Hive script.
Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl}
java.sql.SQLException: Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:189)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:29:10,114] ERROR {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Error while executing script :  Github_Committers_MySQL {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
org.wso2.carbon.analytics.hive.exception.HiveExecutionException: Error while executing Hive script.Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl.execute(HiveExecutorServiceImpl.java:115)
	at org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask.execute(HiveScriptExecutorTask.java:60)
	at org.wso2.carbon.ntask.core.impl.TaskQuartzJobAdapter.execute(TaskQuartzJobAdapter.java:67)
	at org.quartz.core.JobRunShell.run(JobRunShell.java:213)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:29:10,124] ERROR {org.apache.hadoop.hive.cassandra.CassandraProxyClient} -  Error while trying to connect to cassandra host:localhost {org.apache.hadoop.hive.cassandra.CassandraProxyClient}
org.apache.hadoop.hive.cassandra.CassandraException: unable to connect to server
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:57)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.<init>(CassandraClientHolder.java:37)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.createConnection(CassandraProxyClient.java:181)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:207)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:183)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:54)
	... 25 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:351)
	at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:213)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:200)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
	at java.net.Socket.connect(Socket.java:529)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:178)
	... 27 more
TID: [0] [BAM] [2014-09-17 17:29:10,124] ERROR {org.apache.hadoop.hive.cassandra.CassandraProxyClient} -  Error while trying to connect to cassandra host:localhost {org.apache.hadoop.hive.cassandra.CassandraProxyClient}
org.apache.hadoop.hive.cassandra.CassandraException: unable to connect to server
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:57)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.<init>(CassandraClientHolder.java:37)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.createConnection(CassandraProxyClient.java:181)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:207)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:183)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:54)
	... 25 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:351)
	at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:213)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:200)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
	at java.net.Socket.connect(Socket.java:529)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:178)
	... 27 more
TID: [0] [BAM] [2014-09-17 17:29:10,125] ERROR {org.apache.hadoop.hive.ql.exec.Task} -  FAILED: Error in metadata: java.lang.NullPointerException
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:546)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:223)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	... 17 more
 {org.apache.hadoop.hive.ql.exec.Task}
TID: [0] [BAM] [2014-09-17 17:29:10,126] ERROR {org.apache.hadoop.hive.ql.exec.Task} -  FAILED: Error in metadata: java.lang.NullPointerException
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:546)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:223)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	... 17 more
 {org.apache.hadoop.hive.ql.exec.Task}
TID: [0] [BAM] [2014-09-17 17:29:10,126] ERROR {org.apache.hadoop.hive.ql.Driver} -  FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.apache.hadoop.hive.ql.Driver}
TID: [0] [BAM] [2014-09-17 17:29:10,127] ERROR {org.apache.hadoop.hive.ql.Driver} -  FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.apache.hadoop.hive.ql.Driver}
TID: [0] [BAM] [2014-09-17 17:29:10,128] ERROR {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl} -  Error while executing Hive script.
Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl}
java.sql.SQLException: Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:189)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:29:10,128] ERROR {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl} -  Error while executing Hive script.
Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl}
java.sql.SQLException: Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:189)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:29:10,128] ERROR {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Error while executing script : Github_Commits_MySQL {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
org.wso2.carbon.analytics.hive.exception.HiveExecutionException: Error while executing Hive script.Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl.execute(HiveExecutorServiceImpl.java:115)
	at org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask.execute(HiveScriptExecutorTask.java:60)
	at org.wso2.carbon.ntask.core.impl.TaskQuartzJobAdapter.execute(TaskQuartzJobAdapter.java:67)
	at org.quartz.core.JobRunShell.run(JobRunShell.java:213)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:29:10,129] ERROR {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Error while executing script : Gituhub_MySQL {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
org.wso2.carbon.analytics.hive.exception.HiveExecutionException: Error while executing Hive script.Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl.execute(HiveExecutorServiceImpl.java:115)
	at org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask.execute(HiveScriptExecutorTask.java:60)
	at org.wso2.carbon.ntask.core.impl.TaskQuartzJobAdapter.execute(TaskQuartzJobAdapter.java:67)
	at org.quartz.core.JobRunShell.run(JobRunShell.java:213)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:29:17,789] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.GitStatsTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:29:17,793] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.summarizedGitTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:29:17,836] ERROR {org.apache.hadoop.hive.cassandra.CassandraProxyClient} -  Error while trying to connect to cassandra host:localhost {org.apache.hadoop.hive.cassandra.CassandraProxyClient}
org.apache.hadoop.hive.cassandra.CassandraException: unable to connect to server
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:57)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.<init>(CassandraClientHolder.java:37)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.createConnection(CassandraProxyClient.java:181)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:207)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:183)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:54)
	... 25 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:351)
	at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:213)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:200)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
	at java.net.Socket.connect(Socket.java:529)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:178)
	... 27 more
TID: [0] [BAM] [2014-09-17 17:29:17,837] ERROR {org.apache.hadoop.hive.ql.exec.Task} -  FAILED: Error in metadata: java.lang.NullPointerException
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:546)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:223)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	... 17 more
 {org.apache.hadoop.hive.ql.exec.Task}
TID: [0] [BAM] [2014-09-17 17:29:17,837] ERROR {org.apache.hadoop.hive.ql.Driver} -  FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.apache.hadoop.hive.ql.Driver}
TID: [0] [BAM] [2014-09-17 17:29:17,837] ERROR {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl} -  Error while executing Hive script.
Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl}
java.sql.SQLException: Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:189)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:29:17,847] ERROR {org.wso2.carbon.analytics.hive.ui.client.HiveExecutionClient} -  Error while executing Hive script.Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.wso2.carbon.analytics.hive.ui.client.HiveExecutionClient}
org.wso2.carbon.analytics.hive.stub.HiveExecutionServiceHiveExecutionException: HiveExecutionServiceHiveExecutionException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
	at java.lang.Class.newInstance0(Class.java:357)
	at java.lang.Class.newInstance(Class.java:310)
	at org.wso2.carbon.analytics.hive.stub.HiveExecutionServiceStub.executeHiveScript(HiveExecutionServiceStub.java:216)
	at org.wso2.carbon.analytics.hive.ui.client.HiveExecutionClient.executeScript(HiveExecutionClient.java:66)
	at org.apache.jsp.hive_002dexplorer.queryresults_jsp._jspService(org.apache.jsp.hive_002dexplorer.queryresults_jsp:92)
	at org.apache.jasper.runtime.HttpJspBase.service(HttpJspBase.java:111)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.apache.jasper.servlet.JspServletWrapper.service(JspServletWrapper.java:403)
	at org.apache.jasper.servlet.JspServlet.serviceJspFile(JspServlet.java:492)
	at org.apache.jasper.servlet.JspServlet.service(JspServlet.java:378)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.wso2.carbon.ui.JspServlet.service(JspServlet.java:155)
	at org.wso2.carbon.ui.TilesJspServlet.service(TilesJspServlet.java:80)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.eclipse.equinox.http.helper.ContextPathServletAdaptor.service(ContextPathServletAdaptor.java:37)
	at org.eclipse.equinox.http.servlet.internal.ServletRegistration.service(ServletRegistration.java:61)
	at org.eclipse.equinox.http.servlet.internal.ProxyServlet.processAlias(ProxyServlet.java:128)
	at org.eclipse.equinox.http.servlet.internal.ProxyServlet.service(ProxyServlet.java:68)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.wso2.carbon.tomcat.ext.servlet.DelegationServlet.service(DelegationServlet.java:68)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:305)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.apache.catalina.core.ApplicationDispatcher.invoke(ApplicationDispatcher.java:749)
	at org.apache.catalina.core.ApplicationDispatcher.doInclude(ApplicationDispatcher.java:605)
	at org.apache.catalina.core.ApplicationDispatcher.include(ApplicationDispatcher.java:544)
	at org.eclipse.equinox.http.servlet.internal.RequestDispatcherAdaptor.include(RequestDispatcherAdaptor.java:37)
	at org.eclipse.equinox.http.helper.ContextPathServletAdaptor$RequestDispatcherAdaptor.include(ContextPathServletAdaptor.java:369)
	at org.apache.jasper.runtime.JspRuntimeLibrary.include(JspRuntimeLibrary.java:1015)
	at org.apache.jasper.runtime.PageContextImpl.include(PageContextImpl.java:700)
	at sun.reflect.GeneratedMethodAccessor47.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.tiles.jsp.context.JspUtil.doInclude(JspUtil.java:87)
	at org.apache.tiles.jsp.context.JspTilesRequestContext.include(JspTilesRequestContext.java:88)
	at org.apache.tiles.jsp.context.JspTilesRequestContext.dispatch(JspTilesRequestContext.java:82)
	at org.apache.tiles.impl.BasicTilesContainer.render(BasicTilesContainer.java:465)
	at org.apache.tiles.jsp.taglib.InsertAttributeTag.render(InsertAttributeTag.java:140)
	at org.apache.tiles.jsp.taglib.InsertAttributeTag.render(InsertAttributeTag.java:117)
	at org.apache.tiles.jsp.taglib.RenderTagSupport.execute(RenderTagSupport.java:171)
	at org.apache.tiles.jsp.taglib.RoleSecurityTagSupport.doEndTag(RoleSecurityTagSupport.java:75)
	at org.apache.tiles.jsp.taglib.ContainerTagSupport.doEndTag(ContainerTagSupport.java:80)
	at org.apache.jsp.admin.layout.template_jsp._jspx_meth_tiles_insertAttribute_7(org.apache.jsp.admin.layout.template_jsp:603)
	at org.apache.jsp.admin.layout.template_jsp._jspService(org.apache.jsp.admin.layout.template_jsp:335)
	at org.apache.jasper.runtime.HttpJspBase.service(HttpJspBase.java:111)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.apache.jasper.servlet.JspServletWrapper.service(JspServletWrapper.java:403)
	at org.apache.jasper.servlet.JspServlet.serviceJspFile(JspServlet.java:492)
	at org.apache.jasper.servlet.JspServlet.service(JspServlet.java:378)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.wso2.carbon.ui.JspServlet.service(JspServlet.java:155)
	at org.wso2.carbon.ui.TilesJspServlet.service(TilesJspServlet.java:80)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.eclipse.equinox.http.helper.ContextPathServletAdaptor.service(ContextPathServletAdaptor.java:37)
	at org.eclipse.equinox.http.servlet.internal.ServletRegistration.service(ServletRegistration.java:61)
	at org.eclipse.equinox.http.servlet.internal.ProxyServlet.processAlias(ProxyServlet.java:128)
	at org.eclipse.equinox.http.servlet.internal.ProxyServlet.service(ProxyServlet.java:68)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.wso2.carbon.tomcat.ext.servlet.DelegationServlet.service(DelegationServlet.java:68)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:305)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.apache.catalina.core.ApplicationDispatcher.invoke(ApplicationDispatcher.java:749)
	at org.apache.catalina.core.ApplicationDispatcher.processRequest(ApplicationDispatcher.java:487)
	at org.apache.catalina.core.ApplicationDispatcher.doForward(ApplicationDispatcher.java:412)
	at org.apache.catalina.core.ApplicationDispatcher.forward(ApplicationDispatcher.java:339)
	at org.eclipse.equinox.http.servlet.internal.RequestDispatcherAdaptor.forward(RequestDispatcherAdaptor.java:30)
	at org.eclipse.equinox.http.helper.ContextPathServletAdaptor$RequestDispatcherAdaptor.forward(ContextPathServletAdaptor.java:362)
	at org.apache.tiles.servlet.context.ServletTilesRequestContext.forward(ServletTilesRequestContext.java:198)
	at org.apache.tiles.servlet.context.ServletTilesRequestContext.dispatch(ServletTilesRequestContext.java:185)
	at org.apache.tiles.impl.BasicTilesContainer.render(BasicTilesContainer.java:419)
	at org.apache.tiles.impl.BasicTilesContainer.render(BasicTilesContainer.java:370)
	at org.wso2.carbon.ui.action.ActionHelper.render(ActionHelper.java:52)
	at org.wso2.carbon.ui.TilesJspServlet.service(TilesJspServlet.java:101)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.eclipse.equinox.http.helper.ContextPathServletAdaptor.service(ContextPathServletAdaptor.java:37)
	at org.eclipse.equinox.http.servlet.internal.ServletRegistration.service(ServletRegistration.java:61)
	at org.eclipse.equinox.http.servlet.internal.ProxyServlet.processAlias(ProxyServlet.java:128)
	at org.eclipse.equinox.http.servlet.internal.ProxyServlet.service(ProxyServlet.java:68)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.wso2.carbon.tomcat.ext.servlet.DelegationServlet.service(DelegationServlet.java:68)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:305)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.wso2.carbon.tomcat.ext.filter.CharacterSetFilter.doFilter(CharacterSetFilter.java:61)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:222)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:123)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:472)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:171)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:99)
	at org.wso2.carbon.tomcat.ext.valves.CompositeValve.continueInvocation(CompositeValve.java:178)
	at org.wso2.carbon.tomcat.ext.valves.CarbonTomcatValve$1.invoke(CarbonTomcatValve.java:47)
	at org.wso2.carbon.webapp.mgt.TenantLazyLoaderValve.invoke(TenantLazyLoaderValve.java:56)
	at org.wso2.carbon.tomcat.ext.valves.TomcatValveContainer.invokeValves(TomcatValveContainer.java:47)
	at org.wso2.carbon.tomcat.ext.valves.CompositeValve.invoke(CompositeValve.java:141)
	at org.wso2.carbon.tomcat.ext.valves.CarbonStuckThreadDetectionValve.invoke(CarbonStuckThreadDetectionValve.java:156)
	at org.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:936)
	at org.wso2.carbon.tomcat.ext.valves.CarbonContextCreatorValve.invoke(CarbonContextCreatorValve.java:52)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:118)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:407)
	at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1004)
	at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:589)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1653)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:30:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 17:30:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:30:10,005]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 17:30:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:30:10,007]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 17:30:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:30:10,030] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.GithubCommitsTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:30:10,030] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.GitCommittersTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:30:10,030] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.GitStatsTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:30:10,035] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.SummarizedGithubCommitsTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:30:10,045] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.summarizedGitCommittersTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:30:10,047] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.summarizedGitTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:30:10,122] ERROR {org.apache.hadoop.hive.cassandra.CassandraProxyClient} -  Error while trying to connect to cassandra host:localhost {org.apache.hadoop.hive.cassandra.CassandraProxyClient}
org.apache.hadoop.hive.cassandra.CassandraException: unable to connect to server
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:57)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.<init>(CassandraClientHolder.java:37)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.createConnection(CassandraProxyClient.java:181)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:207)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:183)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:54)
	... 25 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:351)
	at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:213)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:200)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
	at java.net.Socket.connect(Socket.java:529)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:178)
	... 27 more
TID: [0] [BAM] [2014-09-17 17:30:10,123] ERROR {org.apache.hadoop.hive.cassandra.CassandraProxyClient} -  Error while trying to connect to cassandra host:localhost {org.apache.hadoop.hive.cassandra.CassandraProxyClient}
org.apache.hadoop.hive.cassandra.CassandraException: unable to connect to server
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:57)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.<init>(CassandraClientHolder.java:37)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.createConnection(CassandraProxyClient.java:181)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:207)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:183)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:54)
	... 25 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:351)
	at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:213)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:200)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
	at java.net.Socket.connect(Socket.java:529)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:178)
	... 27 more
TID: [0] [BAM] [2014-09-17 17:30:10,123] ERROR {org.apache.hadoop.hive.cassandra.CassandraProxyClient} -  Error while trying to connect to cassandra host:localhost {org.apache.hadoop.hive.cassandra.CassandraProxyClient}
org.apache.hadoop.hive.cassandra.CassandraException: unable to connect to server
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:57)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.<init>(CassandraClientHolder.java:37)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.createConnection(CassandraProxyClient.java:181)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:207)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:183)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:54)
	... 25 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:351)
	at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:213)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:200)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
	at java.net.Socket.connect(Socket.java:529)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:178)
	... 27 more
TID: [0] [BAM] [2014-09-17 17:30:10,124] ERROR {org.apache.hadoop.hive.ql.exec.Task} -  FAILED: Error in metadata: java.lang.NullPointerException
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:546)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:223)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	... 17 more
 {org.apache.hadoop.hive.ql.exec.Task}
TID: [0] [BAM] [2014-09-17 17:30:10,124] ERROR {org.apache.hadoop.hive.ql.exec.Task} -  FAILED: Error in metadata: java.lang.NullPointerException
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:546)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:223)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	... 17 more
 {org.apache.hadoop.hive.ql.exec.Task}
TID: [0] [BAM] [2014-09-17 17:30:10,125] ERROR {org.apache.hadoop.hive.ql.Driver} -  FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.apache.hadoop.hive.ql.Driver}
TID: [0] [BAM] [2014-09-17 17:30:10,125] ERROR {org.apache.hadoop.hive.ql.exec.Task} -  FAILED: Error in metadata: java.lang.NullPointerException
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:546)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:223)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	... 17 more
 {org.apache.hadoop.hive.ql.exec.Task}
TID: [0] [BAM] [2014-09-17 17:30:10,126] ERROR {org.apache.hadoop.hive.ql.Driver} -  FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.apache.hadoop.hive.ql.Driver}
TID: [0] [BAM] [2014-09-17 17:30:10,126] ERROR {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl} -  Error while executing Hive script.
Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl}
java.sql.SQLException: Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:189)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:30:10,127] ERROR {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl} -  Error while executing Hive script.
Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl}
java.sql.SQLException: Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:189)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:30:10,127] ERROR {org.apache.hadoop.hive.ql.Driver} -  FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.apache.hadoop.hive.ql.Driver}
TID: [0] [BAM] [2014-09-17 17:30:10,127] ERROR {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Error while executing script :  Github_Committers_MySQL {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
org.wso2.carbon.analytics.hive.exception.HiveExecutionException: Error while executing Hive script.Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl.execute(HiveExecutorServiceImpl.java:115)
	at org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask.execute(HiveScriptExecutorTask.java:60)
	at org.wso2.carbon.ntask.core.impl.TaskQuartzJobAdapter.execute(TaskQuartzJobAdapter.java:67)
	at org.quartz.core.JobRunShell.run(JobRunShell.java:213)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:30:10,127] ERROR {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl} -  Error while executing Hive script.
Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl}
java.sql.SQLException: Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:189)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:30:10,127] ERROR {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Error while executing script : Github_Commits_MySQL {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
org.wso2.carbon.analytics.hive.exception.HiveExecutionException: Error while executing Hive script.Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl.execute(HiveExecutorServiceImpl.java:115)
	at org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask.execute(HiveScriptExecutorTask.java:60)
	at org.wso2.carbon.ntask.core.impl.TaskQuartzJobAdapter.execute(TaskQuartzJobAdapter.java:67)
	at org.quartz.core.JobRunShell.run(JobRunShell.java:213)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:30:10,128] ERROR {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Error while executing script : Gituhub_MySQL {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
org.wso2.carbon.analytics.hive.exception.HiveExecutionException: Error while executing Hive script.Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl.execute(HiveExecutorServiceImpl.java:115)
	at org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask.execute(HiveScriptExecutorTask.java:60)
	at org.wso2.carbon.ntask.core.impl.TaskQuartzJobAdapter.execute(TaskQuartzJobAdapter.java:67)
	at org.quartz.core.JobRunShell.run(JobRunShell.java:213)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:31:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 17:31:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:31:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 17:31:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:31:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 17:31:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:31:10,025] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.GitStatsTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:31:10,029] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.GitCommittersTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:31:10,030] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.GithubCommitsTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:31:10,033] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.summarizedGitTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:31:10,038] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.summarizedGitCommittersTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:31:10,038] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.SummarizedGithubCommitsTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:31:10,117] ERROR {org.apache.hadoop.hive.cassandra.CassandraProxyClient} -  Error while trying to connect to cassandra host:localhost {org.apache.hadoop.hive.cassandra.CassandraProxyClient}
org.apache.hadoop.hive.cassandra.CassandraException: unable to connect to server
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:57)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.<init>(CassandraClientHolder.java:37)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.createConnection(CassandraProxyClient.java:181)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:207)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:183)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:54)
	... 25 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:351)
	at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:213)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:200)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
	at java.net.Socket.connect(Socket.java:529)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:178)
	... 27 more
TID: [0] [BAM] [2014-09-17 17:31:10,119] ERROR {org.apache.hadoop.hive.ql.exec.Task} -  FAILED: Error in metadata: java.lang.NullPointerException
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:546)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:223)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	... 17 more
 {org.apache.hadoop.hive.ql.exec.Task}
TID: [0] [BAM] [2014-09-17 17:31:10,120] ERROR {org.apache.hadoop.hive.ql.Driver} -  FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.apache.hadoop.hive.ql.Driver}
TID: [0] [BAM] [2014-09-17 17:31:10,120] ERROR {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl} -  Error while executing Hive script.
Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl}
java.sql.SQLException: Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:189)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:31:10,121] ERROR {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Error while executing script :  Github_Committers_MySQL {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
org.wso2.carbon.analytics.hive.exception.HiveExecutionException: Error while executing Hive script.Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl.execute(HiveExecutorServiceImpl.java:115)
	at org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask.execute(HiveScriptExecutorTask.java:60)
	at org.wso2.carbon.ntask.core.impl.TaskQuartzJobAdapter.execute(TaskQuartzJobAdapter.java:67)
	at org.quartz.core.JobRunShell.run(JobRunShell.java:213)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:31:10,131] ERROR {org.apache.hadoop.hive.cassandra.CassandraProxyClient} -  Error while trying to connect to cassandra host:localhost {org.apache.hadoop.hive.cassandra.CassandraProxyClient}
org.apache.hadoop.hive.cassandra.CassandraException: unable to connect to server
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:57)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.<init>(CassandraClientHolder.java:37)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.createConnection(CassandraProxyClient.java:181)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:207)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:183)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:54)
	... 25 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:351)
	at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:213)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:200)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
	at java.net.Socket.connect(Socket.java:529)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:178)
	... 27 more
TID: [0] [BAM] [2014-09-17 17:31:10,133] ERROR {org.apache.hadoop.hive.ql.exec.Task} -  FAILED: Error in metadata: java.lang.NullPointerException
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:546)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:223)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	... 17 more
 {org.apache.hadoop.hive.ql.exec.Task}
TID: [0] [BAM] [2014-09-17 17:31:10,134] ERROR {org.apache.hadoop.hive.ql.Driver} -  FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.apache.hadoop.hive.ql.Driver}
TID: [0] [BAM] [2014-09-17 17:31:10,134] ERROR {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl} -  Error while executing Hive script.
Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl}
java.sql.SQLException: Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:189)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:31:10,135] ERROR {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Error while executing script : Gituhub_MySQL {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
org.wso2.carbon.analytics.hive.exception.HiveExecutionException: Error while executing Hive script.Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl.execute(HiveExecutorServiceImpl.java:115)
	at org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask.execute(HiveScriptExecutorTask.java:60)
	at org.wso2.carbon.ntask.core.impl.TaskQuartzJobAdapter.execute(TaskQuartzJobAdapter.java:67)
	at org.quartz.core.JobRunShell.run(JobRunShell.java:213)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:31:10,139] ERROR {org.apache.hadoop.hive.cassandra.CassandraProxyClient} -  Error while trying to connect to cassandra host:localhost {org.apache.hadoop.hive.cassandra.CassandraProxyClient}
org.apache.hadoop.hive.cassandra.CassandraException: unable to connect to server
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:57)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.<init>(CassandraClientHolder.java:37)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.createConnection(CassandraProxyClient.java:181)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:207)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:183)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:54)
	... 25 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:351)
	at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:213)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:200)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
	at java.net.Socket.connect(Socket.java:529)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:178)
	... 27 more
TID: [0] [BAM] [2014-09-17 17:31:10,141] ERROR {org.apache.hadoop.hive.ql.exec.Task} -  FAILED: Error in metadata: java.lang.NullPointerException
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:546)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:223)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	... 17 more
 {org.apache.hadoop.hive.ql.exec.Task}
TID: [0] [BAM] [2014-09-17 17:31:10,141] ERROR {org.apache.hadoop.hive.ql.Driver} -  FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.apache.hadoop.hive.ql.Driver}
TID: [0] [BAM] [2014-09-17 17:31:10,141] ERROR {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl} -  Error while executing Hive script.
Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl}
java.sql.SQLException: Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:189)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:31:10,142] ERROR {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Error while executing script : Github_Commits_MySQL {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
org.wso2.carbon.analytics.hive.exception.HiveExecutionException: Error while executing Hive script.Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl.execute(HiveExecutorServiceImpl.java:115)
	at org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask.execute(HiveScriptExecutorTask.java:60)
	at org.wso2.carbon.ntask.core.impl.TaskQuartzJobAdapter.execute(TaskQuartzJobAdapter.java:67)
	at org.quartz.core.JobRunShell.run(JobRunShell.java:213)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:32:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 17:32:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:32:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 17:32:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:32:10,005]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 17:32:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:32:10,424] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.GitCommittersTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:32:10,430] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.summarizedGitCommittersTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:32:10,432] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.GithubCommitsTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:32:10,434] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.GitStatsTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:32:10,440] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.SummarizedGithubCommitsTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:32:10,441] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.summarizedGitTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:32:10,510] ERROR {org.apache.hadoop.hive.cassandra.CassandraProxyClient} -  Error while trying to connect to cassandra host:localhost {org.apache.hadoop.hive.cassandra.CassandraProxyClient}
org.apache.hadoop.hive.cassandra.CassandraException: unable to connect to server
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:57)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.<init>(CassandraClientHolder.java:37)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.createConnection(CassandraProxyClient.java:181)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:207)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:183)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:54)
	... 25 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:351)
	at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:213)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:200)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
	at java.net.Socket.connect(Socket.java:529)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:178)
	... 27 more
TID: [0] [BAM] [2014-09-17 17:32:10,512] ERROR {org.apache.hadoop.hive.ql.exec.Task} -  FAILED: Error in metadata: java.lang.NullPointerException
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:546)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:223)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	... 17 more
 {org.apache.hadoop.hive.ql.exec.Task}
TID: [0] [BAM] [2014-09-17 17:32:10,513] ERROR {org.apache.hadoop.hive.ql.Driver} -  FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.apache.hadoop.hive.ql.Driver}
TID: [0] [BAM] [2014-09-17 17:32:10,513] ERROR {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl} -  Error while executing Hive script.
Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl}
java.sql.SQLException: Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:189)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:32:10,513] ERROR {org.apache.hadoop.hive.cassandra.CassandraProxyClient} -  Error while trying to connect to cassandra host:localhost {org.apache.hadoop.hive.cassandra.CassandraProxyClient}
org.apache.hadoop.hive.cassandra.CassandraException: unable to connect to server
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:57)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.<init>(CassandraClientHolder.java:37)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.createConnection(CassandraProxyClient.java:181)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:207)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:183)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:54)
	... 25 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:351)
	at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:213)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:200)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
	at java.net.Socket.connect(Socket.java:529)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:178)
	... 27 more
TID: [0] [BAM] [2014-09-17 17:32:10,514] ERROR {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Error while executing script :  Github_Committers_MySQL {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
org.wso2.carbon.analytics.hive.exception.HiveExecutionException: Error while executing Hive script.Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl.execute(HiveExecutorServiceImpl.java:115)
	at org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask.execute(HiveScriptExecutorTask.java:60)
	at org.wso2.carbon.ntask.core.impl.TaskQuartzJobAdapter.execute(TaskQuartzJobAdapter.java:67)
	at org.quartz.core.JobRunShell.run(JobRunShell.java:213)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:32:10,516] ERROR {org.apache.hadoop.hive.ql.exec.Task} -  FAILED: Error in metadata: java.lang.NullPointerException
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:546)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:223)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	... 17 more
 {org.apache.hadoop.hive.ql.exec.Task}
TID: [0] [BAM] [2014-09-17 17:32:10,516] ERROR {org.apache.hadoop.hive.ql.Driver} -  FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.apache.hadoop.hive.ql.Driver}
TID: [0] [BAM] [2014-09-17 17:32:10,516] ERROR {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl} -  Error while executing Hive script.
Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl}
java.sql.SQLException: Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:189)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:32:10,517] ERROR {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Error while executing script : Gituhub_MySQL {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
org.wso2.carbon.analytics.hive.exception.HiveExecutionException: Error while executing Hive script.Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl.execute(HiveExecutorServiceImpl.java:115)
	at org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask.execute(HiveScriptExecutorTask.java:60)
	at org.wso2.carbon.ntask.core.impl.TaskQuartzJobAdapter.execute(TaskQuartzJobAdapter.java:67)
	at org.quartz.core.JobRunShell.run(JobRunShell.java:213)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:32:10,522] ERROR {org.apache.hadoop.hive.cassandra.CassandraProxyClient} -  Error while trying to connect to cassandra host:localhost {org.apache.hadoop.hive.cassandra.CassandraProxyClient}
org.apache.hadoop.hive.cassandra.CassandraException: unable to connect to server
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:57)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.<init>(CassandraClientHolder.java:37)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.createConnection(CassandraProxyClient.java:181)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:207)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:183)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.hadoop.hive.cassandra.CassandraClientHolder.initClient(CassandraClientHolder.java:54)
	... 25 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:351)
	at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:213)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:200)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
	at java.net.Socket.connect(Socket.java:529)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:178)
	... 27 more
TID: [0] [BAM] [2014-09-17 17:32:10,524] ERROR {org.apache.hadoop.hive.ql.exec.Task} -  FAILED: Error in metadata: java.lang.NullPointerException
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:546)
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:3479)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:225)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.initializeConnection(CassandraProxyClient.java:223)
	at org.apache.hadoop.hive.cassandra.CassandraProxyClient.<init>(CassandraProxyClient.java:144)
	at org.apache.hadoop.hive.cassandra.CassandraManager.openConnection(CassandraManager.java:188)
	at org.apache.hadoop.hive.cassandra.CassandraStorageHandler.preCreateTable(CassandraStorageHandler.java:260)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:396)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:540)
	... 17 more
 {org.apache.hadoop.hive.ql.exec.Task}
TID: [0] [BAM] [2014-09-17 17:32:10,525] ERROR {org.apache.hadoop.hive.ql.Driver} -  FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.apache.hadoop.hive.ql.Driver}
TID: [0] [BAM] [2014-09-17 17:32:10,525] ERROR {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl} -  Error while executing Hive script.
Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask {org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl}
java.sql.SQLException: Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:189)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:32:10,526] ERROR {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Error while executing script : Github_Commits_MySQL {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
org.wso2.carbon.analytics.hive.exception.HiveExecutionException: Error while executing Hive script.Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl.execute(HiveExecutorServiceImpl.java:115)
	at org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask.execute(HiveScriptExecutorTask.java:60)
	at org.wso2.carbon.ntask.core.impl.TaskQuartzJobAdapter.execute(TaskQuartzJobAdapter.java:67)
	at org.quartz.core.JobRunShell.run(JobRunShell.java:213)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
TID: [0] [BAM] [2014-09-17 17:32:57,625]  INFO {org.apache.cassandra.thrift.CassandraDaemon} -  Stop listening to thrift clients {org.apache.cassandra.thrift.CassandraDaemon}
TID: [0] [BAM] [2014-09-17 17:32:57,627]  INFO {org.apache.cassandra.gms.Gossiper} -  Announcing shutdown {org.apache.cassandra.gms.Gossiper}
TID: [0] [BAM] [2014-09-17 17:32:57,627]  INFO {org.wso2.carbon.core.init.CarbonServerManager} -  Shutdown hook triggered.... {org.wso2.carbon.core.init.CarbonServerManager}
TID: [0] [BAM] [2014-09-17 17:32:57,627]  INFO {org.wso2.carbon.core.init.CarbonServerManager} -  Gracefully shutting down WSO2 Business Activity Monitor... {org.wso2.carbon.core.init.CarbonServerManager}
TID: [0] [BAM] [2014-09-17 17:32:57,629]  INFO {org.wso2.carbon.core.ServerManagement} -  Starting to switch to maintenance mode... {org.wso2.carbon.core.ServerManagement}
TID: [0] [BAM] [2014-09-17 17:32:57,629]  INFO {org.wso2.carbon.core.ServerManagement} -  Stopped all transport listeners {org.wso2.carbon.core.ServerManagement}
TID: [0] [BAM] [2014-09-17 17:32:57,629]  INFO {org.wso2.carbon.core.ServerManagement} -  Waiting for request service completion... {org.wso2.carbon.core.ServerManagement}
TID: [0] [BAM] [2014-09-17 17:32:57,632]  INFO {org.wso2.carbon.core.ServerManagement} -  All requests have been served. {org.wso2.carbon.core.ServerManagement}
TID: [0] [BAM] [2014-09-17 17:32:57,632]  INFO {org.wso2.carbon.core.ServerManagement} -  Waiting for deployment completion... {org.wso2.carbon.core.ServerManagement}
TID: [0] [BAM] [2014-09-17 17:32:57,647]  INFO {org.wso2.carbon.webapp.mgt.WebApplication} -  Unloaded webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/STRATOS_ROOT] {org.wso2.carbon.webapp.mgt.WebApplication}
TID: [0] [BAM] [2014-09-17 17:32:57,648]  INFO {org.springframework.web.context.support.XmlWebApplicationContext} -  Closing Root WebApplicationContext: startup date [Wed Sep 17 17:22:07 IST 2014]; root of context hierarchy {org.springframework.web.context.support.XmlWebApplicationContext}
TID: [0] [BAM] [2014-09-17 17:32:57,648]  INFO {org.springframework.beans.factory.support.DefaultListableBeanFactory} -  Destroying singletons in org.springframework.beans.factory.support.DefaultListableBeanFactory@718f7af7: defining beans [cxf,org.apache.cxf.bus.spring.BusWiringBeanFactoryPostProcessor,org.apache.cxf.bus.spring.Jsr250BeanPostProcessor,org.apache.cxf.bus.spring.BusExtensionPostProcessor,dataReceiverStreamsService,dataReceiverStreamService,streamsBean,streamBean]; root of factory hierarchy {org.springframework.beans.factory.support.DefaultListableBeanFactory}
TID: [0] [BAM] [2014-09-17 17:32:57,666]  INFO {org.wso2.carbon.webapp.mgt.WebApplication} -  Unloaded webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/datareceiver] {org.wso2.carbon.webapp.mgt.WebApplication}
TID: [0] [BAM] [2014-09-17 17:32:57,678]  INFO {org.wso2.carbon.webapp.mgt.WebApplication} -  Unloaded webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/bamdashboards] {org.wso2.carbon.webapp.mgt.WebApplication}
TID: [0] [BAM] [2014-09-17 17:32:57,690]  INFO {org.wso2.carbon.webapp.mgt.WebApplication} -  Unloaded webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/activitymonitoring] {org.wso2.carbon.webapp.mgt.WebApplication}
TID: [0] [BAM] [2014-09-17 17:32:57,690]  INFO {org.wso2.carbon.core.ServerManagement} -  All deployment tasks have been completed. {org.wso2.carbon.core.ServerManagement}
TID: [0] [BAM] [2014-09-17 17:32:57,691]  INFO {org.wso2.carbon.core.ServerManagement} -  Waiting for server task completion... {org.wso2.carbon.core.ServerManagement}
TID: [0] [BAM] [2014-09-17 17:32:57,691]  INFO {org.wso2.carbon.core.ServerManagement} -  All server tasks have been completed. {org.wso2.carbon.core.ServerManagement}
TID: [0] [BAM] [2014-09-17 17:32:57,691]  INFO {org.wso2.carbon.core.init.CarbonServerManager} -  Shutting down WSO2 Business Activity Monitor... {org.wso2.carbon.core.init.CarbonServerManager}
TID: [0] [BAM] [2014-09-17 17:32:57,691]  INFO {org.wso2.carbon.core.init.CarbonServerManager} -  Shutting down OSGi framework... {org.wso2.carbon.core.init.CarbonServerManager}
TID: [0] [BAM] [2014-09-17 17:32:57,709]  INFO {org.wso2.carbon.databridge.receiver.thrift.internal.ThriftDataReceiverDS} -  Thrift server shutting down... {org.wso2.carbon.databridge.receiver.thrift.internal.ThriftDataReceiverDS}
TID: [0] [BAM] [2014-09-17 17:32:58,627]  INFO {org.apache.cassandra.net.MessagingService} -  Waiting for messaging service to quiesce {org.apache.cassandra.net.MessagingService}
TID: [0] [BAM] [2014-09-17 17:32:58,629]  INFO {org.apache.cassandra.net.MessagingService} -  MessagingService shutting down server thread. {org.apache.cassandra.net.MessagingService}
TID: [0] [BAM] [2014-09-17 17:32:59,844]  INFO {org.wso2.carbon.core.init.CarbonServerManager} -  Stopping CarbonServerManager... {org.wso2.carbon.core.init.CarbonServerManager}
TID: [0] [BAM] [2014-09-17 17:32:59,844]  INFO {org.apache.axis2.transport.tcp.TCPTransportSender} -  TCP Sender Shutdown {org.apache.axis2.transport.tcp.TCPTransportSender}
TID: [0] [BAM] [2014-09-17 17:33:00,080]  INFO {org.wso2.carbon.tomcat.ext.internal.CarbonTomcatServiceComponent} -  Stopping the carbon web-app registered under : / {org.wso2.carbon.tomcat.ext.internal.CarbonTomcatServiceComponent}
TID: [0] [BAM] [2014-09-17 17:33:00,435]  INFO {org.wso2.carbon.core.init.CarbonServerManager} -  Shutdown complete {org.wso2.carbon.core.init.CarbonServerManager}
TID: [0] [BAM] [2014-09-17 17:33:00,435]  INFO {org.wso2.carbon.core.init.CarbonServerManager} -  Halting JVM {org.wso2.carbon.core.init.CarbonServerManager}
TID: [0] [BAM] [2014-09-17 17:33:12,920]  INFO {org.wso2.carbon.core.internal.CarbonCoreActivator} -  Starting WSO2 Carbon... {org.wso2.carbon.core.internal.CarbonCoreActivator}
TID: [0] [BAM] [2014-09-17 17:33:12,921]  INFO {org.wso2.carbon.core.internal.CarbonCoreActivator} -  Operating System : Linux 3.13.0-24-generic, amd64 {org.wso2.carbon.core.internal.CarbonCoreActivator}
TID: [0] [BAM] [2014-09-17 17:33:12,921]  INFO {org.wso2.carbon.core.internal.CarbonCoreActivator} -  Java Home        : /usr/lib/jvm/java-6-oracle/jre {org.wso2.carbon.core.internal.CarbonCoreActivator}
TID: [0] [BAM] [2014-09-17 17:33:12,921]  INFO {org.wso2.carbon.core.internal.CarbonCoreActivator} -  Java Version     : 1.6.0_45 {org.wso2.carbon.core.internal.CarbonCoreActivator}
TID: [0] [BAM] [2014-09-17 17:33:12,921]  INFO {org.wso2.carbon.core.internal.CarbonCoreActivator} -  Java VM          : Java HotSpot(TM) 64-Bit Server VM 20.45-b01,Sun Microsystems Inc. {org.wso2.carbon.core.internal.CarbonCoreActivator}
TID: [0] [BAM] [2014-09-17 17:33:12,921]  INFO {org.wso2.carbon.core.internal.CarbonCoreActivator} -  Carbon Home      : /home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0 {org.wso2.carbon.core.internal.CarbonCoreActivator}
TID: [0] [BAM] [2014-09-17 17:33:12,921]  INFO {org.wso2.carbon.core.internal.CarbonCoreActivator} -  Java Temp Dir    : /home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/tmp {org.wso2.carbon.core.internal.CarbonCoreActivator}
TID: [0] [BAM] [2014-09-17 17:33:12,921]  INFO {org.wso2.carbon.core.internal.CarbonCoreActivator} -  User             : denuwanthi, en-US, Asia/Colombo {org.wso2.carbon.core.internal.CarbonCoreActivator}
TID: [0] [BAM] [2014-09-17 17:33:12,967]  WARN {org.wso2.carbon.core.bootup.validator.util.ValidationResultPrinter} -  The default keystore (wso2carbon.jks) is currently being used. To maximize security when deploying to a production environment, configure a new keystore with a unique password in the production server profile. {org.wso2.carbon.core.bootup.validator.util.ValidationResultPrinter}
TID: [0] [BAM] [2014-09-17 17:33:12,988]  INFO {org.wso2.carbon.databridge.agent.thrift.AgentHolder} -  Agent created ! {org.wso2.carbon.databridge.agent.thrift.AgentHolder}
TID: [0] [BAM] [2014-09-17 17:33:13,045]  INFO {org.wso2.carbon.databridge.agent.thrift.internal.AgentDS} -  Successfully deployed Agent Client {org.wso2.carbon.databridge.agent.thrift.internal.AgentDS}
TID: [0] [BAM] [2014-09-17 17:33:14,068]  INFO {org.wso2.carbon.bam.toolbox.deployer.internal.DataBridgeRecieverServiceComponent} -  Successfully setted data bridge reciever service {org.wso2.carbon.bam.toolbox.deployer.internal.DataBridgeRecieverServiceComponent}
TID: [0] [BAM] [2014-09-17 17:33:14,076]  INFO {org.wso2.carbon.databridge.core.internal.DataBridgeDS} -  Successfully deployed Agent Server  {org.wso2.carbon.databridge.core.internal.DataBridgeDS}
TID: [0] [BAM] [2014-09-17 17:33:14,197]  INFO {org.wso2.carbon.registry.core.jdbc.EmbeddedRegistryService} -  Configured Registry in 45ms {org.wso2.carbon.registry.core.jdbc.EmbeddedRegistryService}
TID: [0] [BAM] [2014-09-17 17:33:14,279]  INFO {org.wso2.carbon.registry.core.internal.RegistryCoreServiceComponent} -  Registry Mode    : READ-WRITE {org.wso2.carbon.registry.core.internal.RegistryCoreServiceComponent}
TID: [0] [BAM] [2014-09-17 17:33:14,676]  INFO {org.wso2.carbon.user.core.internal.UserStoreMgtDSComponent} -  Carbon UserStoreMgtDSComponent activated successfully. {org.wso2.carbon.user.core.internal.UserStoreMgtDSComponent}
TID: [0] [BAM] [2014-09-17 17:33:15,092]  INFO {org.apache.cassandra.net.MessagingService} -  Starting Messaging Service on port 7001 {org.apache.cassandra.net.MessagingService}
TID: [0] [BAM] [2014-09-17 17:33:15,133]  INFO {org.apache.cassandra.thrift.CassandraDaemon} -  Binding thrift service to localhost/127.0.0.1:9161 {org.apache.cassandra.thrift.CassandraDaemon}
TID: [0] [BAM] [2014-09-17 17:33:15,134]  INFO {org.apache.cassandra.thrift.CassandraDaemon} -  Using TFastFramedTransport with a max frame size of 15728640 bytes. {org.apache.cassandra.thrift.CassandraDaemon}
TID: [0] [BAM] [2014-09-17 17:33:15,136]  INFO {org.apache.cassandra.thrift.CassandraDaemon} -  Using synchronous/threadpool thrift server on localhost/127.0.0.1 : 9161 {org.apache.cassandra.thrift.CassandraDaemon}
TID: [0] [BAM] [2014-09-17 17:33:15,136]  INFO {org.wso2.carbon.cassandra.server.CassandraServerController} -  Cassandra Server Controller Thread was destroyed successfully {org.wso2.carbon.cassandra.server.CassandraServerController}
TID: [0] [BAM] [2014-09-17 17:33:15,136]  INFO {org.apache.cassandra.thrift.CassandraDaemon} -  Listening for thrift clients... {org.apache.cassandra.thrift.CassandraDaemon}
TID: [0] [BAM] [2014-09-17 17:33:18,491]  INFO {org.apache.axis2.deployment.ClusterBuilder} -  Clustering has been disabled {org.apache.axis2.deployment.ClusterBuilder}
TID: [0] [BAM] [2014-09-17 17:33:18,633]  INFO {org.wso2.carbon.identity.user.store.configuration.deployer.UserStoreConfigurationDeployer} -  User Store Configuration Deployer initiated. {org.wso2.carbon.identity.user.store.configuration.deployer.UserStoreConfigurationDeployer}
TID: [0] [BAM] [2014-09-17 17:33:18,668]  INFO {org.wso2.carbon.stratos.landing.page.deployer.LandingPageWebappDeployer} -  Deployed product landing page webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/home] {org.wso2.carbon.stratos.landing.page.deployer.LandingPageWebappDeployer}
TID: [0] [BAM] [2014-09-17 17:33:18,672]  INFO {org.apache.axis2.transport.tcp.TCPTransportSender} -  TCP Sender started {org.apache.axis2.transport.tcp.TCPTransportSender}
TID: [0] [BAM] [2014-09-17 17:33:18,699]  INFO {org.wso2.carbon.webapp.mgt.TomcatGenericWebappsDeployer} -  Deployed webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/STRATOS_ROOT].File[/home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/repository/deployment/server/webapps/STRATOS_ROOT] {org.wso2.carbon.webapp.mgt.TomcatGenericWebappsDeployer}
TID: [0] [BAM] [2014-09-17 17:33:19,210]  INFO {org.springframework.web.context.support.XmlWebApplicationContext} -  Refreshing Root WebApplicationContext: startup date [Wed Sep 17 17:33:19 IST 2014]; root of context hierarchy {org.springframework.web.context.support.XmlWebApplicationContext}
TID: [0] [BAM] [2014-09-17 17:33:19,245]  INFO {org.springframework.beans.factory.xml.XmlBeanDefinitionReader} -  Loading XML bean definitions from class path resource [META-INF/cxf/cxf.xml] {org.springframework.beans.factory.xml.XmlBeanDefinitionReader}
TID: [0] [BAM] [2014-09-17 17:33:19,297]  INFO {org.springframework.beans.factory.xml.XmlBeanDefinitionReader} -  Loading XML bean definitions from URL [jndi:/localhost/datareceiver/WEB-INF/cxf-servlet.xml] {org.springframework.beans.factory.xml.XmlBeanDefinitionReader}
TID: [0] [BAM] [2014-09-17 17:33:19,529]  INFO {org.springframework.beans.factory.support.DefaultListableBeanFactory} -  Pre-instantiating singletons in org.springframework.beans.factory.support.DefaultListableBeanFactory@45ab6087: defining beans [cxf,org.apache.cxf.bus.spring.BusWiringBeanFactoryPostProcessor,org.apache.cxf.bus.spring.Jsr250BeanPostProcessor,org.apache.cxf.bus.spring.BusExtensionPostProcessor,dataReceiverStreamsService,dataReceiverStreamService,streamsBean,streamBean]; root of factory hierarchy {org.springframework.beans.factory.support.DefaultListableBeanFactory}
TID: [0] [BAM] [2014-09-17 17:33:19,825]  INFO {org.apache.cxf.endpoint.ServerImpl} -  Setting the server's publish address to be /streams {org.apache.cxf.endpoint.ServerImpl}
TID: [0] [BAM] [2014-09-17 17:33:19,869]  INFO {org.apache.cxf.endpoint.ServerImpl} -  Setting the server's publish address to be /stream {org.apache.cxf.endpoint.ServerImpl}
TID: [0] [BAM] [2014-09-17 17:33:19,874]  INFO {org.wso2.carbon.webapp.mgt.TomcatGenericWebappsDeployer} -  Deployed webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/datareceiver].File[/home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/repository/deployment/server/webapps/datareceiver.war] {org.wso2.carbon.webapp.mgt.TomcatGenericWebappsDeployer}
TID: [0] [BAM] [2014-09-17 17:33:20,414]  INFO {org.jaggeryjs.jaggery.app.mgt.TomcatJaggeryWebappsDeployer} -  Deployed webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/bamdashboards].File[/home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/repository/deployment/server/jaggeryapps/bamdashboards] {org.jaggeryjs.jaggery.app.mgt.TomcatJaggeryWebappsDeployer}
TID: [0] [BAM] [2014-09-17 17:33:20,451]  INFO {org.jaggeryjs.jaggery.app.mgt.TomcatJaggeryWebappsDeployer} -  Deployed webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/activitymonitoring].File[/home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/repository/deployment/server/jaggeryapps/activitymonitoring] {org.jaggeryjs.jaggery.app.mgt.TomcatJaggeryWebappsDeployer}
TID: [0] [BAM] [2014-09-17 17:33:20,525]  INFO {org.apache.axis2.deployment.ModuleDeployer} -  Deploying module: rampart-1.6.1-wso2v10 - file:/home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/repository/deployment/client/modules/rampart-1.6.1-wso2v10.mar {org.apache.axis2.deployment.ModuleDeployer}
TID: [0] [BAM] [2014-09-17 17:33:20,528]  INFO {org.apache.axis2.deployment.ModuleDeployer} -  Deploying module: addressing-1.6.1-wso2v10 - file:/home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/repository/deployment/client/modules/addressing-1.6.1-wso2v10.mar {org.apache.axis2.deployment.ModuleDeployer}
TID: [0] [BAM] [2014-09-17 17:33:20,530]  INFO {org.apache.axis2.transport.tcp.TCPTransportSender} -  TCP Sender started {org.apache.axis2.transport.tcp.TCPTransportSender}
TID: [0] [BAM] [2014-09-17 17:33:20,734]  INFO {org.wso2.carbon.core.deployment.DeploymentInterceptor} -  Deploying Axis2 service: BAMMessageStoreService {super-tenant} {org.wso2.carbon.core.deployment.DeploymentInterceptor}
TID: [0] [BAM] [2014-09-17 17:33:20,782]  INFO {org.apache.axis2.deployment.DeploymentEngine} -  Deploying Web service: org.wso2.carbon.bam.messagestore -  {org.apache.axis2.deployment.DeploymentEngine}
TID: [0] [BAM] [2014-09-17 17:33:20,960]  INFO {org.wso2.carbon.core.deployment.DeploymentInterceptor} -  Deploying Axis2 service: CassandraSearchAdmin {super-tenant} {org.wso2.carbon.core.deployment.DeploymentInterceptor}
TID: [0] [BAM] [2014-09-17 17:33:21,062]  INFO {org.apache.axis2.deployment.DeploymentEngine} -  Deploying Web service: org.wso2.carbon.cassandra.search.mgt -  {org.apache.axis2.deployment.DeploymentEngine}
TID: [0] [BAM] [2014-09-17 17:33:21,656]  INFO {org.wso2.carbon.core.init.CarbonServerManager} -  Repository       : /home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/repository/deployment/server/ {org.wso2.carbon.core.init.CarbonServerManager}
TID: [0] [BAM] [2014-09-17 17:33:21,676]  INFO {org.wso2.carbon.bam.toolbox.deployer.internal.BAMToolBoxDeployerComponent} -  Successfully Started BAM Toolbox Deployer {org.wso2.carbon.bam.toolbox.deployer.internal.BAMToolBoxDeployerComponent}
TID: [0] [BAM] [2014-09-17 17:33:21,703]  INFO {org.wso2.carbon.core.internal.permission.update.PermissionUpdater} -  Permission cache updated for tenant -1234 {org.wso2.carbon.core.internal.permission.update.PermissionUpdater}
TID: [0] [BAM] [2014-09-17 17:33:21,712]  INFO {org.wso2.carbon.bam.toolbox.deployer.internal.DashboardServiceComponent} -  Successfully setted dashboard services {org.wso2.carbon.bam.toolbox.deployer.internal.DashboardServiceComponent}
TID: [0] [BAM] [2014-09-17 17:33:21,798]  INFO {org.wso2.carbon.databridge.receiver.thrift.internal.ThriftDataReceiver} -  Thrift Server started at 10.100.5.90 {org.wso2.carbon.databridge.receiver.thrift.internal.ThriftDataReceiver}
TID: [0] [BAM] [2014-09-17 17:33:21,802]  INFO {org.wso2.carbon.databridge.receiver.thrift.internal.ThriftDataReceiver} -  Thrift SSL port : 7712 {org.wso2.carbon.databridge.receiver.thrift.internal.ThriftDataReceiver}
TID: [0] [BAM] [2014-09-17 17:33:21,804]  INFO {org.wso2.carbon.databridge.receiver.thrift.internal.ThriftDataReceiver} -  Thrift port : 7612 {org.wso2.carbon.databridge.receiver.thrift.internal.ThriftDataReceiver}
TID: [0] [BAM] [2014-09-17 17:33:22,012]  INFO {org.wso2.carbon.core.transports.http.HttpsTransportListener} -  HTTPS port       : 9444 {org.wso2.carbon.core.transports.http.HttpsTransportListener}
TID: [0] [BAM] [2014-09-17 17:33:22,012]  INFO {org.wso2.carbon.core.transports.http.HttpTransportListener} -  HTTP port        : 9764 {org.wso2.carbon.core.transports.http.HttpTransportListener}
TID: [0] [BAM] [2014-09-17 17:33:22,082]  INFO {org.wso2.carbon.ntask.core.service.impl.TaskServiceImpl} -  Task service starting in STANDALONE mode... {org.wso2.carbon.ntask.core.service.impl.TaskServiceImpl}
TID: [0] [BAM] [2014-09-17 17:33:22,181]  INFO {org.wso2.carbon.core.init.JMXServerManager} -  JMX Service URL  : service:jmx:rmi://localhost:11112/jndi/rmi://localhost:10000/jmxrmi {org.wso2.carbon.core.init.JMXServerManager}
TID: [0] [BAM] [2014-09-17 17:33:22,181]  INFO {org.wso2.carbon.bam.toolbox.deployer.internal.ServerStartUpInspector} -  BAM Toolbox is ready to do deployments {org.wso2.carbon.bam.toolbox.deployer.internal.ServerStartUpInspector}
TID: [0] [BAM] [2014-09-17 17:33:22,185]  INFO {org.wso2.carbon.bam.toolbox.deployer.core.BAMToolBoxDeployer} -  /home/denuwanthi/G-reg/Feature-LCDashboard/datacollector/BAM/wso2bam-2.4.0/repository/deployment/server/bam-toolbox {org.wso2.carbon.bam.toolbox.deployer.core.BAMToolBoxDeployer}
TID: [0] [BAM] [2014-09-17 17:33:22,223]  INFO {org.wso2.carbon.ntask.core.impl.AbstractQuartzTaskManager} -  Task scheduled: [-1234][HIVE_TASK][ Github_Committers_MySQL] {org.wso2.carbon.ntask.core.impl.AbstractQuartzTaskManager}
TID: [0] [BAM] [2014-09-17 17:33:22,225]  INFO {org.wso2.carbon.ntask.core.impl.AbstractQuartzTaskManager} -  Task scheduled: [-1234][HIVE_TASK][Github_Commits_MySQL] {org.wso2.carbon.ntask.core.impl.AbstractQuartzTaskManager}
TID: [0] [BAM] [2014-09-17 17:33:22,227]  INFO {org.wso2.carbon.ntask.core.impl.AbstractQuartzTaskManager} -  Task scheduled: [-1234][HIVE_TASK][Gituhub_MySQL] {org.wso2.carbon.ntask.core.impl.AbstractQuartzTaskManager}
TID: [0] [BAM] [2014-09-17 17:33:22,227]  INFO {org.wso2.carbon.core.internal.StartupFinalizerServiceComponent} -  Server           :  WSO2 Business Activity Monitor-2.4.0 {org.wso2.carbon.core.internal.StartupFinalizerServiceComponent}
TID: [0] [BAM] [2014-09-17 17:33:22,227]  INFO {org.wso2.carbon.core.internal.StartupFinalizerServiceComponent} -  WSO2 Carbon started in 11 sec {org.wso2.carbon.core.internal.StartupFinalizerServiceComponent}
TID: [0] [BAM] [2014-09-17 17:33:22,967]  INFO {org.wso2.carbon.dashboard.common.oauth.GSOAuthModule} -  Using random key for OAuth client-side state encryption {org.wso2.carbon.dashboard.common.oauth.GSOAuthModule}
TID: [0] [BAM] [2014-09-17 17:33:23,350]  INFO {org.wso2.carbon.ui.internal.CarbonUIServiceComponent} -  Mgt Console URL  : https://10.100.5.90:9444/carbon/ {org.wso2.carbon.ui.internal.CarbonUIServiceComponent}
TID: [0] [BAM] [2014-09-17 17:33:23,350]  INFO {org.wso2.carbon.ui.internal.CarbonUIServiceComponent} -  Gadget Server Default Context : http://10.100.5.90:9764/portal {org.wso2.carbon.ui.internal.CarbonUIServiceComponent}
TID: [0] [BAM] [2014-09-17 17:34:10,009]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 17:34:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:34:10,009]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 17:34:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:34:10,009]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 17:34:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:34:11,101] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.GitCommittersTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:34:11,101] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.GithubCommitsTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:34:11,101] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.GitStatsTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:34:11,114] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.summarizedGitTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:34:11,114] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.summarizedGitCommittersTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:34:11,114] ERROR {hive.ql.metadata.Hive} -  NoSuchObjectException(message:default.SummarizedGithubCommitsTable table not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1222)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$17.run(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1217)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:734)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:901)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:843)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3127)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {hive.ql.metadata.Hive}
TID: [0] [BAM] [2014-09-17 17:34:14,094]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:34:14,114]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:34:14,303]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:35:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 17:35:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:35:10,006]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 17:35:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:35:10,009]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 17:35:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:35:10,234] ERROR {DataNucleus.Datastore.Persist} -  Update of object "org.apache.hadoop.hive.metastore.model.MStorageDescriptor@39a569f0" using statement "UPDATE SDS SET CD_ID=? WHERE SD_ID=?" failed : org.h2.jdbc.JdbcSQLException: Deadlock detected. The current transaction was rolled back. Details: "
Session #17 (user: WSO2CARBON) is waiting to lock PUBLIC.COLUMNS_V2 while locking PUBLIC.IDXS (shared), PUBLIC.TBLS (shared), PUBLIC.DBS (shared), PUBLIC.TBL_PRIVS (shared), PUBLIC.TBL_COL_PRIVS (shared), PUBLIC.PART_PRIVS (shared), PUBLIC.PARTITIONS (shared), PUBLIC.PART_COL_PRIVS (shared), PUBLIC.SDS (exclusive).
Session #16 (user: WSO2CARBON) is waiting to lock PUBLIC.SDS while locking PUBLIC.PARTITION_KEYS (shared), PUBLIC.COLUMNS_V2 (shared), PUBLIC.SORT_COLS (shared), PUBLIC.IDXS (shared), PUBLIC.TBLS (shared), PUBLIC.DBS (shared), PUBLIC.TBL_PRIVS (shared), PUBLIC.TBL_COL_PRIVS (shared), PUBLIC.PART_PRIVS (shared), PUBLIC.PARTITIONS (shared), PUBLIC.PART_COL_PRIVS (shared)."; SQL statement:
UPDATE SDS SET CD_ID=? WHERE SD_ID=? [40001-140]
	at org.h2.message.DbException.getJdbcSQLException(DbException.java:327)
	at org.h2.message.DbException.get(DbException.java:167)
	at org.h2.message.DbException.get(DbException.java:144)
	at org.h2.table.RegularTable.doLock(RegularTable.java:457)
	at org.h2.table.RegularTable.lock(RegularTable.java:404)
	at org.h2.command.dml.Update.update(Update.java:80)
	at org.h2.command.CommandContainer.update(CommandContainer.java:70)
	at org.h2.command.Command.executeUpdate(Command.java:199)
	at org.h2.jdbc.JdbcPreparedStatement.executeUpdateInternal(JdbcPreparedStatement.java:141)
	at org.h2.jdbc.JdbcPreparedStatement.executeUpdate(JdbcPreparedStatement.java:127)
	at org.apache.commons.dbcp.DelegatingPreparedStatement.executeUpdate(DelegatingPreparedStatement.java:105)
	at org.apache.commons.dbcp.DelegatingPreparedStatement.executeUpdate(DelegatingPreparedStatement.java:105)
	at org.datanucleus.store.rdbms.SQLController.executeStatementUpdate(SQLController.java:419)
	at org.datanucleus.store.rdbms.request.UpdateRequest.execute(UpdateRequest.java:375)
	at org.datanucleus.store.rdbms.RDBMSPersistenceHandler.updateTable(RDBMSPersistenceHandler.java:411)
	at org.datanucleus.store.rdbms.RDBMSPersistenceHandler.updateObject(RDBMSPersistenceHandler.java:384)
	at org.datanucleus.state.JDOStateManager.flush(JDOStateManager.java:3846)
	at org.datanucleus.ObjectManagerImpl.flushInternalWithOrdering(ObjectManagerImpl.java:3888)
	at org.datanucleus.ObjectManagerImpl.flushInternal(ObjectManagerImpl.java:3811)
	at org.datanucleus.MultithreadedObjectManager.flushInternal(MultithreadedObjectManager.java:531)
	at org.datanucleus.store.query.Query.prepareDatastore(Query.java:1560)
	at org.datanucleus.store.query.Query.executeQuery(Query.java:1763)
	at org.datanucleus.store.query.Query.executeWithArray(Query.java:1666)
	at org.datanucleus.api.jdo.JDOQuery.execute(JDOQuery.java:243)
	at org.apache.hadoop.hive.metastore.ObjectStore.listStorageDescriptorsWithCD(ObjectStore.java:2063)
	at org.apache.hadoop.hive.metastore.ObjectStore.removeUnusedColumnDescriptor(ObjectStore.java:2009)
	at org.apache.hadoop.hive.metastore.ObjectStore.preDropStorageDescriptor(ObjectStore.java:2040)
	at org.apache.hadoop.hive.metastore.ObjectStore.dropTable(ObjectStore.java:739)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.drop_table_core(HiveMetaStore.java:1154)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.access$800(HiveMetaStore.java:141)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$16.run(HiveMetaStore.java:1180)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$16.run(HiveMetaStore.java:1177)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.drop_table(HiveMetaStore.java:1177)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropTable(HiveMetaStoreClient.java:552)
	at org.apache.hadoop.hive.ql.metadata.Hive.dropTable(Hive.java:820)
	at org.apache.hadoop.hive.ql.metadata.Hive.dropTable(Hive.java:783)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3171)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {DataNucleus.Datastore.Persist}
TID: [0] [BAM] [2014-09-17 17:35:10,236] ERROR {org.apache.hadoop.hive.metastore.HiveMetaStore} -  JDO datastore error. Retrying metastore command after 1000 ms (attempt 1 of 1) {org.apache.hadoop.hive.metastore.HiveMetaStore}
TID: [0] [BAM] [2014-09-17 17:35:10,335] ERROR {DataNucleus.Datastore.Persist} -  Update of object "org.apache.hadoop.hive.metastore.model.MStorageDescriptor@2db068f5" using statement "UPDATE SDS SET CD_ID=? WHERE SD_ID=?" failed : org.h2.jdbc.JdbcSQLException: Deadlock detected. The current transaction was rolled back. Details: "
Session #17 (user: WSO2CARBON) is waiting to lock PUBLIC.TBLS while locking PUBLIC.IDXS (shared), PUBLIC.TBLS (shared), PUBLIC.DBS (shared), PUBLIC.TBL_PRIVS (shared), PUBLIC.TBL_COL_PRIVS (shared), PUBLIC.PART_PRIVS (shared), PUBLIC.PARTITIONS (shared), PUBLIC.PART_COL_PRIVS (shared), PUBLIC.SDS (exclusive), PUBLIC.COLUMNS_V2 (exclusive), PUBLIC.CDS (exclusive), PUBLIC.TABLE_PARAMS (exclusive).
Session #15 (user: WSO2CARBON) is waiting to lock PUBLIC.SDS while locking PUBLIC.SORT_COLS (shared), PUBLIC.IDXS (shared), PUBLIC.TBLS (shared), PUBLIC.DBS (shared), PUBLIC.TBL_PRIVS (shared), PUBLIC.TBL_COL_PRIVS (shared), PUBLIC.PART_PRIVS (shared), PUBLIC.PARTITIONS (shared), PUBLIC.PART_COL_PRIVS (shared)."; SQL statement:
UPDATE SDS SET CD_ID=? WHERE SD_ID=? [40001-140]
	at org.h2.message.DbException.getJdbcSQLException(DbException.java:327)
	at org.h2.message.DbException.get(DbException.java:167)
	at org.h2.message.DbException.get(DbException.java:144)
	at org.h2.table.RegularTable.doLock(RegularTable.java:457)
	at org.h2.table.RegularTable.lock(RegularTable.java:404)
	at org.h2.command.dml.Update.update(Update.java:80)
	at org.h2.command.CommandContainer.update(CommandContainer.java:70)
	at org.h2.command.Command.executeUpdate(Command.java:199)
	at org.h2.jdbc.JdbcPreparedStatement.executeUpdateInternal(JdbcPreparedStatement.java:141)
	at org.h2.jdbc.JdbcPreparedStatement.executeUpdate(JdbcPreparedStatement.java:127)
	at org.apache.commons.dbcp.DelegatingPreparedStatement.executeUpdate(DelegatingPreparedStatement.java:105)
	at org.apache.commons.dbcp.DelegatingPreparedStatement.executeUpdate(DelegatingPreparedStatement.java:105)
	at org.datanucleus.store.rdbms.SQLController.executeStatementUpdate(SQLController.java:419)
	at org.datanucleus.store.rdbms.request.UpdateRequest.execute(UpdateRequest.java:375)
	at org.datanucleus.store.rdbms.RDBMSPersistenceHandler.updateTable(RDBMSPersistenceHandler.java:411)
	at org.datanucleus.store.rdbms.RDBMSPersistenceHandler.updateObject(RDBMSPersistenceHandler.java:384)
	at org.datanucleus.state.JDOStateManager.flush(JDOStateManager.java:3846)
	at org.datanucleus.ObjectManagerImpl.flushInternalWithOrdering(ObjectManagerImpl.java:3888)
	at org.datanucleus.ObjectManagerImpl.flushInternal(ObjectManagerImpl.java:3811)
	at org.datanucleus.MultithreadedObjectManager.flushInternal(MultithreadedObjectManager.java:531)
	at org.datanucleus.store.query.Query.prepareDatastore(Query.java:1560)
	at org.datanucleus.store.query.Query.executeQuery(Query.java:1763)
	at org.datanucleus.store.query.Query.executeWithArray(Query.java:1666)
	at org.datanucleus.api.jdo.JDOQuery.execute(JDOQuery.java:243)
	at org.apache.hadoop.hive.metastore.ObjectStore.listStorageDescriptorsWithCD(ObjectStore.java:2063)
	at org.apache.hadoop.hive.metastore.ObjectStore.removeUnusedColumnDescriptor(ObjectStore.java:2009)
	at org.apache.hadoop.hive.metastore.ObjectStore.preDropStorageDescriptor(ObjectStore.java:2040)
	at org.apache.hadoop.hive.metastore.ObjectStore.dropTable(ObjectStore.java:739)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.drop_table_core(HiveMetaStore.java:1154)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.access$800(HiveMetaStore.java:141)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$16.run(HiveMetaStore.java:1180)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$16.run(HiveMetaStore.java:1177)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:360)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.drop_table(HiveMetaStore.java:1177)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropTable(HiveMetaStoreClient.java:552)
	at org.apache.hadoop.hive.ql.metadata.Hive.dropTable(Hive.java:820)
	at org.apache.hadoop.hive.ql.metadata.Hive.dropTable(Hive.java:783)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3171)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:250)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:129)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:62)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1351)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1126)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:934)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:201)
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:187)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.executeHiveQuery(HiveExecutorServiceImpl.java:569)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:282)
	at org.wso2.carbon.analytics.hive.impl.HiveExecutorServiceImpl$ScriptCallable.call(HiveExecutorServiceImpl.java:189)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
 {DataNucleus.Datastore.Persist}
TID: [0] [BAM] [2014-09-17 17:35:10,337] ERROR {org.apache.hadoop.hive.metastore.HiveMetaStore} -  JDO datastore error. Retrying metastore command after 1000 ms (attempt 1 of 1) {org.apache.hadoop.hive.metastore.HiveMetaStore}
TID: [0] [BAM] [2014-09-17 17:35:12,131]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:35:13,458]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:35:13,708]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:36:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 17:36:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:36:10,007]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 17:36:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:36:10,009]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 17:36:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:36:12,292]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:36:12,364]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:36:12,393]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:37:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 17:37:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:37:10,005]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 17:37:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:37:10,007]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 17:37:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:37:12,082]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:37:12,162]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:37:12,216]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:38:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 17:38:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:38:10,004]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 17:38:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:38:10,006]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 17:38:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:38:12,053]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:38:12,240]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:38:12,472]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:39:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 17:39:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:39:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 17:39:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:39:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 17:39:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:39:12,191]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:39:12,224]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:39:12,544]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:40:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 17:40:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:40:10,004]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 17:40:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:40:10,006]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 17:40:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:40:12,122]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:40:12,148]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:40:12,187]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:41:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 17:41:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:41:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 17:41:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:41:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 17:41:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:41:12,010]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:41:12,513]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:41:12,593]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:42:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 17:42:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:42:10,004]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 17:42:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:42:10,007]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 17:42:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:42:12,056]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:42:12,101]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:42:12,241]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:43:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 17:43:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:43:10,004]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 17:43:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:43:10,006]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 17:43:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:43:11,962]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:43:12,113]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:43:12,152]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:44:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 17:44:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:44:10,004]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 17:44:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:44:10,006]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 17:44:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:44:12,051]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:44:12,157]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:44:12,195]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:45:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 17:45:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:45:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 17:45:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:45:10,005]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 17:45:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:45:12,117]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:45:12,141]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:45:12,268]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:46:10,000]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 17:46:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:46:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 17:46:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:46:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 17:46:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:46:12,073]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:46:12,247]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:46:12,342]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:47:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 17:47:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:47:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 17:47:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:47:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 17:47:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:47:11,977]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:47:12,253]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:47:12,292]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:48:10,000]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 17:48:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:48:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 17:48:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:48:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 17:48:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:48:11,989]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:48:12,100]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:48:12,138]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:49:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 17:49:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:49:10,004]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 17:49:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:49:10,005]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 17:49:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:49:12,082]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:49:12,293]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:49:12,390]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:50:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 17:50:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:50:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 17:50:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:50:10,004]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 17:50:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:50:12,090]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:50:12,169]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:50:12,196]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:51:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 17:51:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:51:10,004]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 17:51:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:51:10,007]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 17:51:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:51:12,070]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:51:12,277]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:51:12,334]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:52:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 17:52:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:52:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 17:52:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:52:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 17:52:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:52:11,901]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:52:12,302]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:52:12,340]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:53:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 17:53:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:53:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 17:53:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:53:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 17:53:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:53:12,321]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:53:12,413]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:53:12,500]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:54:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 17:54:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:54:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 17:54:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:54:10,004]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 17:54:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:54:12,046]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:54:12,104]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:54:12,202]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:55:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 17:55:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:55:10,005]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 17:55:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:55:10,006]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 17:55:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:55:12,021]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:55:12,296]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:55:12,451]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:56:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 17:56:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:56:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 17:56:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:56:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 17:56:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:56:12,005]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:56:12,446]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:56:12,508]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:57:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 17:57:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:57:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 17:57:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:57:10,005]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 17:57:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:57:12,068]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:57:12,212]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:57:12,327]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:58:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 17:58:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:58:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 17:58:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:58:10,004]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 17:58:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:58:12,038]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:58:12,108]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:58:12,152]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:59:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 17:59:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:59:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 17:59:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:59:10,004]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 17:59:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 17:59:12,164]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:59:12,370]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 17:59:12,432]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:00:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:00:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:00:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:00:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:00:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:00:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:00:12,429]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:00:12,523]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:00:12,579]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:01:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:01:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:01:10,004]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:01:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:01:10,006]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:01:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:01:12,175]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:01:12,268]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:01:12,404]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:02:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:02:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:02:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:02:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:02:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:02:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:02:12,746]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:02:12,780]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:02:12,855]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:03:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:03:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:03:10,004]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:03:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:03:10,006]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:03:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:03:12,231]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:03:12,320]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:03:12,354]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:04:10,000]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:04:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:04:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:04:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:04:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:04:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:04:12,228]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:04:12,265]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:04:12,331]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:05:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:05:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:05:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:05:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:05:10,005]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:05:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:05:12,399]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:05:12,510]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:05:12,550]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:06:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:06:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:06:10,004]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:06:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:06:10,005]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:06:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:06:13,706]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:06:13,732]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:06:14,023]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:07:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:07:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:07:10,004]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:07:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:07:10,005]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:07:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:07:13,263]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:07:13,498]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:07:13,583]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:08:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:08:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:08:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:08:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:08:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:08:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:08:12,945]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:08:12,970]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:08:13,001]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:09:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:09:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:09:10,004]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:09:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:09:10,007]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:09:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:09:13,342]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:09:13,469]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:09:13,774]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:10:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:10:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:10:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:10:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:10:10,005]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:10:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:10:12,037]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:10:12,070]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:10:12,184]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:11:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:11:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:11:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:11:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:11:10,005]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:11:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:11:11,955]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:11:12,242]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:11:12,394]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:12:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:12:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:12:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:12:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:12:10,005]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:12:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:12:12,050]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:12:12,285]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:12:12,486]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:13:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:13:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:13:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:13:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:13:10,005]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:13:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:13:12,080]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:13:12,177]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:13:12,204]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:14:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:14:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:14:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:14:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:14:10,005]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:14:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:14:12,089]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:14:12,111]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:14:12,174]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:15:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:15:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:15:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:15:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:15:10,005]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:15:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:15:12,178]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:15:12,195]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:15:12,376]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:16:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:16:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:16:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:16:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:16:10,004]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:16:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:16:12,250]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:16:12,323]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:16:12,417]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:17:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:17:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:17:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:17:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:17:10,005]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:17:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:17:12,156]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:17:12,187]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:17:12,323]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:18:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:18:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:18:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:18:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:18:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:18:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:18:12,841]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:18:13,068]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:18:13,207]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:19:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:19:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:19:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:19:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:19:10,004]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:19:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:19:12,055]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:19:12,061]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:19:12,124]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:20:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:20:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:20:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:20:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:20:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:20:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:20:12,165]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:20:12,269]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:20:12,320]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:21:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:21:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:21:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:21:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:21:10,005]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:21:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:21:12,131]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:21:12,245]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:21:12,354]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:22:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:22:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:22:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:22:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:22:10,005]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:22:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:22:12,128]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:22:12,231]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:22:12,290]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:23:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:23:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:23:10,005]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:23:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:23:10,007]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:23:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:23:12,051]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:23:12,187]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:23:12,292]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:24:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:24:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:24:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:24:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:24:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:24:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:24:12,197]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:24:12,250]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:24:12,475]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:25:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:25:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:25:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:25:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:25:10,004]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:25:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:25:12,128]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:25:12,171]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:25:12,228]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:26:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:26:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:26:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:26:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:26:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:26:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:26:11,942]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:26:12,124]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:26:12,197]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:27:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:27:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:27:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:27:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:27:10,005]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:27:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:27:11,979]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:27:12,380]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:27:12,413]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:28:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:28:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:28:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:28:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:28:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:28:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:28:12,050]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:28:12,235]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:28:12,272]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:29:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:29:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:29:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:29:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:29:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:29:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:29:14,379]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:29:14,415]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:29:14,609]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:30:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:30:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:30:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:30:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:30:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:30:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:30:12,036]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:30:12,539]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:30:12,582]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:31:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:31:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:31:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:31:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:31:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:31:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:31:12,114]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:31:12,224]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:31:12,250]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:32:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:32:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:32:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:32:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:32:10,006]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:32:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:32:12,171]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:32:12,477]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:32:12,633]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:33:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:33:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:33:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:33:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:33:10,004]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:33:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:33:12,212]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:33:12,247]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:33:12,294]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:34:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:34:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:34:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:34:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:34:10,004]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:34:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:34:12,087]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:34:12,200]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:34:12,224]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:35:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:35:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:35:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:35:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:35:10,004]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:35:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:35:12,265]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:35:12,357]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:35:12,460]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:36:10,000]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:36:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:36:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:36:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:36:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:36:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:36:12,209]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:36:12,666]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:36:12,738]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:37:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:37:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:37:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:37:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:37:10,004]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:37:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:37:12,434]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:37:12,437]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:37:12,477]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:38:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:38:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:38:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:38:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:38:10,004]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:38:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:38:12,207]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:38:12,540]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:38:12,665]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:39:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:39:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:39:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:39:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:39:10,005]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:39:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:39:12,110]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:39:12,282]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:39:12,365]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:40:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:40:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:40:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:40:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:40:10,005]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:40:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:40:12,166]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:40:12,643]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:40:12,711]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:41:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:41:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:41:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:41:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:41:10,004]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:41:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:41:12,032]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:41:12,321]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:41:12,330]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:42:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:42:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:42:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:42:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:42:10,004]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:42:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:42:12,172]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:42:12,360]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:42:12,370]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:43:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:43:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:43:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:43:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:43:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:43:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:43:11,994]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:43:12,020]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:43:12,300]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:44:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:44:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:44:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:44:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:44:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:44:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:44:12,173]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:44:12,223]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:44:12,324]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:45:10,000]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:45:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:45:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:45:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:45:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:45:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:45:11,960]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:45:12,250]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:45:12,384]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:46:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:46:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:46:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:46:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:46:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:46:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:46:12,097]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:46:12,374]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:46:12,401]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:47:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:47:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:47:10,004]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:47:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:47:10,006]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:47:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:47:18,119]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:47:18,148]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:47:18,238]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:48:10,000]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:48:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:48:10,000]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:48:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:48:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:48:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:48:12,262]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:48:12,363]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:48:12,409]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:49:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:49:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:49:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:49:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:49:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:49:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:49:12,175]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:49:12,289]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:49:12,413]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:50:10,000]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:50:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:50:10,000]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:50:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:50:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:50:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:50:12,125]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:50:12,376]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:50:12,426]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:51:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:51:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:51:10,004]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:51:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:51:10,005]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:51:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:51:12,057]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:51:12,068]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:51:12,204]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:52:10,000]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:52:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:52:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:52:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:52:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:52:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:52:11,971]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:52:12,229]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:52:12,372]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:53:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:53:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:53:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:53:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:53:10,005]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:53:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:53:12,054]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:53:12,169]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:53:12,225]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:54:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:54:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:54:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:54:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:54:10,005]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:54:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:54:11,952]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:54:12,332]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:54:12,463]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:55:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:55:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:55:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:55:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:55:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:55:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:55:12,127]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:55:12,229]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:55:12,348]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:56:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:56:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:56:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:56:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:56:10,004]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:56:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:56:12,085]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:56:12,125]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:56:12,178]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:57:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:57:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:57:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:57:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:57:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:57:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:57:12,073]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:57:12,114]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:57:12,273]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:58:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:58:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:58:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:58:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:58:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:58:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:58:12,120]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:58:12,306]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:58:12,353]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:59:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 18:59:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:59:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 18:59:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:59:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 18:59:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 18:59:12,133]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:59:12,219]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 18:59:12,369]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 19:00:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 19:00:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 19:00:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 19:00:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 19:00:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 19:00:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 19:00:12,127]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 19:00:12,211]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 19:00:12,378]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 19:01:10,000]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 19:01:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 19:01:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 19:01:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 19:01:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 19:01:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 19:01:12,072]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 19:01:12,176]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 19:01:12,265]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 19:02:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 19:02:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 19:02:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 19:02:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 19:02:10,004]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 19:02:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 19:02:12,088]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 19:02:12,323]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 19:02:12,375]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 19:03:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 19:03:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 19:03:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 19:03:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 19:03:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 19:03:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 19:03:11,978]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 19:03:12,357]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 19:03:12,518]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 19:04:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 19:04:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 19:04:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 19:04:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 19:04:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 19:04:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 19:04:12,159]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 19:04:12,218]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 19:04:12,372]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 19:05:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 19:05:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 19:05:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 19:05:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 19:05:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 19:05:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 19:05:12,008]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 19:05:12,102]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 19:05:12,109]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 19:06:10,000]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 19:06:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 19:06:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 19:06:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 19:06:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 19:06:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 19:06:12,271]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 19:06:12,480]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 19:06:12,626]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 19:07:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 19:07:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 19:07:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 19:07:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 19:07:10,004]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 19:07:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 19:07:12,126]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 19:07:12,166]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 19:07:12,209]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 19:08:10,001]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 19:08:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 19:08:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 19:08:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 19:08:10,004]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 19:08:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 19:08:12,198]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 19:08:12,221]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 19:08:12,396]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 19:09:10,002]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script  Github_Committers_MySQL. [Wed Sep 17 19:09:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 19:09:10,003]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Github_Commits_MySQL. [Wed Sep 17 19:09:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 19:09:10,004]  INFO {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask} -  Running script executor task for script Gituhub_MySQL. [Wed Sep 17 19:09:10 IST 2014] {org.wso2.carbon.analytics.hive.task.HiveScriptExecutorTask}
TID: [0] [BAM] [2014-09-17 19:09:12,076]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 19:09:12,078]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 19:09:12,150]  WARN {org.apache.hadoop.mapred.JobClient} -  Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. {org.apache.hadoop.mapred.JobClient}
TID: [0] [BAM] [2014-09-17 19:09:49,739]  INFO {org.wso2.carbon.core.init.CarbonServerManager} -  Shutdown hook triggered.... {org.wso2.carbon.core.init.CarbonServerManager}
TID: [0] [BAM] [2014-09-17 19:09:49,740]  INFO {org.wso2.carbon.core.init.CarbonServerManager} -  Gracefully shutting down WSO2 Business Activity Monitor... {org.wso2.carbon.core.init.CarbonServerManager}
TID: [0] [BAM] [2014-09-17 19:09:49,741]  INFO {org.apache.cassandra.thrift.CassandraDaemon} -  Stop listening to thrift clients {org.apache.cassandra.thrift.CassandraDaemon}
TID: [0] [BAM] [2014-09-17 19:09:49,741]  INFO {org.wso2.carbon.core.ServerManagement} -  Starting to switch to maintenance mode... {org.wso2.carbon.core.ServerManagement}
TID: [0] [BAM] [2014-09-17 19:09:49,742]  INFO {org.apache.cassandra.gms.Gossiper} -  Announcing shutdown {org.apache.cassandra.gms.Gossiper}
TID: [0] [BAM] [2014-09-17 19:09:49,742]  INFO {org.wso2.carbon.core.ServerManagement} -  Stopped all transport listeners {org.wso2.carbon.core.ServerManagement}
TID: [0] [BAM] [2014-09-17 19:09:49,742]  INFO {org.wso2.carbon.core.ServerManagement} -  Waiting for request service completion... {org.wso2.carbon.core.ServerManagement}
TID: [0] [BAM] [2014-09-17 19:09:49,745]  INFO {org.wso2.carbon.core.ServerManagement} -  All requests have been served. {org.wso2.carbon.core.ServerManagement}
TID: [0] [BAM] [2014-09-17 19:09:49,745]  INFO {org.wso2.carbon.core.ServerManagement} -  Waiting for deployment completion... {org.wso2.carbon.core.ServerManagement}
TID: [0] [BAM] [2014-09-17 19:09:49,771]  INFO {org.wso2.carbon.webapp.mgt.WebApplication} -  Unloaded webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/STRATOS_ROOT] {org.wso2.carbon.webapp.mgt.WebApplication}
TID: [0] [BAM] [2014-09-17 19:09:49,771]  INFO {org.springframework.web.context.support.XmlWebApplicationContext} -  Closing Root WebApplicationContext: startup date [Wed Sep 17 17:33:19 IST 2014]; root of context hierarchy {org.springframework.web.context.support.XmlWebApplicationContext}
TID: [0] [BAM] [2014-09-17 19:09:49,772]  INFO {org.springframework.beans.factory.support.DefaultListableBeanFactory} -  Destroying singletons in org.springframework.beans.factory.support.DefaultListableBeanFactory@45ab6087: defining beans [cxf,org.apache.cxf.bus.spring.BusWiringBeanFactoryPostProcessor,org.apache.cxf.bus.spring.Jsr250BeanPostProcessor,org.apache.cxf.bus.spring.BusExtensionPostProcessor,dataReceiverStreamsService,dataReceiverStreamService,streamsBean,streamBean]; root of factory hierarchy {org.springframework.beans.factory.support.DefaultListableBeanFactory}
TID: [0] [BAM] [2014-09-17 19:09:49,794]  INFO {org.wso2.carbon.webapp.mgt.WebApplication} -  Unloaded webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/datareceiver] {org.wso2.carbon.webapp.mgt.WebApplication}
TID: [0] [BAM] [2014-09-17 19:09:49,808]  INFO {org.wso2.carbon.webapp.mgt.WebApplication} -  Unloaded webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/bamdashboards] {org.wso2.carbon.webapp.mgt.WebApplication}
TID: [0] [BAM] [2014-09-17 19:09:49,823]  INFO {org.wso2.carbon.webapp.mgt.WebApplication} -  Unloaded webapp: StandardEngine[Catalina].StandardHost[localhost].StandardContext[/activitymonitoring] {org.wso2.carbon.webapp.mgt.WebApplication}
TID: [0] [BAM] [2014-09-17 19:09:49,823]  INFO {org.wso2.carbon.core.ServerManagement} -  All deployment tasks have been completed. {org.wso2.carbon.core.ServerManagement}
TID: [0] [BAM] [2014-09-17 19:09:49,823]  INFO {org.wso2.carbon.core.ServerManagement} -  Waiting for server task completion... {org.wso2.carbon.core.ServerManagement}
TID: [0] [BAM] [2014-09-17 19:09:49,824]  INFO {org.wso2.carbon.core.ServerManagement} -  All server tasks have been completed. {org.wso2.carbon.core.ServerManagement}
TID: [0] [BAM] [2014-09-17 19:09:49,824]  INFO {org.wso2.carbon.core.init.CarbonServerManager} -  Shutting down WSO2 Business Activity Monitor... {org.wso2.carbon.core.init.CarbonServerManager}
TID: [0] [BAM] [2014-09-17 19:09:49,824]  INFO {org.wso2.carbon.core.init.CarbonServerManager} -  Shutting down OSGi framework... {org.wso2.carbon.core.init.CarbonServerManager}
TID: [0] [BAM] [2014-09-17 19:09:49,875]  INFO {org.wso2.carbon.databridge.receiver.thrift.internal.ThriftDataReceiverDS} -  Thrift server shutting down... {org.wso2.carbon.databridge.receiver.thrift.internal.ThriftDataReceiverDS}
TID: [0] [BAM] [2014-09-17 19:09:50,742]  INFO {org.apache.cassandra.net.MessagingService} -  Waiting for messaging service to quiesce {org.apache.cassandra.net.MessagingService}
TID: [0] [BAM] [2014-09-17 19:09:50,744]  INFO {org.apache.cassandra.net.MessagingService} -  MessagingService shutting down server thread. {org.apache.cassandra.net.MessagingService}
TID: [0] [BAM] [2014-09-17 19:09:52,010]  INFO {org.wso2.carbon.core.init.CarbonServerManager} -  Stopping CarbonServerManager... {org.wso2.carbon.core.init.CarbonServerManager}
TID: [0] [BAM] [2014-09-17 19:09:52,011]  INFO {org.apache.axis2.transport.tcp.TCPTransportSender} -  TCP Sender Shutdown {org.apache.axis2.transport.tcp.TCPTransportSender}
TID: [0] [BAM] [2014-09-17 19:09:52,301]  INFO {org.wso2.carbon.tomcat.ext.internal.CarbonTomcatServiceComponent} -  Stopping the carbon web-app registered under : / {org.wso2.carbon.tomcat.ext.internal.CarbonTomcatServiceComponent}
TID: [0] [BAM] [2014-09-17 19:09:52,624]  INFO {org.wso2.carbon.core.init.CarbonServerManager} -  Shutdown complete {org.wso2.carbon.core.init.CarbonServerManager}
TID: [0] [BAM] [2014-09-17 19:09:52,624]  INFO {org.wso2.carbon.core.init.CarbonServerManager} -  Halting JVM {org.wso2.carbon.core.init.CarbonServerManager}
